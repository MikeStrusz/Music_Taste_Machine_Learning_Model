{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d392a2d-8247-40dc-9431-ae29941dc3ea",
   "metadata": {},
   "source": [
    "# Music Taste Prediction Model: New Music Friday Recommender\n",
    "In this model, I use my liked songs playlist, my recently loved and not loved albums, to train my regression model on what kind of music I do and don't like. At the end my test model will be the new music friday albums from the most recent Friday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e436444-4aff-431a-aedc-e7871c247d1e",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160a9a1f-e9f9-4fb7-b0e3-dcc706dba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# API and Network Requests\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from time import sleep\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Type Hints\n",
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c118756-4281-4236-b2b7-08f74aabd351",
   "metadata": {},
   "source": [
    "# Load Datasets\n",
    "Here we have 4 spotify playlists from my libarary, downloaded using Exportify.net. Plus a dataset of similar artists to the artists I've enjoyed prior to this new music friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8067f0c-b06b-4426-bad9-69bd28e3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked = pd.read_csv(\"data/liked.csv\")  # Liked playlist on Spotify\n",
    "df_fav_albums = pd.read_csv(\"data/liked_albums.csv\")  # Albums I've Liked in Recent Years\n",
    "df_not_liked = pd.read_csv(\"data/did_not_like.csv\")  # Albums I've not liked in Recent Years\n",
    "df_nmf = pd.read_csv(\"data/nmf.csv\")  # The most recent New Music Friday Playlist\n",
    "df_liked_similar = pd.read_csv(\"data/liked_artists_only_similar.csv\") #Lastfm pull of similar artists to my liked artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae0fe9-7816-4c12-828c-19d15b62f80b",
   "metadata": {},
   "source": [
    "## Pull Similar Artists to Your Favorite Artists\n",
    "This api will pull similar artists to all the unique artists from my liked songs and liked albums of the last few years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae3c1adc-0020-425f-89fa-56dee6f455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing and new data...\n",
      "Loaded 2126 existing artists from database\n",
      "Found 0 new artists to process\n",
      "No new artists to process. Database is up to date!\n",
      "\n",
      "First few rows of the similar artists DataFrame:\n",
      "        Artist                                    Similar Artists\n",
      "0         RY X                                                NaN\n",
      "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...\n",
      "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...\n",
      "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...\n",
      "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies...\n"
     ]
    }
   ],
   "source": [
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25, limit: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        self.limit = limit\n",
    "\n",
    "    def get_similar_artists(self, artist_name: str) -> List[str]:\n",
    "        \"\"\"Fetch similar artists for a given artist from LastFM API.\"\"\"\n",
    "        params = {\n",
    "            'method': 'artist.getSimilar',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'limit': self.limit,  # Add limit parameter\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Handle rate limiting\n",
    "            if 'X-RateLimit-Remaining' in response.headers:\n",
    "                remaining = int(response.headers['X-RateLimit-Remaining'])\n",
    "                if remaining == 0:\n",
    "                    sleep(self.rate_limit_delay)\n",
    "            \n",
    "            data = response.json()\n",
    "            if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "                return [artist['name'] for artist in data['similarartists']['artist'][:self.limit]]\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching similar artists for {artist_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "def extract_primary_artist(artist_string: str) -> str:\n",
    "    \"\"\"Extract the first artist name before any comma.\"\"\"\n",
    "    if pd.isna(artist_string):\n",
    "        return \"\"\n",
    "    return artist_string.split(\",\")[0].strip()\n",
    "\n",
    "def update_similar_artists(liked_path: str, \n",
    "                         albums_path: str, \n",
    "                         output_path: str, \n",
    "                         api_key: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Update the similar artists database with new artists from liked playlists.\n",
    "    Returns the complete DataFrame of artists and their similar artists.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading existing and new data...\")\n",
    "    \n",
    "    # Load existing similar artists data\n",
    "    existing_data: Dict[str, List[str]] = {}\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        existing_data = dict(zip(existing_df['Artist'], existing_df['Similar Artists']))\n",
    "        print(f\"Loaded {len(existing_data)} existing artists from database\")\n",
    "    \n",
    "    # Load and process current playlists\n",
    "    df_liked = pd.read_csv(liked_path)\n",
    "    df_albums = pd.read_csv(albums_path)\n",
    "    \n",
    "    # Extract and combine primary artists\n",
    "    current_artists = set(\n",
    "        pd.concat([\n",
    "            df_liked['Artist Name(s)'].apply(extract_primary_artist),\n",
    "            df_albums['Artist Name(s)'].apply(extract_primary_artist)\n",
    "        ]).unique()\n",
    "    )\n",
    "    current_artists.discard(\"\")  # Remove empty strings\n",
    "    \n",
    "    # Find new artists not in existing data\n",
    "    new_artists = current_artists - set(existing_data.keys())\n",
    "    print(f\"Found {len(new_artists)} new artists to process\")\n",
    "    \n",
    "    if not new_artists:\n",
    "        print(\"No new artists to process. Database is up to date!\")\n",
    "        # Create and return DataFrame even if no updates\n",
    "        return pd.DataFrame({\n",
    "            'Artist': list(existing_data.keys()),\n",
    "            'Similar Artists': list(existing_data.values())\n",
    "        })\n",
    "    \n",
    "    # Initialize LastFM API client\n",
    "    api = LastFMAPI(api_key)\n",
    "    \n",
    "    # Process artists with concurrent requests\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(api.get_similar_artists, artist): artist \n",
    "            for artist in new_artists\n",
    "        }\n",
    "        \n",
    "        # Show progress bar while processing\n",
    "        for future in tqdm(as_completed(future_to_artist), \n",
    "                         total=len(future_to_artist),\n",
    "                         desc=\"Fetching similar artists\"):\n",
    "            artist = future_to_artist[future]\n",
    "            similar_artists = future.result()\n",
    "            results[artist] = ', '.join(similar_artists)\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    combined_data = {**existing_data, **results}\n",
    "    \n",
    "    # Create DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        'Artist': list(combined_data.keys()),\n",
    "        'Similar Artists': list(combined_data.values())\n",
    "    })\n",
    "    \n",
    "    # Save updated data\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    print(f\"Successfully updated database with {len(new_artists)} new artists\")\n",
    "    print(f\"Total artists in database: {len(combined_data)}\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "    LIKED_PATH = \"data/liked.csv\"\n",
    "    ALBUMS_PATH = \"data/liked_albums.csv\"\n",
    "    OUTPUT_PATH = \"data/liked_artists_only_similar.csv\"\n",
    "    \n",
    "    # Run the update and get the DataFrame\n",
    "    df_liked_similar = update_similar_artists(\n",
    "        LIKED_PATH, \n",
    "        ALBUMS_PATH, \n",
    "        OUTPUT_PATH, \n",
    "        API_KEY\n",
    "    )\n",
    "    \n",
    "    # Now df_liked_similar is ready to use\n",
    "    print(\"\\nFirst few rows of the similar artists DataFrame:\")\n",
    "    print(df_liked_similar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b978abe-0086-4608-bbe9-a45c5591a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sampa the Great</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spillage Village</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>serpentwithfeet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Omar Apollo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Urban Jams United</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>Cate Le Bon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>GAYLE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Artist Similar Artists\n",
       "0                  RY X             NaN\n",
       "22      Sampa the Great             NaN\n",
       "30     Spillage Village             NaN\n",
       "45      serpentwithfeet             NaN\n",
       "76          Omar Apollo             NaN\n",
       "...                 ...             ...\n",
       "2041  Urban Jams United             NaN\n",
       "2043              JAY-Z             NaN\n",
       "2045     PinkPantheress             NaN\n",
       "2067        Cate Le Bon             NaN\n",
       "2106              GAYLE             NaN\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03340fb2-3681-4654-8d18-c0f4b2c4397a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncommented out for now because i might want to use this site for producers,\\nand other things. Good to have a sample code that worked.\\n\\n# Load the existing CSV file into a DataFrame\\ndf_liked_similar = pd.read_csv(\\'data/liked_artists_only_similar.csv\\')\\n\\n# Filter out the artists with missing similar artists (where \\'Similar Artists\\' is NaN)\\ndf_missing_similar = df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]\\n\\n# Function to fetch similar artists using ListenBrainz\\ndef get_similar_artists(artist_mbid):\\n    api_url = f\\'https://labs.api.listenbrainz.org/similar-artists?artist_mbid={artist_mbid}&algorithm=session_based_days_9000_session_300_contribution_5_threshold_15_limit_50_skip_30\\'\\n    try:\\n        response = requests.get(api_url)\\n        if response.status_code == 200:\\n            data = response.json()\\n            similar_artists = [artist[\\'artist_name\\'] for artist in data.get(\\'payload\\', {}).get(\\'artists\\', [])]\\n            return \\', \\'.join(similar_artists)\\n        else:\\n            print(f\"Failed to fetch data for MBID {artist_mbid}: {response.status_code}\")\\n            return None\\n    except Exception as e:\\n        print(f\"Error fetching data for MBID {artist_mbid}: {str(e)}\")\\n        return None\\n\\n# Function to get MBID from artist name using MusicBrainz API\\ndef get_artist_mbid(artist_name):\\n    api_url = f\\'https://musicbrainz.org/ws/2/artist?query={artist_name}&limit=1&fmt=json\\'\\n    try:\\n        response = requests.get(api_url, headers={\\'User-Agent\\': \\'YourApp/1.0\\'})\\n        if response.status_code == 200:\\n            data = response.json()\\n            if data.get(\\'artists\\'):\\n                return data[\\'artists\\'][0][\\'id\\']  # Return the first matching MBID\\n        else:\\n            print(f\"Failed to fetch MBID for {artist_name}: {response.status_code}\")\\n            return None\\n    except Exception as e:\\n        print(f\"Error fetching MBID for {artist_name}: {str(e)}\")\\n        return None\\n\\n# To avoid overwhelming the API, we will process a batch at a time\\nbatch_size = 5\\ndelay_seconds = 3  # Delay in seconds between requests\\n\\n# Iterate over missing artists in batches\\nupdated_rows = []\\nfor i, row in df_missing_similar.iterrows():\\n    artist_name = row[\\'Artist\\']\\n    artist_mbid = get_artist_mbid(artist_name)\\n    \\n    if artist_mbid:\\n        similar_artists = get_similar_artists(artist_mbid)\\n        updated_rows.append((i, similar_artists))\\n    else:\\n        updated_rows.append((i, None))\\n    \\n    # Wait for the specified delay before the next request\\n    if (i + 1) % batch_size == 0:\\n        print(f\"Processed {i + 1} artists, pausing for {delay_seconds} seconds...\")\\n        time.sleep(delay_seconds)\\n\\n# Update the \\'Similar Artists\\' column for the rows that were processed\\nfor index, similar_artists in updated_rows:\\n    df_liked_similar.at[index, \\'Similar Artists\\'] = similar_artists\\n\\n# Save the updated DataFrame back to the CSV file\\ndf_liked_similar.to_csv(\\'data/liked_artists_only_similar.csv\\', index=False)\\n\\n# After the loop, you can check if all the missing artists have been filled\\nprint(\"Updated DataFrame:\")\\nprint(df_liked_similar.head())\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "commented out for now because i might want to use this site for producers,\n",
    "and other things. Good to have a sample code that worked.\n",
    "\n",
    "# Load the existing CSV file into a DataFrame\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')\n",
    "\n",
    "# Filter out the artists with missing similar artists (where 'Similar Artists' is NaN)\n",
    "df_missing_similar = df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]\n",
    "\n",
    "# Function to fetch similar artists using ListenBrainz\n",
    "def get_similar_artists(artist_mbid):\n",
    "    api_url = f'https://labs.api.listenbrainz.org/similar-artists?artist_mbid={artist_mbid}&algorithm=session_based_days_9000_session_300_contribution_5_threshold_15_limit_50_skip_30'\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            similar_artists = [artist['artist_name'] for artist in data.get('payload', {}).get('artists', [])]\n",
    "            return ', '.join(similar_artists)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for MBID {artist_mbid}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for MBID {artist_mbid}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to get MBID from artist name using MusicBrainz API\n",
    "def get_artist_mbid(artist_name):\n",
    "    api_url = f'https://musicbrainz.org/ws/2/artist?query={artist_name}&limit=1&fmt=json'\n",
    "    try:\n",
    "        response = requests.get(api_url, headers={'User-Agent': 'YourApp/1.0'})\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get('artists'):\n",
    "                return data['artists'][0]['id']  # Return the first matching MBID\n",
    "        else:\n",
    "            print(f\"Failed to fetch MBID for {artist_name}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching MBID for {artist_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# To avoid overwhelming the API, we will process a batch at a time\n",
    "batch_size = 5\n",
    "delay_seconds = 3  # Delay in seconds between requests\n",
    "\n",
    "# Iterate over missing artists in batches\n",
    "updated_rows = []\n",
    "for i, row in df_missing_similar.iterrows():\n",
    "    artist_name = row['Artist']\n",
    "    artist_mbid = get_artist_mbid(artist_name)\n",
    "    \n",
    "    if artist_mbid:\n",
    "        similar_artists = get_similar_artists(artist_mbid)\n",
    "        updated_rows.append((i, similar_artists))\n",
    "    else:\n",
    "        updated_rows.append((i, None))\n",
    "    \n",
    "    # Wait for the specified delay before the next request\n",
    "    if (i + 1) % batch_size == 0:\n",
    "        print(f\"Processed {i + 1} artists, pausing for {delay_seconds} seconds...\")\n",
    "        time.sleep(delay_seconds)\n",
    "\n",
    "# Update the 'Similar Artists' column for the rows that were processed\n",
    "for index, similar_artists in updated_rows:\n",
    "    df_liked_similar.at[index, 'Similar Artists'] = similar_artists\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df_liked_similar.to_csv('data/liked_artists_only_similar.csv', index=False)\n",
    "\n",
    "# After the loop, you can check if all the missing artists have been filled\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df_liked_similar.head())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392df38d-c607-4196-bf48-ab735338849e",
   "metadata": {},
   "source": [
    "## Quick Glance at our Refreshed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929ec508-7fe2-43be-ac08-f08bb640aca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0AAXgVpk3VBbjcwNBNt3Iz</td>\n",
       "      <td>Hope You Find What You're Looking For</td>\n",
       "      <td>Out Of The Blue</td>\n",
       "      <td>Morgan Saint</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>190834</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-16T17:59:46Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.898</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.696</td>\n",
       "      <td>104.993</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5FfGYE5eTM2K1Si4ucy2XC</td>\n",
       "      <td>Monuments &amp; Bricks</td>\n",
       "      <td>Poison</td>\n",
       "      <td>CATHEDRALE</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>243029</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-15T22:44:31Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.327</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.234</td>\n",
       "      <td>137.635</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6J1qJGfbB31D0WxiehfcoV</td>\n",
       "      <td>Did You Lose Your Heart</td>\n",
       "      <td>Out Of The Blue</td>\n",
       "      <td>Morgan Saint</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>244143</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-15T19:50:54Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.904</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.914</td>\n",
       "      <td>94.995</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5Iel8B8LQe12lEofB20OTp</td>\n",
       "      <td>Over and Over</td>\n",
       "      <td>Heartache in Room 14</td>\n",
       "      <td>The Altons</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>228933</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-15T18:46:58Z</td>\n",
       "      <td>retro soul</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.260</td>\n",
       "      <td>115.136</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5sZ5AyRhjKSYAh7vqNJXuH</td>\n",
       "      <td>Victory Lap</td>\n",
       "      <td>Victory Lap</td>\n",
       "      <td>Valley Palace</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>187629</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-12T16:12:28Z</td>\n",
       "      <td>dream pop</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.695</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.590</td>\n",
       "      <td>152.014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID                             Track Name  \\\n",
       "0  0AAXgVpk3VBbjcwNBNt3Iz  Hope You Find What You're Looking For   \n",
       "1  5FfGYE5eTM2K1Si4ucy2XC                     Monuments & Bricks   \n",
       "2  6J1qJGfbB31D0WxiehfcoV                Did You Lose Your Heart   \n",
       "3  5Iel8B8LQe12lEofB20OTp                          Over and Over   \n",
       "4  5sZ5AyRhjKSYAh7vqNJXuH                            Victory Lap   \n",
       "\n",
       "             Album Name Artist Name(s) Release Date  Duration (ms)  \\\n",
       "0       Out Of The Blue   Morgan Saint   2025-02-14         190834   \n",
       "1                Poison     CATHEDRALE   2025-02-14         243029   \n",
       "2       Out Of The Blue   Morgan Saint   2025-02-14         244143   \n",
       "3  Heartache in Room 14     The Altons   2025-02-14         228933   \n",
       "4           Victory Lap  Valley Palace   2022-11-29         187629   \n",
       "\n",
       "   Popularity  Added By              Added At      Genres  ... Key  Loudness  \\\n",
       "0          12       NaN  2025-02-16T17:59:46Z         NaN  ...   6    -8.898   \n",
       "1           9       NaN  2025-02-15T22:44:31Z   post-punk  ...   9    -7.327   \n",
       "2          11       NaN  2025-02-15T19:50:54Z         NaN  ...   0    -7.904   \n",
       "3          23       NaN  2025-02-15T18:46:58Z  retro soul  ...   6    -6.220   \n",
       "4          24       NaN  2025-02-12T16:12:28Z   dream pop  ...   2    -6.695   \n",
       "\n",
       "   Mode  Speechiness  Acousticness  Instrumentalness  Liveness  Valence  \\\n",
       "0     1       0.0372      0.722000          0.001540     0.092    0.696   \n",
       "1     1       0.0322      0.000036          0.003600     0.264    0.234   \n",
       "2     1       0.0367      0.360000          0.007430     0.115    0.914   \n",
       "3     1       0.0261      0.780000          0.000021     0.162    0.260   \n",
       "4     1       0.0283      0.024000          0.658000     0.262    0.590   \n",
       "\n",
       "     Tempo  Time Signature  \n",
       "0  104.993               4  \n",
       "1  137.635               4  \n",
       "2   94.995               4  \n",
       "3  115.136               3  \n",
       "4  152.014               4  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80b875a-ebab-472e-82b5-85568f036a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0UOeq7bSskoJa4cJaJOmFS</td>\n",
       "      <td>Ticking</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>186949</td>\n",
       "      <td>31</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.291</td>\n",
       "      <td>175.574</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02bA26OEe0nNFyE3YcNx4K</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>207409</td>\n",
       "      <td>46</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.00435</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.0877</td>\n",
       "      <td>0.189</td>\n",
       "      <td>88.581</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7IPDhCIQlpvxVxtC1Q7Jq4</td>\n",
       "      <td>Cathedral</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>179694</td>\n",
       "      <td>30</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.00978</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.397</td>\n",
       "      <td>119.056</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65fPteG9ctHt2rrJxlbMr8</td>\n",
       "      <td>Shaking Their Hands</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>222489</td>\n",
       "      <td>28</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.551</td>\n",
       "      <td>89.485</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4UgkFdXpJD0fhw06BMk0bz</td>\n",
       "      <td>Adore Adore Adore</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>157766</td>\n",
       "      <td>36</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.402</td>\n",
       "      <td>176.054</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID           Track Name      Album Name Artist Name(s)  \\\n",
       "0  0UOeq7bSskoJa4cJaJOmFS              Ticking  Letter to Self        SPRINTS   \n",
       "1  02bA26OEe0nNFyE3YcNx4K                Heavy  Letter to Self        SPRINTS   \n",
       "2  7IPDhCIQlpvxVxtC1Q7Jq4            Cathedral  Letter to Self        SPRINTS   \n",
       "3  65fPteG9ctHt2rrJxlbMr8  Shaking Their Hands  Letter to Self        SPRINTS   \n",
       "4  4UgkFdXpJD0fhw06BMk0bz    Adore Adore Adore  Letter to Self        SPRINTS   \n",
       "\n",
       "  Release Date  Duration (ms)  Popularity                   Added By  \\\n",
       "0   2024-01-05         186949          31  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "1   2024-01-05         207409          46  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "2   2024-01-05         179694          30  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "3   2024-01-05         222489          28  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "4   2024-01-05         157766          36  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "\n",
       "               Added At     Genres  ...   Key  Loudness  Mode  Speechiness  \\\n",
       "0  2025-01-29T00:53:10Z  post-punk  ...  11.0    -6.490   1.0       0.3440   \n",
       "1  2025-01-29T00:53:10Z  post-punk  ...  11.0    -5.925   1.0       0.0591   \n",
       "2  2025-01-29T00:53:10Z  post-punk  ...   7.0    -6.231   1.0       0.0473   \n",
       "3  2025-01-29T00:53:10Z  post-punk  ...   4.0    -5.658   0.0       0.0533   \n",
       "4  2025-01-29T00:53:10Z  post-punk  ...   4.0    -4.401   0.0       0.2570   \n",
       "\n",
       "   Acousticness  Instrumentalness  Liveness  Valence    Tempo  Time Signature  \n",
       "0       0.02500          0.076500    0.0934    0.291  175.574             4.0  \n",
       "1       0.00435          0.000738    0.0877    0.189   88.581             4.0  \n",
       "2       0.00978          0.002700    0.0887    0.397  119.056             4.0  \n",
       "3       0.19900          0.108000    0.1330    0.551   89.485             4.0  \n",
       "4       0.01070          0.000107    0.1010    0.402  176.054             4.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liked Albums in Recent Years\n",
    "df_fav_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0d6345-80d1-4b33-a4c5-10b1e138bbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54KEm0VI9i3ic7VHHKHKRx</td>\n",
       "      <td>¿Cómo Así?</td>\n",
       "      <td>ORQUÍDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>169654</td>\n",
       "      <td>56</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.04170</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.379</td>\n",
       "      <td>135.985</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5mVkTPlTPxlQOn7kEvuM3j</td>\n",
       "      <td>Me Pongo Loca</td>\n",
       "      <td>ORQUÍDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>177815</td>\n",
       "      <td>53</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.03710</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.407</td>\n",
       "      <td>114.999</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6XaJfhwof7qIgbbXO5tIQI</td>\n",
       "      <td>Igual Que Un Ángel (with Peso Pluma)</td>\n",
       "      <td>ORQUÍDEAS</td>\n",
       "      <td>Kali Uchis,Peso Pluma</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>260370</td>\n",
       "      <td>75</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>corrido,corridos tumbados,corridos bélicos,mús...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.482</td>\n",
       "      <td>108.001</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52x8HIGuk1gGTlvO8CuLNS</td>\n",
       "      <td>Pensamientos Intrusivos</td>\n",
       "      <td>ORQUÍDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>192027</td>\n",
       "      <td>60</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.511</td>\n",
       "      <td>119.994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3RleMgz4iO0BNezGdSxDnY</td>\n",
       "      <td>Diosa</td>\n",
       "      <td>ORQUÍDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>156037</td>\n",
       "      <td>58</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.06750</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.698</td>\n",
       "      <td>107.994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID                            Track Name Album Name  \\\n",
       "0  54KEm0VI9i3ic7VHHKHKRx                            ¿Cómo Así?  ORQUÍDEAS   \n",
       "1  5mVkTPlTPxlQOn7kEvuM3j                         Me Pongo Loca  ORQUÍDEAS   \n",
       "2  6XaJfhwof7qIgbbXO5tIQI  Igual Que Un Ángel (with Peso Pluma)  ORQUÍDEAS   \n",
       "3  52x8HIGuk1gGTlvO8CuLNS               Pensamientos Intrusivos  ORQUÍDEAS   \n",
       "4  3RleMgz4iO0BNezGdSxDnY                                 Diosa  ORQUÍDEAS   \n",
       "\n",
       "          Artist Name(s) Release Date  Duration (ms)  Popularity  \\\n",
       "0             Kali Uchis   2024-01-12         169654          56   \n",
       "1             Kali Uchis   2024-01-12         177815          53   \n",
       "2  Kali Uchis,Peso Pluma   2024-01-12         260370          75   \n",
       "3             Kali Uchis   2024-01-12         192027          60   \n",
       "4             Kali Uchis   2024-01-12         156037          58   \n",
       "\n",
       "                    Added By              Added At  \\\n",
       "0  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "1  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "2  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "3  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "4  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "\n",
       "                                              Genres  ...  Key  Loudness  \\\n",
       "0                                                NaN  ...  6.0    -7.662   \n",
       "1                                                NaN  ...  7.0    -8.680   \n",
       "2  corrido,corridos tumbados,corridos bélicos,mús...  ...  5.0    -5.340   \n",
       "3                                                NaN  ...  9.0    -8.333   \n",
       "4                                                NaN  ...  5.0    -5.518   \n",
       "\n",
       "   Mode  Speechiness  Acousticness  Instrumentalness  Liveness  Valence  \\\n",
       "0   0.0       0.0892       0.04170          0.346000     0.154    0.379   \n",
       "1   0.0       0.0426       0.03710          0.152000     0.106    0.407   \n",
       "2   0.0       0.0320       0.00449          0.000663     0.185    0.482   \n",
       "3   0.0       0.0394       0.57500          0.012900     0.110    0.511   \n",
       "4   0.0       0.0668       0.06750          0.000101     0.078    0.698   \n",
       "\n",
       "     Tempo  Time Signature  \n",
       "0  135.985             4.0  \n",
       "1  114.999             4.0  \n",
       "2  108.001             4.0  \n",
       "3  119.994             4.0  \n",
       "4  107.994             4.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Albums Not Liked in Recent Years\n",
    "df_not_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a190ec91-73e0-40c5-95b4-fc212abd1730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3y0DIcBw075qzj3dOwJ5aL</td>\n",
       "      <td>From The Gods</td>\n",
       "      <td>Food From the Gods</td>\n",
       "      <td>Black Milk,Fat Ray</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>88678</td>\n",
       "      <td>26</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-02-14T06:13:23Z</td>\n",
       "      <td>alternative hip hop,underground hip hop</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.559</td>\n",
       "      <td>89.450</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6TR2jKnq9yFwk3oqKUTnWp</td>\n",
       "      <td>ELDERBERRY</td>\n",
       "      <td>Food From the Gods</td>\n",
       "      <td>Black Milk,Fat Ray</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>189000</td>\n",
       "      <td>27</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-02-14T06:13:23Z</td>\n",
       "      <td>alternative hip hop,underground hip hop</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.634</td>\n",
       "      <td>81.092</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6UC2W5IR7lx3BQGsWf4qD3</td>\n",
       "      <td>Talcum</td>\n",
       "      <td>Food From the Gods</td>\n",
       "      <td>Black Milk,Fat Ray</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>156144</td>\n",
       "      <td>27</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-02-14T06:13:23Z</td>\n",
       "      <td>alternative hip hop,underground hip hop</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.628</td>\n",
       "      <td>79.591</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7HSjLESxFyDRrmq6AdGkJh</td>\n",
       "      <td>CANE</td>\n",
       "      <td>Food From the Gods</td>\n",
       "      <td>Black Milk,Fat Ray,Guilty Simpson</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>149010</td>\n",
       "      <td>26</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-02-14T06:13:23Z</td>\n",
       "      <td>alternative hip hop,underground hip hop,boom bap</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-6.045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.719</td>\n",
       "      <td>90.831</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1XZqPCN9JU3xtnS0aC72UC</td>\n",
       "      <td>Just Say No</td>\n",
       "      <td>Food From the Gods</td>\n",
       "      <td>Black Milk,Fat Ray,Danny Brown</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>201276</td>\n",
       "      <td>31</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-02-14T06:13:23Z</td>\n",
       "      <td>alternative hip hop,underground hip hop,experi...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-8.114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.907</td>\n",
       "      <td>90.020</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID     Track Name          Album Name  \\\n",
       "0  3y0DIcBw075qzj3dOwJ5aL  From The Gods  Food From the Gods   \n",
       "1  6TR2jKnq9yFwk3oqKUTnWp     ELDERBERRY  Food From the Gods   \n",
       "2  6UC2W5IR7lx3BQGsWf4qD3         Talcum  Food From the Gods   \n",
       "3  7HSjLESxFyDRrmq6AdGkJh           CANE  Food From the Gods   \n",
       "4  1XZqPCN9JU3xtnS0aC72UC    Just Say No  Food From the Gods   \n",
       "\n",
       "                      Artist Name(s) Release Date  Duration (ms)  Popularity  \\\n",
       "0                 Black Milk,Fat Ray   2025-02-13          88678          26   \n",
       "1                 Black Milk,Fat Ray   2025-02-13         189000          27   \n",
       "2                 Black Milk,Fat Ray   2025-02-13         156144          27   \n",
       "3  Black Milk,Fat Ray,Guilty Simpson   2025-02-13         149010          26   \n",
       "4     Black Milk,Fat Ray,Danny Brown   2025-02-13         201276          31   \n",
       "\n",
       "    Added By              Added At  \\\n",
       "0  jaytroymo  2025-02-14T06:13:23Z   \n",
       "1  jaytroymo  2025-02-14T06:13:23Z   \n",
       "2  jaytroymo  2025-02-14T06:13:23Z   \n",
       "3  jaytroymo  2025-02-14T06:13:23Z   \n",
       "4  jaytroymo  2025-02-14T06:13:23Z   \n",
       "\n",
       "                                              Genres  ...   Key  Loudness  \\\n",
       "0            alternative hip hop,underground hip hop  ...   9.0    -8.414   \n",
       "1            alternative hip hop,underground hip hop  ...   2.0    -7.407   \n",
       "2            alternative hip hop,underground hip hop  ...  11.0    -6.015   \n",
       "3   alternative hip hop,underground hip hop,boom bap  ...   8.0    -6.045   \n",
       "4  alternative hip hop,underground hip hop,experi...  ...   4.0    -8.114   \n",
       "\n",
       "   Mode  Speechiness  Acousticness  Instrumentalness  Liveness  Valence  \\\n",
       "0   0.0        0.408         0.449          0.118000    0.3760    0.559   \n",
       "1   1.0        0.347         0.454          0.004310    0.0916    0.634   \n",
       "2   0.0        0.240         0.660          0.000005    0.2150    0.628   \n",
       "3   1.0        0.280         0.219          0.000000    0.4430    0.719   \n",
       "4   0.0        0.206         0.737          0.261000    0.3630    0.907   \n",
       "\n",
       "    Tempo  Time Signature  \n",
       "0  89.450             3.0  \n",
       "1  81.092             4.0  \n",
       "2  79.591             4.0  \n",
       "3  90.831             4.0  \n",
       "4  90.020             4.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New Music Friday Playlist\n",
    "df_nmf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64bfbf76-1649-4542-b001-2fedd527ecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Faim</td>\n",
       "      <td>Oh The Larceny, City Wolf, Random Hero, needsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melody Lake</td>\n",
       "      <td>Ian Wong, Limelight Glow, Slow Rising Hope, Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liza Anne</td>\n",
       "      <td>Miya Folick, Torres, Billie Marten, Pom Pom Sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Kinks</td>\n",
       "      <td>Dave Davies, The Who, Small Faces, The Zombies...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Artist                                    Similar Artists\n",
       "0         RY X                                                NaN\n",
       "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...\n",
       "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...\n",
       "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...\n",
       "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar Artists to Recently Played Artists (Last.fm)\n",
    "\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30386-5197-4245-9871-cffbe4952a33",
   "metadata": {},
   "source": [
    "> A quick reminder of the standard columns of a spotify export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a3f0c33-76f1-4d7b-95c3-988b1ca941a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track ID', 'Track Name', 'Album Name', 'Artist Name(s)',\n",
       "       'Release Date', 'Duration (ms)', 'Popularity', 'Added By', 'Added At',\n",
       "       'Genres', 'Record Label', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
       "       'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
       "       'Valence', 'Tempo', 'Time Signature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fe763b3-50c4-474d-8363-a5c41461ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Artist', 'Similar Artists'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25a6b9-e488-4c3a-9e27-4cf15e57c504",
   "metadata": {},
   "source": [
    "### Add Target Labels for Training Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a802d4-ff06-4dab-886d-059ed0ee2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign liked scores before combining\n",
    "df_liked['liked'] = 100\n",
    "df_fav_albums['liked'] = 50\n",
    "df_not_liked['liked'] = 0\n",
    "df_nmf['liked'] = np.nan \n",
    "\n",
    "# Add playlist_origin column before combining\n",
    "df_liked['playlist_origin'] = 'df_liked'\n",
    "df_fav_albums['playlist_origin'] = 'df_fav_albums'\n",
    "df_not_liked['playlist_origin'] = 'df_not_liked'\n",
    "df_nmf['playlist_origin'] = 'df_nmf'\n",
    "df_liked_similar['source'] = 'liked_similar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10e0ba-5881-4cd4-91e0-630063a72dd8",
   "metadata": {},
   "source": [
    "### Check application of the target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4add9e6b-4a3c-46f0-bc43-4bb4215cd97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0    100        df_liked\n",
       "1    100        df_liked\n",
       "2    100        df_liked\n",
       "3    100        df_liked\n",
       "4    100        df_liked"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6cb7c2-b08e-4d00-9cd7-fcea6eec1ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0     50   df_fav_albums\n",
       "1     50   df_fav_albums\n",
       "2     50   df_fav_albums\n",
       "3     50   df_fav_albums\n",
       "4     50   df_fav_albums"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fav_albums[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b72fb6-dac5-4d75-b6fd-b3ca1d8973f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0      0    df_not_liked\n",
       "1      0    df_not_liked\n",
       "2      0    df_not_liked\n",
       "3      0    df_not_liked\n",
       "4      0    df_not_liked"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c75164a9-8182-463f-a450-2534f52aeb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0    NaN          df_nmf\n",
       "1    NaN          df_nmf\n",
       "2    NaN          df_nmf\n",
       "3    NaN          df_nmf\n",
       "4    NaN          df_nmf"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e40fa4a1-a55a-42c6-b3b1-8994b44c3602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Faim</td>\n",
       "      <td>Oh The Larceny, City Wolf, Random Hero, needsh...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melody Lake</td>\n",
       "      <td>Ian Wong, Limelight Glow, Slow Rising Hope, Po...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liza Anne</td>\n",
       "      <td>Miya Folick, Torres, Billie Marten, Pom Pom Sq...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Kinks</td>\n",
       "      <td>Dave Davies, The Who, Small Faces, The Zombies...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Artist                                    Similar Artists  \\\n",
       "0         RY X                                                NaN   \n",
       "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...   \n",
       "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...   \n",
       "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...   \n",
       "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies...   \n",
       "\n",
       "          source  \n",
       "0  liked_similar  \n",
       "1  liked_similar  \n",
       "2  liked_similar  \n",
       "3  liked_similar  \n",
       "4  liked_similar  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar[['Artist', 'Similar Artists', 'source']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44856ee-a472-41f3-8622-01d76e370849",
   "metadata": {},
   "source": [
    "## Merge The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34bd66a5-2ed8-4eda-b8df-09a5feaa782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_liked, df_fav_albums, df_not_liked, df_nmf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f9b1007-6bfe-429b-bf10-5de0241f9e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13319, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How Large is the Dataset, Now?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035bf83-b7da-4fbb-bc26-f1ed816a5798",
   "metadata": {},
   "source": [
    "#### Remove the Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "861de4ff-4fb7-421b-8923-419d750172bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11053, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates: Keep the highest 'liked' score (100 > 50)\n",
    "df = df.sort_values(by='liked', ascending=False)  # Ensures 100-rated songs come first\n",
    "df = df.drop_duplicates(subset=['Track Name', 'Artist Name(s)'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32b202b5-4145-4b67-96fa-d7a9642088be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track ID', 'Track Name', 'Album Name', 'Artist Name(s)',\n",
       "       'Release Date', 'Duration (ms)', 'Popularity', 'Added By', 'Added At',\n",
       "       'Genres', 'Record Label', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
       "       'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
       "       'Valence', 'Tempo', 'Time Signature', 'liked', 'playlist_origin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #Checking to remind myself what is all available to drop, keep seperate as metadata, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2580a-e10a-4d8f-a9fc-258a2777d37f",
   "metadata": {},
   "source": [
    "#### Drop columns that won't help the model (Track ID, Added By, Added At, Time Signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9a1551b-d6a6-4ff4-b5f3-f333f2e4e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Track ID', 'Added By', 'Added At', 'Time Signature', 'Key', 'Mode',\n",
    "                'Loudness', 'Speechiness', 'Liveness', 'Valence'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658750-d956-442d-99ed-2dca4323ec47",
   "metadata": {},
   "source": [
    "#### Getting missing Genres (of which Spotify is \"Spotty\" at best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "427b250a-eb92-4eb4-a0a1-c20f0550eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total artists with missing genres: 1135\n",
      "Total new artists with missing genres: 2\n",
      "\n",
      "Export complete! Processed 2 new artists.\n"
     ]
    }
   ],
   "source": [
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        \n",
    "    def _make_request(self, params: dict) -> dict:\n",
    "        try:\n",
    "            # Handle rate limit by checking headers for remaining requests\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Check for rate limit info in the response headers\n",
    "            remaining = int(response.headers.get('X-RateLimit-Remaining', 1))\n",
    "            if remaining == 0:\n",
    "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
    "                wait_time = reset_time - int(datetime.now().timestamp())\n",
    "                print(f\"Rate limit hit, waiting for {wait_time} seconds...\")\n",
    "                sleep(wait_time + 1)  # wait for the reset time plus 1 second for safety\n",
    "                response = requests.get(self.base_url, params=params)  # retry after waiting\n",
    "                response.raise_for_status()\n",
    "\n",
    "            return response.json()\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed: {e}\")\n",
    "            if response.status_code == 429:\n",
    "                print(\"Rate limit exceeded, increasing delay.\")\n",
    "                self.rate_limit_delay *= 2\n",
    "            return None\n",
    "\n",
    "    def get_artist_tags(self, artist_name: str, limit: int = 5) -> List[str]:\n",
    "        params = {\n",
    "            'method': 'artist.getTopTags',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'format': 'json',\n",
    "            'limit': limit\n",
    "        }\n",
    "        data = self._make_request(params)\n",
    "        if data and 'toptags' in data:\n",
    "            return [tag['name'] for tag in data['toptags'].get('tag', [])]\n",
    "        return []\n",
    "\n",
    "def export_artist_tags(api_key: str, unique_artists: List[str], output_file: str = 'data/missing_genres.csv'):\n",
    "    api = LastFMAPI(api_key)\n",
    "\n",
    "    # Load existing data if the file exists\n",
    "    existing_data = {}\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                existing_data[row['Artist']] = row['Tags']\n",
    "\n",
    "    # Identify new artists not in the existing data\n",
    "    new_artists = [artist for artist in unique_artists if artist not in existing_data]\n",
    "    print(f\"Total new artists with missing genres: {len(new_artists)}\")\n",
    "\n",
    "    if not new_artists:\n",
    "        print(\"No new missing artists to process.\")\n",
    "        return\n",
    "\n",
    "    # Using ThreadPoolExecutor to parallelize API requests\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers based on your needs\n",
    "        future_to_artist = {executor.submit(api.get_artist_tags, artist): artist for artist in new_artists}\n",
    "        \n",
    "        try:\n",
    "            with open(output_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=['Artist', 'Tags'])\n",
    "                if not os.path.exists(output_file):  # Write header only if file doesn't exist\n",
    "                    writer.writeheader()\n",
    "                \n",
    "                for i, future in enumerate(as_completed(future_to_artist), 1):\n",
    "                    artist = future_to_artist[future]\n",
    "                    tags = future.result()\n",
    "                    \n",
    "                    # Ensure only the top 5 tags are saved\n",
    "                    top_5_tags = tags[:5]\n",
    "                    writer.writerow({\n",
    "                        'Artist': artist,\n",
    "                        'Tags': ', '.join(top_5_tags)  # Join only the top 5 tags\n",
    "                    })\n",
    "\n",
    "                    # Print progress in increments of 100\n",
    "                    if i % 100 == 0:\n",
    "                        print(f\"Processed tags for {i} new artists\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Fatal error during export: {e}\")\n",
    "    \n",
    "    print(f\"\\nExport complete! Processed {len(new_artists)} new artists.\")\n",
    "\n",
    "# Extract first artist if multiple are listed\n",
    "df['Primary Artist'] = df['Artist Name(s)'].apply(lambda x: x.split(',')[0] if pd.notna(x) else x)\n",
    "\n",
    "# Get unique artists with missing genres\n",
    "artists_missing_genres = df[df['Genres'].isna()]['Primary Artist'].unique()\n",
    "print(f\"Total artists with missing genres: {len(artists_missing_genres)}\")\n",
    "\n",
    "# Fetch tags for missing artists\n",
    "API_KEY = '74a510ecc9fc62bf3e0edc6adc2e99f9'\n",
    "export_artist_tags(API_KEY, artists_missing_genres, output_file='data/missing_genres.csv')\n",
    "\n",
    "# Load the fetched tags\n",
    "missing_genres_df = pd.read_csv('data/missing_genres.csv')\n",
    "\n",
    "# Merge with the original dataframe\n",
    "df = df.merge(\n",
    "    missing_genres_df,\n",
    "    how='left',\n",
    "    left_on='Primary Artist',\n",
    "    right_on='Artist',\n",
    "    suffixes=('', '_tags')  # Add a suffix to overlapping columns from missing_genres_df\n",
    ")\n",
    "\n",
    "# Fill missing genres in the original 'Genres' column\n",
    "df['Genres'] = df['Genres'].fillna(df['Tags'])\n",
    "\n",
    "# Drop the temporary 'Tags' and 'Artist' columns if no longer needed\n",
    "df.drop(columns=['Tags', 'Artist'], inplace=True)\n",
    "\n",
    "# Now `df` is updated in memory with the new genre data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e2fb3b7-348c-4d1a-abd2-29710e0c866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Genres' and 'Record Label' with 'Unknown'\n",
    "df['Genres'] = df['Genres'].fillna('Unknown')\n",
    "df['Record Label'] = df['Record Label'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff07c-0b26-47bf-af09-6c87b741ba13",
   "metadata": {},
   "source": [
    "#### Handle missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34d7d185-71c3-4aa3-8b81-8920a76aa070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track Name            0\n",
       "Album Name            0\n",
       "Artist Name(s)        0\n",
       "Release Date          0\n",
       "Duration (ms)         0\n",
       "Popularity            0\n",
       "Genres                0\n",
       "Record Label          0\n",
       "Danceability          8\n",
       "Energy                8\n",
       "Acousticness          8\n",
       "Instrumentalness      8\n",
       "Tempo                 8\n",
       "liked               383\n",
       "playlist_origin       0\n",
       "Primary Artist        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b2e0e6e-7b06-452d-8999-c96b5fcd8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls in any column except 'liked'\n",
    "df = df[df.drop(columns=['liked']).notna().all(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11d89341-0210-4136-bd93-66070a896e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track Name            0\n",
       "Album Name            0\n",
       "Artist Name(s)        0\n",
       "Release Date          0\n",
       "Duration (ms)         0\n",
       "Popularity            0\n",
       "Genres                0\n",
       "Record Label          0\n",
       "Danceability          0\n",
       "Energy                0\n",
       "Acousticness          0\n",
       "Instrumentalness      0\n",
       "Tempo                 0\n",
       "liked               382\n",
       "playlist_origin       0\n",
       "Primary Artist        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c803a7f-4ea3-431f-8c62-54b6801f8416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11045, 16)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4860391-1274-4020-bd0a-8cca3608576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist Origin Counts:\n",
      "playlist_origin\n",
      "df_fav_albums    5334\n",
      "df_liked         4128\n",
      "df_not_liked     1201\n",
      "df_nmf            382\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many of each 'playlist_origin' are in the df dataset\n",
    "playlist_origin_counts = df['playlist_origin'].value_counts()\n",
    "\n",
    "print(\"Playlist Origin Counts:\")\n",
    "print(playlist_origin_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef584c69-80fb-4a3c-9631-e0e9edcb042a",
   "metadata": {},
   "source": [
    "## Target Encoding Record Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122a46b-a3a6-4320-87d4-51ec9e1503ed",
   "metadata": {},
   "source": [
    "Record labels are currently having an outsized influence on our model, making up 48% of feature importance (at the time of this addition to the model). This is mainly due to the target encoding being too granular, with hundreds of individual labels. To address this, we're grouping labels by size and frequency first. This helps reduce the risk of overfitting to smaller labels, creates more meaningful categories based on their reach and influence, and makes it easier to handle rare or lesser-known labels without distorting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ad58690-f119-4e18-be12-8693f9fc0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Category Distribution:\n",
      "Label_Category\n",
      "Large Label     8688\n",
      "Medium Label    1394\n",
      "Small Label      820\n",
      "Unknown/DIY      143\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of Large Labels: ['Anti/Epitaph', 'Loma Vista Recordings', 'Columbia', 'Mom+Pop', 'Dead Oceans']\n",
      "\n",
      "Sample of encoded values:\n",
      "  Label_Category  Label_Category_encoded  liked\n",
      "0   Medium Label               82.183174  100.0\n",
      "1    Large Label               57.356399  100.0\n",
      "2    Large Label               57.356399  100.0\n",
      "3    Large Label               57.356399  100.0\n",
      "4    Large Label               57.356399  100.0\n"
     ]
    }
   ],
   "source": [
    "def categorize_labels_by_size(df):\n",
    "    # Count number of tracks per label\n",
    "    label_counts = df[df['playlist_origin'] != 'df_nmf']['Record Label'].value_counts()\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    p75 = label_counts.quantile(0.75)\n",
    "    p25 = label_counts.quantile(0.25)\n",
    "    \n",
    "    # Create category mapping\n",
    "    label_categories = {}\n",
    "    for label, count in label_counts.items():\n",
    "        if count >= p75:\n",
    "            label_categories[label] = 'Large Label'\n",
    "        elif count <= p25:\n",
    "            label_categories[label] = 'Small Label'\n",
    "        else:\n",
    "            label_categories[label] = 'Medium Label'\n",
    "    \n",
    "    # Map unknown labels to 'Unknown/DIY'\n",
    "    df['Label_Category'] = df['Record Label'].map(label_categories).fillna('Unknown/DIY')\n",
    "    \n",
    "    # Print some statistics about the categorization\n",
    "    print(\"\\nLabel Category Distribution:\")\n",
    "    print(df['Label_Category'].value_counts())\n",
    "    print(\"\\nSample of Large Labels:\", \n",
    "          list(label for label, count in label_counts.items() if count >= p75)[:5])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def target_encode_categories(df, column, target, smoothing=100):\n",
    "    # Separate out df_nmf to ensure it's never used in encoding\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    mean_target = df_train[target].mean()\n",
    "    \n",
    "    # Calculate encoding values for each category\n",
    "    label_means = df_train.groupby(column)[target].mean()\n",
    "    label_counts = df_train[column].value_counts()\n",
    "    smoothed_values = (label_means * label_counts + mean_target * smoothing) / (label_counts + smoothing)\n",
    "    \n",
    "    # Map with a fallback to the overall mean\n",
    "    df[column + '_encoded'] = df[column].map(smoothed_values).fillna(mean_target)\n",
    "    return df\n",
    "\n",
    "# Apply the categorization and encoding\n",
    "df = categorize_labels_by_size(df)\n",
    "df = target_encode_categories(df, 'Label_Category', 'liked', smoothing=100)\n",
    "\n",
    "# Print sample of results\n",
    "print(\"\\nSample of encoded values:\")\n",
    "print(df[['Label_Category', 'Label_Category_encoded', 'liked']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e14d4-ae08-4cf0-bc7c-e78f0aa26bca",
   "metadata": {},
   "source": [
    "## Artists with Missing Genres (Last.fm to the rescue!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67598ab-44f6-4d23-a30c-6ceedf2c1de7",
   "metadata": {},
   "source": [
    "> I noticed in the data previews that one of the common genres imported from last.fm was 'seen live', which I take to meen a lot of last.fm users have seen that artist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eccb97b-cd24-4928-ab57-7f77f311f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'seen live' from the 'Genres' column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: ', '.join([genre for genre in x.split(', ') if genre != 'seen live']) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275ff43-c4a4-4a7a-acb7-d5c74a80285e",
   "metadata": {},
   "source": [
    "## Target Encode Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6b1f54f-259b-46aa-826e-df7fa3d3596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Genres  Genres_encoded  \\\n",
      "0        electronic, indie, pop, chill, experimental       64.012642   \n",
      "1  indie, folk, indie pop, british, female vocalists       69.553807   \n",
      "2            indie rock, dream pop, indie, indie pop       67.790130   \n",
      "3  indie, folk, indie pop, british, female vocalists       69.553807   \n",
      "4  indie, folk, indie pop, british, female vocalists       69.553807   \n",
      "\n",
      "   is_unknown_genre  liked playlist_origin  \n",
      "0                 0  100.0        df_liked  \n",
      "1                 0  100.0        df_liked  \n",
      "2                 0  100.0        df_liked  \n",
      "3                 0  100.0        df_liked  \n",
      "4                 0  100.0        df_liked  \n"
     ]
    }
   ],
   "source": [
    "# Create a binary indicator column for 'Unknown' genres\n",
    "df['is_unknown_genre'] = (df['Genres'] == 'Unknown').astype(int)\n",
    "\n",
    "# Define the target encoding function\n",
    "def target_encode_multi_genre(df, genre_column, target, smoothing=1, aggregation_method='mean', nmf_fallback=0):\n",
    "    \"\"\"\n",
    "    Target encode a multi-genre column by splitting genres, encoding individually, and aggregating.\n",
    "    Explicitly handles 'Unknown' genres and NMF rows.\n",
    "    \"\"\"\n",
    "    # Separate out df_nmf to ensure it's never used in encoding\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "    # Calculate the global mean of the target variable\n",
    "    global_mean = df_train[target].mean()\n",
    "\n",
    "    # Split genres into individual categories and exclude 'seen live' and 'Unknown'\n",
    "    df_train['split_genres'] = df_train[genre_column].str.split(', ').apply(\n",
    "        lambda x: [genre for genre in x if genre != 'seen live' and genre != 'Unknown'] if isinstance(x, list) else x\n",
    "    )\n",
    "\n",
    "    # Explode the list of genres into separate rows\n",
    "    exploded_genres = df_train.explode('split_genres')\n",
    "\n",
    "    # Calculate target encoding for individual genres\n",
    "    label_means = exploded_genres.groupby('split_genres')[target].mean()\n",
    "    label_counts = exploded_genres['split_genres'].value_counts()\n",
    "\n",
    "    # Calculate smoothed target encoding for individual genres\n",
    "    smoothed_values = (label_means * label_counts + global_mean * smoothing) / (label_counts + smoothing)\n",
    "\n",
    "    # Map the smoothed values back to the exploded genres\n",
    "    exploded_genres['genre_encoded'] = exploded_genres['split_genres'].map(smoothed_values).fillna(global_mean)\n",
    "\n",
    "    # Aggregate encodings for multi-genre rows\n",
    "    if aggregation_method == 'mean':\n",
    "        aggregated_encodings = exploded_genres.groupby(exploded_genres.index)['genre_encoded'].mean()\n",
    "    elif aggregation_method == 'max':\n",
    "        aggregated_encodings = exploded_genres.groupby(exploded_genres.index)['genre_encoded'].max()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported aggregation method: {aggregation_method}\")\n",
    "\n",
    "    # Add the aggregated encodings to the original dataframe\n",
    "    df[genre_column + '_encoded'] = aggregated_encodings\n",
    "\n",
    "    # Handle 'Unknown' genres\n",
    "    is_unknown = df[genre_column] == 'Unknown'\n",
    "    df.loc[is_unknown, genre_column + '_encoded'] = global_mean  # Use global mean for non-NMF rows\n",
    "\n",
    "    # Handle NMF rows with 'Unknown' genres separately\n",
    "    is_nmf = df['playlist_origin'] == 'df_nmf'\n",
    "    df.loc[is_nmf & is_unknown, genre_column + '_encoded'] = nmf_fallback  # Use nmf_fallback for NMF rows\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the target encoding function\n",
    "df = target_encode_multi_genre(df, 'Genres', 'liked', smoothing=100, nmf_fallback=0)\n",
    "\n",
    "# Inspect the results\n",
    "print(df[['Genres', 'Genres_encoded', 'is_unknown_genre', 'liked', 'playlist_origin']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "399d5831-7b8d-4658-8a6b-96df44836fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the genre target encoding, add:\n",
    "def extract_genre_features(genres_str):\n",
    "    genres = genres_str.split(', ')\n",
    "    primary_genre = genres[0]  # First genre often most relevant\n",
    "    return {\n",
    "        'genre_count': len(genres),\n",
    "        'has_location_genre': any(g for g in genres if g.title() in STATES_AND_CITIES),\n",
    "        'primary_genre': primary_genre\n",
    "    }\n",
    "\n",
    "# Add location check (add at top with imports)\n",
    "STATES_AND_CITIES = {'Minnesota', 'Seattle', 'Brooklyn', 'Portland', 'Austin'} # Add more as needed\n",
    "\n",
    "# Apply extraction\n",
    "genre_features = df['Genres'].apply(extract_genre_features).apply(pd.Series)\n",
    "df = pd.concat([df, genre_features], axis=1)\n",
    "\n",
    "# Target encode primary genre\n",
    "df = target_encode_categories(df, 'primary_genre', 'liked', smoothing=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a202887-7b10-4ba6-858c-b52a0d2727b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genres_encoded\n",
       "63.72503    222\n",
       "0.00000      13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Genres'] == 'Unknown']['Genres_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "990cc7ef-4c65-42c0-8cd7-f799aa52a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in Genres_encoded\n",
    "genres_encoded_mean = df['Genres_encoded'].mean()\n",
    "df['Genres_encoded'] = df['Genres_encoded'].fillna(genres_encoded_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb6056-15fe-4dfa-b8b7-9d12b4e6f350",
   "metadata": {},
   "source": [
    "#### Further Examination of Missing Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb359b86-12e7-4553-a8af-0f3e49c97d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Genres by Playlist Origin:\n",
      "playlist_origin\n",
      "df_fav_albums    133\n",
      "df_liked          89\n",
      "df_nmf            13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Which rows still have Unknown Genres\n",
    "unknown_genres = df[df['Genres'] == 'Unknown']\n",
    "\n",
    "# Count the number of 'Unknown' genre tracks from each playlist_origin\n",
    "unknown_genres_origin_counts = unknown_genres['playlist_origin'].value_counts()\n",
    "\n",
    "print(\"Unknown Genres by Playlist Origin:\")\n",
    "print(unknown_genres_origin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84e7d3-24d4-4095-ab40-8fd3941a7e54",
   "metadata": {},
   "source": [
    "##### Getting Rid of Rows Where Genre is Unknown and Playlist Origin is Not df_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7e843cb-99a9-42ae-b356-5ce4a6ddb91b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Rows by Playlist Origin:\n",
      "playlist_origin\n",
      "df_fav_albums    5201\n",
      "df_liked         4039\n",
      "df_not_liked     1201\n",
      "df_nmf            382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Remaining 'Unknown' Genres by Playlist Origin:\n",
      "playlist_origin\n",
      "df_nmf    13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Remaining NMF Tracks with 'Unknown' Genres:\n",
      "                    Track Name             Artist Name(s)  Genres_encoded\n",
      "10674  The Night Comes For You        Last Days of Heaven             0.0\n",
      "10675             Pain Machine        Last Days of Heaven             0.0\n",
      "10677       Before the Sadness  Last Days of Heaven,Almma             0.0\n",
      "10678                 Babygirl  Last Days of Heaven,Almma             0.0\n",
      "10894               Millennium                      Gaiko             0.0\n",
      "10895                 Setagaya                      Gaiko             0.0\n",
      "10896          Misses Euphoria                      Gaiko             0.0\n",
      "10897                  Subdued                      Gaiko             0.0\n",
      "10898                   Martyr                      Gaiko             0.0\n",
      "10899           Ever's Lullaby                      Gaiko             0.0\n",
      "10900                    Crush                      Gaiko             0.0\n",
      "10901                   Weirdo                      Gaiko             0.0\n",
      "10902                   Cocoon                      Gaiko             0.0\n"
     ]
    }
   ],
   "source": [
    "# Keep rows where:\n",
    "# 1. Genres is not 'Unknown', OR\n",
    "# 2. Genres is 'Unknown' and playlist_origin is 'df_nmf'\n",
    "df_filtered = df[~((df['Genres'] == 'Unknown') & (df['playlist_origin'] != 'df_nmf'))]\n",
    "\n",
    "# Verify the result\n",
    "print(\"Remaining Rows by Playlist Origin:\")\n",
    "print(df_filtered['playlist_origin'].value_counts())\n",
    "\n",
    "# Check remaining 'Unknown' genre rows\n",
    "remaining_unknown_genres = df_filtered[df_filtered['Genres'] == 'Unknown']\n",
    "\n",
    "print(\"\\nRemaining 'Unknown' Genres by Playlist Origin:\")\n",
    "print(remaining_unknown_genres['playlist_origin'].value_counts())\n",
    "\n",
    "# Inspect the remaining NMF tracks with 'Unknown' genres\n",
    "unknown_genres_nmf = df_filtered[(df_filtered['Genres'] == 'Unknown') & (df_filtered['playlist_origin'] == 'df_nmf')]\n",
    "\n",
    "print(\"\\nRemaining NMF Tracks with 'Unknown' Genres:\")\n",
    "print(unknown_genres_nmf[['Track Name', 'Artist Name(s)', 'Genres_encoded']])\n",
    "\n",
    "# Save the filtered dataframe to a CSV file (optional)\n",
    "df_filtered.to_csv('data/filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df9122-2225-49b9-b63c-3f9f15f433dc",
   "metadata": {},
   "source": [
    "# Finding How Central an Artist is to My Music Taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "612732d8-7cc2-4527-bcc5-307649e7d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Artist Name(s)  Artist Centrality\n",
      "0   Morgan Saint          46.729154\n",
      "1  Billie Marten          52.044802\n",
      "2     Blondshell          38.560083\n",
      "3  Billie Marten          52.044802\n",
      "4  Billie Marten          52.044802\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for liked artists\n",
    "liked_artists = set(\n",
    "    df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Artist Name(s)']\n",
    "    .str.split(',').explode().str.strip()\n",
    ")\n",
    "G.add_nodes_from(liked_artists, type='liked')\n",
    "\n",
    "# Add nodes for similar artists (from liked)\n",
    "similar_artists_liked = set(\n",
    "    df_liked_similar['Similar Artists']\n",
    "    .dropna()  # Remove NaN values\n",
    "    .str.split(',').explode().str.strip()\n",
    ")\n",
    "G.add_nodes_from(similar_artists_liked, type='similar_liked')\n",
    "\n",
    "# Add edges based on similarity (from liked)\n",
    "for _, row in df_liked_similar.iterrows():\n",
    "    artist = row['Artist']\n",
    "    # Check if Similar Artists is a string before splitting\n",
    "    if isinstance(row['Similar Artists'], str):\n",
    "        similar = row['Similar Artists'].split(', ')\n",
    "        for s in similar:\n",
    "            G.add_edge(artist, s, weight=1.0)\n",
    "\n",
    "# Step 2: Calculate centrality scores\n",
    "centrality_scores = nx.pagerank(G)\n",
    "\n",
    "# Step 3: Map centrality scores back to DataFrame\n",
    "df['Artist Centrality'] = (\n",
    "    df['Artist Name(s)']\n",
    "    .str.split(',').str[0].str.strip()\n",
    "    .map(centrality_scores).fillna(0)\n",
    ")\n",
    "\n",
    "# Normalize centrality scores to 0-100\n",
    "df['Artist Centrality'] = (df['Artist Centrality'] / df['Artist Centrality'].max()) * 100\n",
    "\n",
    "\n",
    "# Check the result\n",
    "print(df[['Artist Name(s)', 'Artist Centrality']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7945566-7ea2-4c1d-8693-81283db3bebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN Similar Artists:\n",
      "                 Artist Similar Artists         source\n",
      "0                  RY X             NaN  liked_similar\n",
      "22      Sampa the Great             NaN  liked_similar\n",
      "30     Spillage Village             NaN  liked_similar\n",
      "45      serpentwithfeet             NaN  liked_similar\n",
      "76          Omar Apollo             NaN  liked_similar\n",
      "...                 ...             ...            ...\n",
      "2041  Urban Jams United             NaN  liked_similar\n",
      "2043              JAY-Z             NaN  liked_similar\n",
      "2045     PinkPantheress             NaN  liked_similar\n",
      "2067        Cate Le Bon             NaN  liked_similar\n",
      "2106              GAYLE             NaN  liked_similar\n",
      "\n",
      "[121 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with NaN Similar Artists:\")\n",
    "print(df_liked_similar[df_liked_similar['Similar Artists'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c71190-c95d-476a-8a07-e92748e5e757",
   "metadata": {},
   "source": [
    "## Genre Strength Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02d0a5cb-84d6-4248-978b-b74cabd4495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Genres  Genre Strength\n",
      "0        electronic, indie, pop, chill, experimental            20.0\n",
      "1  indie, folk, indie pop, british, female vocalists            20.0\n",
      "2            indie rock, dream pop, indie, indie pop            25.0\n",
      "3  indie, folk, indie pop, british, female vocalists            20.0\n",
      "4  indie, folk, indie pop, british, female vocalists            20.0\n"
     ]
    }
   ],
   "source": [
    "# Get the set of liked genres\n",
    "liked_genres = set(df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Genres'].str.split(',').explode().str.strip())\n",
    "\n",
    "# Calculate genre strength for each artist\n",
    "def calculate_genre_strength(genres):\n",
    "    if pd.isna(genres):\n",
    "        return 0\n",
    "    artist_genres = set(genres.split(','))\n",
    "    overlap = artist_genres.intersection(liked_genres)\n",
    "    return len(overlap) / len(artist_genres) if artist_genres else 0\n",
    "\n",
    "df['Genre Strength'] = df['Genres'].apply(calculate_genre_strength)\n",
    "\n",
    "# Normalize genre strength to 0–100\n",
    "df['Genre Strength'] = (df['Genre Strength'] / df['Genre Strength'].max()) * 100\n",
    "\n",
    "# Check the result\n",
    "print(df[['Genres', 'Genre Strength']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99014cb9-33e6-4a36-b721-38efa5bf1220",
   "metadata": {},
   "source": [
    "## Extra Feature Engineering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27c0a236-7e93-4a4f-ad96-aa77414f9120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track Name', 'Album Name', 'Artist Name(s)', 'Release Date',\n",
       "       'Duration (ms)', 'Popularity', 'Genres', 'Record Label', 'Danceability',\n",
       "       'Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'liked',\n",
       "       'playlist_origin', 'Primary Artist', 'Label_Category',\n",
       "       'Label_Category_encoded', 'is_unknown_genre', 'Genres_encoded',\n",
       "       'genre_count', 'has_location_genre', 'primary_genre',\n",
       "       'primary_genre_encoded', 'Artist Centrality', 'Genre Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2dff4e76-fde1-460d-8997-9fbf06ce956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track Name                 object\n",
       "Album Name                 object\n",
       "Artist Name(s)             object\n",
       "Release Date               object\n",
       "Duration (ms)               int64\n",
       "Popularity                  int64\n",
       "Genres                     object\n",
       "Record Label               object\n",
       "Danceability              float64\n",
       "Energy                    float64\n",
       "Acousticness              float64\n",
       "Instrumentalness          float64\n",
       "Tempo                     float64\n",
       "liked                     float64\n",
       "playlist_origin            object\n",
       "Primary Artist             object\n",
       "Label_Category             object\n",
       "Label_Category_encoded    float64\n",
       "is_unknown_genre            int32\n",
       "Genres_encoded            float64\n",
       "genre_count                 int64\n",
       "has_location_genre           bool\n",
       "primary_genre              object\n",
       "primary_genre_encoded     float64\n",
       "Artist Centrality         float64\n",
       "Genre Strength            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e10d2a-a4b1-4fc5-ba15-e0f339c9d738",
   "metadata": {},
   "source": [
    "## Standardize the numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e2297-9c93-4b11-aa84-a465fcacbe93",
   "metadata": {},
   "source": [
    "### Seperate New Music Friday and Save it for Later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46560726-196c-49ae-aa77-eb98091b8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 'df_nmf' from the main dataframe and save it for later\n",
    "df_nmf = df[df['playlist_origin'] == 'df_nmf'].copy()\n",
    "\n",
    "# Remove df_nmf entries from the original dataframe\n",
    "df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Save df_nmf to CSV for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb709d88-3b66-4b3d-bd0f-31c17b361b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns to standardize\n",
    "numeric_columns = [\n",
    "    'Duration (ms)', 'Popularity', 'Danceability', 'Energy',\n",
    "    'Acousticness', 'Instrumentalness',\n",
    "    'Tempo', 'Label_Category_encoded', 'Genres_encoded',  \n",
    "    'Artist Centrality', 'Genre Strength' \n",
    "]\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data (df)\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Transform the test data (df_nmf) using the fitted scaler\n",
    "df_nmf[numeric_columns] = scaler.transform(df_nmf[numeric_columns])\n",
    "\n",
    "# Save the standardized df_nmf for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a66c9a3-793f-4955-82a5-3b50e79be99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Label_Category_encoded</th>\n",
       "      <th>Genres_encoded</th>\n",
       "      <th>Artist Centrality</th>\n",
       "      <th>Genre Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>-1.798552</td>\n",
       "      <td>0.138851</td>\n",
       "      <td>-0.187197</td>\n",
       "      <td>0.483369</td>\n",
       "      <td>0.285986</td>\n",
       "      <td>0.035748</td>\n",
       "      <td>-1.040421</td>\n",
       "      <td>-0.484897</td>\n",
       "      <td>-0.020241</td>\n",
       "      <td>-1.534955</td>\n",
       "      <td>0.962292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>-0.360264</td>\n",
       "      <td>0.188928</td>\n",
       "      <td>-0.180970</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.300948</td>\n",
       "      <td>-0.436113</td>\n",
       "      <td>-1.322086</td>\n",
       "      <td>-0.484897</td>\n",
       "      <td>-0.020241</td>\n",
       "      <td>-1.534955</td>\n",
       "      <td>0.962292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>-0.831311</td>\n",
       "      <td>0.188928</td>\n",
       "      <td>-0.766273</td>\n",
       "      <td>0.788754</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>-0.453979</td>\n",
       "      <td>-1.372670</td>\n",
       "      <td>-0.484897</td>\n",
       "      <td>-0.020241</td>\n",
       "      <td>-1.534955</td>\n",
       "      <td>0.962292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10666</th>\n",
       "      <td>-0.933589</td>\n",
       "      <td>0.138851</td>\n",
       "      <td>0.429240</td>\n",
       "      <td>1.550065</td>\n",
       "      <td>-0.402290</td>\n",
       "      <td>-0.454001</td>\n",
       "      <td>-0.993881</td>\n",
       "      <td>-0.484897</td>\n",
       "      <td>-0.020241</td>\n",
       "      <td>-1.534955</td>\n",
       "      <td>0.962292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10667</th>\n",
       "      <td>-0.184266</td>\n",
       "      <td>0.389235</td>\n",
       "      <td>-0.336636</td>\n",
       "      <td>0.289816</td>\n",
       "      <td>1.147827</td>\n",
       "      <td>0.629257</td>\n",
       "      <td>-1.021212</td>\n",
       "      <td>-0.484897</td>\n",
       "      <td>-0.020241</td>\n",
       "      <td>-1.534955</td>\n",
       "      <td>0.962292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Duration (ms)  Popularity  Danceability    Energy  Acousticness  \\\n",
       "10663      -1.798552    0.138851     -0.187197  0.483369      0.285986   \n",
       "10664      -0.360264    0.188928     -0.180970  0.952200      0.300948   \n",
       "10665      -0.831311    0.188928     -0.766273  0.788754      0.917404   \n",
       "10666      -0.933589    0.138851      0.429240  1.550065     -0.402290   \n",
       "10667      -0.184266    0.389235     -0.336636  0.289816      1.147827   \n",
       "\n",
       "       Instrumentalness     Tempo  Label_Category_encoded  Genres_encoded  \\\n",
       "10663          0.035748 -1.040421               -0.484897       -0.020241   \n",
       "10664         -0.436113 -1.322086               -0.484897       -0.020241   \n",
       "10665         -0.453979 -1.372670               -0.484897       -0.020241   \n",
       "10666         -0.454001 -0.993881               -0.484897       -0.020241   \n",
       "10667          0.629257 -1.021212               -0.484897       -0.020241   \n",
       "\n",
       "       Artist Centrality  Genre Strength  \n",
       "10663          -1.534955        0.962292  \n",
       "10664          -1.534955        0.962292  \n",
       "10665          -1.534955        0.962292  \n",
       "10666          -1.534955        0.962292  \n",
       "10667          -1.534955        0.962292  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf[numeric_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f901-f9af-4fd4-b402-32873abf0327",
   "metadata": {},
   "source": [
    "#### The data is now ready for modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a81c7d-b745-4c61-bb08-14142affdd55",
   "metadata": {},
   "source": [
    "## One last look at our columns before we run our model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd46fea-b43c-4b31-b48a-43679928a062",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "| Column Name           | Description                                                                                      | Data Type   | Drop From Model? |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|-------------|------------------|\n",
    "| Track Name            | Name of the track (song)                                                                          | object      | Yes              |\n",
    "| Album Name            | Name of the album the track belongs to                                                            | object      | Yes              |\n",
    "| Artist Name(s)        | Name(s) of the artist(s) associated with the track                                                | object      | Yes              |\n",
    "| Release Date          | Release date of the track (in object format for now, can be converted to datetime)               | object      | Yes              |\n",
    "| Duration (ms)         | Duration of the track in milliseconds                                                             | int64       | No               |\n",
    "| Popularity            | Popularity score of the track (higher is more popular)                                            | int64       | No               |\n",
    "| Genres                | Genres associated with the track                                                                  | object      | Yes              |\n",
    "| Record Label          | Record label associated with the track                                                            | object      | Yes              |\n",
    "| Danceability          | Measure of the track's danceability (0-1 scale)                                                  | float64     | No               |\n",
    "| Energy                | Energy level of the track (0-1 scale)                                                            | float64     | No               |\n",
    "| Key                   | The key of the track (musical key)                                                                | float64     | No               |\n",
    "| Loudness              | The loudness of the track (in decibels)                                                          | float64     | No               |\n",
    "| Mode                  | Mode of the track (major or minor key)                                                           | float64     | No               |\n",
    "| Speechiness           | Amount of speech-like content in the track                                                        | float64     | No               |\n",
    "| Acousticness          | Measure of acoustic quality (0-1 scale)                                                           | float64     | No               |\n",
    "| Instrumentalness      | Measure of instrumental content (0-1 scale)                                                      | float64     | No               |\n",
    "| Liveness              | Measure of the track's liveness (0-1 scale)                                                      | float64     | No               |\n",
    "| Valence               | Measure of the track's mood (0-1 scale, from negative to positive)                               | float64     | No               |\n",
    "| Tempo                 | Tempo of the track (beats per minute)                                                            | float64     | No               |\n",
    "| liked                 | Target variable: Whether the track was liked (1 = liked, 0 = not liked)                          | float64     | No               |\n",
    "| playlist_origin       | The playlist where the track originates from (e.g., 'df_nmf' for New Music Friday)               | object      | Yes              |\n",
    "| Primary Artist        | Main artist of the track (extracted from Artist Name(s))                                         | object      | Yes              |\n",
    "| Record Label_encoded  | Encoded version of the record label (numeric representation)                                     | float64     | No               |\n",
    "| is_unknown_genre      | Binary indicator if the track has an unknown genre (1 = unknown, 0 = known)                     | int32       | No               |\n",
    "| Genres_encoded        | Encoded version of the genre (numeric representation)                                            | float64     | No               |\n",
    "| Artist Centrality     | Measure of artist's importance in the similarity network (0-100 scale)                          | float64     | No               |\n",
    "| NMF Similarity        | Similarity score based on NMF algorithm (0-100 scale)                                           | float64     | No               |\n",
    "| Genre Strength        | Measure of how strongly a track belongs to its assigned genres                                   | float64     | No               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7455-4090-48fb-92bd-1fe791ed3f65",
   "metadata": {},
   "source": [
    "# Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37f3948a-af2a-497b-9b0e-5f68579ced00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 10663, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 63.725030\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by RandomForestRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m df_nmf_cleaned \u001b[38;5;241m=\u001b[39m df_nmf[features]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Get Base Predictions and Scale Them to 0-100 Range\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m rf_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip((rf_model\u001b[38;5;241m.\u001b[39mpredict(df_nmf_cleaned) \u001b[38;5;241m*\u001b[39m y_std \u001b[38;5;241m+\u001b[39m y_mean) \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     73\u001b[0m xgb_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip((xgb_model\u001b[38;5;241m.\u001b[39mpredict(df_nmf_cleaned) \u001b[38;5;241m*\u001b[39m y_std \u001b[38;5;241m+\u001b[39m y_mean) \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     74\u001b[0m lgb_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip((lgb_model\u001b[38;5;241m.\u001b[39mpredict(df_nmf_cleaned) \u001b[38;5;241m*\u001b[39m y_std \u001b[38;5;241m+\u001b[39m y_mean) \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1064\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1062\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by RandomForestRegressor."
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate Genre_Diversity for the Entire Dataframe (df)\n",
    "df['Genre_Diversity'] = df['Genres'].str.count(',') / df['Genres'].str.len()\n",
    "\n",
    "# Step 2: Split the Data into Training and Test Sets\n",
    "df_train = df[df['playlist_origin'] != 'df_nmf'].copy()  # Training data (liked, fav_albums, not_liked)\n",
    "df_nmf = df[df['playlist_origin'] == 'df_nmf'].copy()    # Test data (New Music Friday)\n",
    "\n",
    "\n",
    "# Define the Features List\n",
    "features = [\n",
    "    'Popularity', 'Genres_encoded', 'Artist Centrality',\n",
    "]\n",
    "\n",
    "# Prepare Training Data\n",
    "X = df[features]  # Features\n",
    "y = df['liked']   # Target variable\n",
    "\n",
    "# Train LightGBM Model\n",
    "lgb_model = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "lgb_model.fit(X, y)\n",
    "\n",
    "# Normalize the Target Variable\n",
    "y_mean = df['liked'].mean()\n",
    "y_std = df['liked'].std()\n",
    "y_normalized = (df['liked'] - y_mean) / y_std\n",
    "\n",
    "# Use Normalized Target\n",
    "X = df[features]  # Keep X the same\n",
    "y = y_normalized  # Use normalized target\n",
    "\n",
    "# Train Other Models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X, y)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Get Feature Importance from All Models\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_rf': rf_model.feature_importances_\n",
    "}).sort_values('importance_rf', ascending=False)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_xgb': xgb_model.feature_importances_\n",
    "}).sort_values('importance_xgb', ascending=False)\n",
    "\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_lgb': lgb_model.feature_importances_\n",
    "}).sort_values('importance_lgb', ascending=False)\n",
    "\n",
    "# Combine Importance Scores from All Three Models\n",
    "feature_importance = pd.merge(rf_importance, xgb_importance, on='feature')\n",
    "feature_importance = pd.merge(feature_importance, lgb_importance, on='feature')\n",
    "feature_importance['avg_importance'] = (\n",
    "    feature_importance['importance_rf'] + \n",
    "    feature_importance['importance_xgb'] + \n",
    "    feature_importance['importance_lgb']\n",
    ") / 3\n",
    "\n",
    "# Scale Feature Importances to Percentages\n",
    "feature_importance['avg_importance'] = feature_importance['avg_importance'] * 100 / feature_importance['avg_importance'].sum()\n",
    "feature_importance = feature_importance.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "# Prepare NMF Data for Prediction\n",
    "df_nmf['Genre_Diversity'] = df_nmf['Genres'].str.count(',') / df_nmf['Genres'].str.len()\n",
    "df_nmf_cleaned = df_nmf[features]\n",
    "\n",
    "# Get Base Predictions and Scale Them to 0-100 Range\n",
    "rf_predictions = np.clip((rf_model.predict(df_nmf_cleaned) * y_std + y_mean) / df['liked'].max() * 100, 0, 100)\n",
    "xgb_predictions = np.clip((xgb_model.predict(df_nmf_cleaned) * y_std + y_mean) / df['liked'].max() * 100, 0, 100)\n",
    "lgb_predictions = np.clip((lgb_model.predict(df_nmf_cleaned) * y_std + y_mean) / df['liked'].max() * 100, 0, 100)\n",
    "\n",
    "# Get CV Scores for All Models (for Weighted Ensemble)\n",
    "custom_scorer_func = make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true * y_std + y_mean, y_pred * y_std + y_mean), greater_is_better=False)\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "lgb_cv_scores = cross_val_score(lgb_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "\n",
    "# Create Weighted Ensemble Based on CV Scores\n",
    "cv_scores = {\n",
    "    'rf': abs(rf_cv_scores.mean()),\n",
    "    'xgb': abs(xgb_cv_scores.mean()),\n",
    "    'lgb': abs(lgb_cv_scores.mean())\n",
    "}\n",
    "total = sum(cv_scores.values())\n",
    "weights = {k: v/total for k, v in cv_scores.items()}\n",
    "\n",
    "# Combine Scaled Predictions\n",
    "final_predictions = (\n",
    "    rf_predictions * weights['rf'] +\n",
    "    xgb_predictions * weights['xgb'] +\n",
    "    lgb_predictions * weights['lgb']\n",
    ")\n",
    "\n",
    "df_nmf['predicted_score'] = final_predictions\n",
    "\n",
    "# Get Prediction Intervals (Modified for Scaled Values)\n",
    "def get_prediction_interval(X, model, percentile=95):\n",
    "    predictions = []\n",
    "    for estimator in model.estimators_:\n",
    "        pred = estimator.predict(X) * y_std + y_mean\n",
    "        pred = np.clip(pred / df['liked'].max() * 100, 0, 100)  # Scale to 0-100\n",
    "        predictions.append(pred)\n",
    "    predictions = np.array(predictions)\n",
    "    lower = np.percentile(predictions, (100-percentile)/2, axis=0)\n",
    "    upper = np.percentile(predictions, 100-(100-percentile)/2, axis=0)\n",
    "    return lower, upper\n",
    "\n",
    "# Calculate Prediction Intervals\n",
    "lower_bound, upper_bound = get_prediction_interval(df_nmf_cleaned, rf_model)\n",
    "df_nmf['prediction_lower'] = lower_bound\n",
    "df_nmf['prediction_upper'] = upper_bound\n",
    "df_nmf['prediction_uncertainty'] = upper_bound - lower_bound\n",
    "\n",
    "# Get the Most Common Release Date from NMF Dataset\n",
    "nmf_release_date = df_nmf['Release Date'].mode().iloc[0]\n",
    "\n",
    "# Aggregate by Album (Working with Already-Scaled Values)\n",
    "album_predictions = df_nmf.groupby('Album Name').agg({\n",
    "    'Artist Name(s)': 'first',\n",
    "    'predicted_score': ['mean', 'min', 'max', 'std', 'count'],\n",
    "    'prediction_uncertainty': 'mean',\n",
    "    'Genres': 'first',\n",
    "    'Record Label': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten Column Names\n",
    "album_predictions.columns = [\n",
    "    'Album Name', 'Artist', \n",
    "    'avg_score', 'min_score', 'max_score', 'score_std', 'track_count',\n",
    "    'avg_uncertainty', 'Genres', 'Record Label'\n",
    "]\n",
    "\n",
    "# Calculate Confidence Score\n",
    "max_std = album_predictions['score_std'].max()\n",
    "max_uncertainty = album_predictions['avg_uncertainty'].max()\n",
    "\n",
    "album_predictions['confidence_score'] = (\n",
    "    (1 - album_predictions['score_std'] / max_std) * \n",
    "    (1 - album_predictions['avg_uncertainty'] / max_uncertainty) * \n",
    "    (1 - 1/(1 + album_predictions['track_count']))\n",
    ") * 100\n",
    "\n",
    "# Clip Confidence Scores\n",
    "album_predictions['confidence_score'] = np.clip(\n",
    "    album_predictions['confidence_score'], a_min=1, a_max=100\n",
    ")\n",
    "\n",
    "# Add Weighted Score for Ranking\n",
    "album_predictions['weighted_score'] = (\n",
    "    album_predictions['avg_score'] * album_predictions['confidence_score'] / 100\n",
    ")\n",
    "\n",
    "# Format the Date for the Filename\n",
    "date_str = datetime.strptime(nmf_release_date, '%Y-%m-%d').strftime('%m-%d-%y')\n",
    "filename = f\"{date_str}_Album_Recommendations.csv\"\n",
    "\n",
    "# Create Predictions Directory if It Doesn't Exist\n",
    "os.makedirs('predictions', exist_ok=True)\n",
    "\n",
    "# Reorder Columns and Sort by avg_score\n",
    "album_recommendations = album_predictions.reindex(columns=[\n",
    "    'Artist', 'Album Name', 'avg_score', 'confidence_score',\n",
    "    'min_score', 'max_score', 'score_std', 'track_count',\n",
    "    'avg_uncertainty', 'Genres', 'Record Label', 'weighted_score'\n",
    "]).sort_values('avg_score', ascending=False)\n",
    "\n",
    "# Save Recommendations\n",
    "album_recommendations.to_csv(f'predictions/{filename}', index=False)\n",
    "\n",
    "# Sort df_nmf by predicted_score Before Saving Detailed Predictions\n",
    "df_nmf_sorted = df_nmf.sort_values('predicted_score', ascending=False)\n",
    "df_nmf_sorted[['Artist Name(s)', 'Track Name', 'Album Name', 'predicted_score',\n",
    "               'prediction_lower', 'prediction_upper', 'prediction_uncertainty']].to_csv(\n",
    "                   f'predictions/nmf_predictions_with_uncertainty.csv', index=False)\n",
    "\n",
    "# Print Results\n",
    "print(f\"\\nNew Music Friday Release Date: {nmf_release_date}\")\n",
    "print(\"\\nTop 20 Recommended Albums:\")\n",
    "print(album_recommendations[['Album Name', 'Artist', 'avg_score', 'track_count', \n",
    "                           'confidence_score']].head(20))\n",
    "\n",
    "# Print Cross-Validation Results\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(f\"Random Forest CV Score: {rf_cv_scores.mean():.3f} (+/- {rf_cv_scores.std() * 2:.3f})\")\n",
    "print(f\"XGBoost CV Score: {xgb_cv_scores.mean():.3f} (+/- {xgb_cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Print Top 20 Most Important Features\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance[['feature', 'avg_importance']].head(20).to_string(index=False))\n",
    "\n",
    "# Visualize Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['avg_importance'])\n",
    "plt.xlabel('Importance (%)')\n",
    "plt.title('Feature Importance (% of Total Impact)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9322a5-2f57-4eec-a695-15c73b3a8b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
