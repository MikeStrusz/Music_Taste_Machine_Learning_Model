import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

def analyze_genres_from_ten_genres():
    # Load the ten_genres.csv file
    ten_genres_df = pd.read_csv("data/ten_genres.csv")
    
    # Load the cleaned pre-standardized data to get playlist_origin
    df_cleaned = pd.read_csv("data/df_cleaned_pre_standardized.csv")
    
    # Create a mapping of artists to their playlist origin
    artist_origin_map = df_cleaned[['Primary Artist', 'playlist_origin']].drop_duplicates()
    artist_origin_map = artist_origin_map.set_index('Primary Artist')['playlist_origin'].to_dict()
    
    # Add playlist origin to ten_genres_df
    ten_genres_df['playlist_origin'] = ten_genres_df['Artist'].apply(
        lambda x: artist_origin_map.get(x, 'unknown')
    )
    
    # Assign weights based on playlist origin
    def get_weight(origin):
        if origin == 'df_liked':
            return 1.0  # Highest weight for explicitly liked songs
        elif origin == 'df_fav_albums':
            return 0.8  # High weight for favorite albums
        elif origin == 'df_mid':
            return 0.4  # Medium weight for "mid" albums
        elif origin == 'df_not_liked':
            return 0.0  # No weight for disliked albums
        else:
            return 0.0  # Default for unknown
    
    ten_genres_df['weight'] = ten_genres_df['playlist_origin'].apply(get_weight)
    
    # Extract all genres from the Genres column
    all_genres = []
    genre_weights = {}
    
    for _, row in ten_genres_df.iterrows():
        if pd.notna(row['Genres']):
            genres = str(row['Genres']).split(', ')
            for genre in genres:
                genre = genre.strip().lower()
                if genre and genre != 'nan' and genre != 'unknown':
                    all_genres.append((genre, row['weight']))
                    
                    # Update weighted count
                    if row['weight'] > 0:  # Only count positive weights
                        genre_weights[genre] = genre_weights.get(genre, 0) + row['weight']
    
    # Create DataFrame for analysis
    genres_df = pd.DataFrame(all_genres, columns=['genre', 'weight'])
    
    # Group by genre and calculate metrics
    genre_stats = genres_df.groupby('genre').agg(
        count=('weight', 'count'),
        total_weight=('weight', 'sum'),
        avg_weight=('weight', 'mean')
    ).reset_index()
    
    # Calculate normalized score (1-10 scale)
    max_weight = genre_stats['total_weight'].max()
    genre_stats['normalized_score'] = (genre_stats['total_weight'] / max_weight) * 10
    
    # Filter out rare genres (appearing less than 5 times)
    genre_stats = genre_stats[genre_stats['count'] >= 5]
    
    # Sort by total weight
    genre_stats = genre_stats.sort_values('total_weight', ascending=False)
    
    # Print top 30 genres
    print("Top 30 Genres by Weighted Score:")
    for i, row in genre_stats.head(30).iterrows():
        print(f"{row['genre']}: {row['normalized_score']:.1f}/10 ({row['count']} occurrences)")
    
    # Visualize top 20 genres
    plt.figure(figsize=(12, 10))
    sns.barplot(x='normalized_score', y='genre', data=genre_stats.head(20))
    plt.title('Top 20 Genres by Preference Score')
    plt.xlabel('Preference Score (0-10)')
    plt.tight_layout()
    plt.savefig('top_genres_analysis_from_ten_genres.png')
    
    # Create a dictionary of liked genres with their scores
    liked_genres = {
        row['genre']: row['normalized_score'] / 10  # Convert to 0-1 scale
        for _, row in genre_stats.head(50).iterrows()  # Take top 50 genres
    }
    
    # Print the dictionary in a format that can be copied into code
    print("\nLiked Genres Dictionary (for model integration):")
    print("{")
    for genre, score in liked_genres.items():
        print(f"    '{genre}': {score:.2f},")
    print("}")
    
    return genre_stats, liked_genres

# Run the analysis
genre_stats, liked_genres = analyze_genres_from_ten_genres()

