{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826242c6-c59e-42e0-9d2f-adc2631ada21",
   "metadata": {},
   "source": [
    "# RUN THURSDAY.ipynb\n",
    "# ====================================================================\n",
    "# ðŸ“Š GUT SCORE INTEGRATION PIPELINE\n",
    "# Run this on Thursday to update training data with your latest ratings\n",
    "# ===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13c7a42-daa4-4248-b7e4-d1f2bf333e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—“ï¸ RUN THURSDAY: Clean Output Version\n",
      "============================================================\n",
      "ðŸ“… 2026-01-16 08:55:52\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Loading gut scores from MASTER file...\n",
      "âœ… Found 14 total rated albums in master file\n",
      "\n",
      "ðŸ“ Loading training data...\n",
      "  Current: 10,284 tracks\n",
      "  Existing gut-scored tracks: 165\n",
      "\n",
      "ðŸŽµ Processing NEW gut-scored albums...\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š WEEKLY REPORT\n",
      "============================================================\n",
      "â„¹ï¸ No new gut scores to add this week\n",
      "\n",
      "ðŸ“ˆ OVERALL TOTALS:\n",
      "------------------------------------------------------------\n",
      "  Total rated albums: 14\n",
      "  Gut-scored tracks: 165\n",
      "  Total training tracks: 10,284\n",
      "\n",
      "============================================================\n",
      "âœ… THURSDAY PROCESSING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ====================================================================\n",
    "# ðŸŽ¯ THURSDAY: CLEAN OUTPUT VERSION\n",
    "# Only shows NEW albums being processed\n",
    "# ====================================================================\n",
    "\n",
    "print(\"ðŸ—“ï¸ RUN THURSDAY: Clean Output Version\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“… \" + datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- STEP 1: LOAD GUT SCORES FROM MASTER FILE ---\n",
    "print(\"\\nðŸ“Š Loading gut scores from MASTER file...\")\n",
    "\n",
    "master_file = 'feedback/master_gut_scores.csv'\n",
    "\n",
    "if not os.path.exists(master_file):\n",
    "    print(f\"âŒ Master file not found: {master_file}\")\n",
    "    exit()\n",
    "\n",
    "master_df = pd.read_csv(master_file)\n",
    "master_df = master_df[master_df['gut_score'].notna()]\n",
    "\n",
    "if len(master_df) == 0:\n",
    "    print(\"âŒ No gut scores found!\")\n",
    "    exit()\n",
    "\n",
    "total_albums = len(master_df)\n",
    "print(f\"âœ… Found {total_albums} total rated albums in master file\")\n",
    "\n",
    "# --- STEP 2: LOAD TRAINING DATA ---\n",
    "print(\"\\nðŸ“ Loading training data...\")\n",
    "training_file = 'data/2026_training_complete_with_features.csv'\n",
    "\n",
    "if not os.path.exists(training_file):\n",
    "    print(f\"âŒ Training file not found: {training_file}\")\n",
    "    exit()\n",
    "\n",
    "df_training = pd.read_csv(training_file)\n",
    "print(f\"  Current: {len(df_training):,} tracks\")\n",
    "\n",
    "# Count existing gut-scored tracks\n",
    "if 'source_type' in df_training.columns:\n",
    "    existing_gut = df_training[df_training['source_type'] == 'gut_score_rated']\n",
    "    existing_count = len(existing_gut)\n",
    "    print(f\"  Existing gut-scored tracks: {existing_count:,}\")\n",
    "else:\n",
    "    existing_count = 0\n",
    "\n",
    "# --- STEP 3: FIND AND ADD ONLY NEW TRACKS ---\n",
    "print(\"\\nðŸŽµ Processing NEW gut-scored albums...\")\n",
    "\n",
    "# Get archives (newest first)\n",
    "archive_files = sorted(glob.glob('data/archived_nmf_with_features/*.csv'), reverse=True)\n",
    "\n",
    "if not archive_files:\n",
    "    print(\"âŒ No archive files found!\")\n",
    "    exit()\n",
    "\n",
    "tracks_added = 0\n",
    "new_albums = 0\n",
    "new_albums_list = []\n",
    "\n",
    "for _, fb_row in master_df.iterrows():\n",
    "    artist = fb_row['Artist']\n",
    "    album = fb_row['Album']\n",
    "    score = fb_row['gut_score']\n",
    "    \n",
    "    # Skip if already in training as gut_score_rated\n",
    "    already_in_training = df_training[\n",
    "        (df_training['Album Name'] == album) &\n",
    "        (df_training['Artist Name(s)'].str.contains(artist, na=False)) &\n",
    "        (df_training['source_type'] == 'gut_score_rated')\n",
    "    ]\n",
    "    \n",
    "    if len(already_in_training) > 0:\n",
    "        continue  # SILENTLY skip - don't print anything!\n",
    "    \n",
    "    # ---- ONLY REACH HERE FOR NEW ALBUMS ----\n",
    "    if new_albums == 0:  # First new album\n",
    "        print(\"  Processing...\")\n",
    "    \n",
    "    new_albums += 1\n",
    "    new_albums_list.append((artist, album, score))\n",
    "    \n",
    "    # Search archives\n",
    "    found_tracks = None\n",
    "    for archive_file in archive_files:\n",
    "        try:\n",
    "            archive_df = pd.read_csv(archive_file)\n",
    "            album_tracks = archive_df[\n",
    "                (archive_df['Album Name'] == album) &\n",
    "                (archive_df['Artist Name(s)'].str.contains(artist, na=False))\n",
    "            ].copy()\n",
    "            \n",
    "            if len(album_tracks) > 0:\n",
    "                found_tracks = album_tracks\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if found_tracks is None:\n",
    "        print(f\"  âŒ Could not find tracks for: {artist} - {album}\")\n",
    "        continue\n",
    "    \n",
    "    # Add gut score\n",
    "    found_tracks['liked'] = score\n",
    "    found_tracks['source_type'] = 'gut_score_rated'\n",
    "    found_tracks['gut_score_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Add to training\n",
    "    df_training = pd.concat([df_training, found_tracks], ignore_index=True)\n",
    "    tracks_added += len(found_tracks)\n",
    "\n",
    "# --- STEP 4: DUPLICATE HANDLING (SILENT) ---\n",
    "if tracks_added > 0:\n",
    "    # Silent duplicate handling\n",
    "    def clean_artist_name(artist_str):\n",
    "        if pd.isna(artist_str): return \"\"\n",
    "        artist = str(artist_str).strip()\n",
    "        separators = [' feat. ', ' featuring ', ' ft. ', ' with ', ' & ', ' and ', ';', ',']\n",
    "        for sep in separators:\n",
    "            if sep in artist.lower():\n",
    "                artist = artist.split(sep)[0].strip()\n",
    "        return artist\n",
    "    \n",
    "    df_training['artist_clean'] = df_training['Artist Name(s)'].apply(clean_artist_name)\n",
    "    df_training = df_training.sort_values('liked', ascending=False)\n",
    "    df_training = df_training.drop_duplicates(\n",
    "        subset=['Album Name', 'artist_clean', 'Track Name'],\n",
    "        keep='first'\n",
    "    )\n",
    "    df_training = df_training.drop(columns=['artist_clean'], errors='ignore')\n",
    "\n",
    "# --- STEP 5: SAVE AND REPORT ---\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š WEEKLY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if tracks_added > 0:\n",
    "    # Create backup\n",
    "    backup_dir = 'data/backups'\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    backup_file = f\"{backup_dir}/training_backup_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "    pd.read_csv(training_file).to_csv(backup_file, index=False)\n",
    "    \n",
    "    # Save updated training\n",
    "    df_training.to_csv(training_file, index=False)\n",
    "    \n",
    "    print(f\"âœ… ADDED THIS WEEK:\")\n",
    "    print(\"-\" * 60)\n",
    "    for artist, album, score in new_albums_list:\n",
    "        print(f\"  â€¢ {artist[:25]:<25} - {album[:25]:<25} â†’ {score}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  Tracks added: {tracks_added:,}\")\n",
    "    print(f\"  Albums added: {new_albums}\")\n",
    "    \n",
    "else:\n",
    "    print(\"â„¹ï¸ No new gut scores to add this week\")\n",
    "\n",
    "# Final stats\n",
    "print(f\"\\nðŸ“ˆ OVERALL TOTALS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Total rated albums: {total_albums}\")\n",
    "print(f\"  Gut-scored tracks: {len(df_training[df_training['source_type'] == 'gut_score_rated']):,}\")\n",
    "print(f\"  Total training tracks: {len(df_training):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… THURSDAY PROCESSING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139bb5c1-6e93-4e06-a94f-9378add17e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—“ï¸ RUN THURSDAY: Enhanced with Release Dates\n",
      "============================================================\n",
      "ðŸ“… 2026-01-16 08:55:53\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Loading gut scores from MASTER file...\n",
      "âœ… Found 14 total rated albums in master file\n",
      "\n",
      "ðŸ“ Loading training data...\n",
      "  Current: 10,284 tracks\n",
      "  Existing gut-scored tracks: 165\n",
      "\n",
      "ðŸ—‚ï¸  Scanning archive files...\n",
      "  Found 1 archive weeks\n",
      "\n",
      "ðŸŽµ Processing NEW gut-scored albums...\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š WEEKLY REPORT\n",
      "============================================================\n",
      "â„¹ï¸ No new gut scores to add this week\n",
      "\n",
      "ðŸ“ˆ OVERALL TOTALS:\n",
      "------------------------------------------------------------\n",
      "  Total gut-scored tracks: 165\n",
      "  Total rated albums: 14\n",
      "  Total training tracks: 10,284\n",
      "\n",
      "============================================================\n",
      "âœ… THURSDAY PROCESSING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ðŸŽ¯ THURSDAY: ENHANCED WITH RELEASE DATES\n",
    "# Shows which NMF week each album came from\n",
    "# ====================================================================\n",
    "\n",
    "print(\"ðŸ—“ï¸ RUN THURSDAY: Enhanced with Release Dates\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“… \" + datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- STEP 1: LOAD GUT SCORES FROM MASTER FILE ---\n",
    "print(\"\\nðŸ“Š Loading gut scores from MASTER file...\")\n",
    "\n",
    "master_file = 'feedback/master_gut_scores.csv'\n",
    "\n",
    "if not os.path.exists(master_file):\n",
    "    print(f\"âŒ Master file not found: {master_file}\")\n",
    "    exit()\n",
    "\n",
    "master_df = pd.read_csv(master_file)\n",
    "master_df = master_df[master_df['gut_score'].notna()]\n",
    "\n",
    "if len(master_df) == 0:\n",
    "    print(\"âŒ No gut scores found!\")\n",
    "    exit()\n",
    "\n",
    "total_albums = len(master_df)\n",
    "print(f\"âœ… Found {total_albums} total rated albums in master file\")\n",
    "\n",
    "# --- STEP 2: LOAD TRAINING DATA ---\n",
    "print(\"\\nðŸ“ Loading training data...\")\n",
    "training_file = 'data/2026_training_complete_with_features.csv'\n",
    "\n",
    "if not os.path.exists(training_file):\n",
    "    print(f\"âŒ Training file not found: {training_file}\")\n",
    "    exit()\n",
    "\n",
    "df_training = pd.read_csv(training_file)\n",
    "print(f\"  Current: {len(df_training):,} tracks\")\n",
    "\n",
    "# Count existing gut-scored tracks\n",
    "if 'source_type' in df_training.columns:\n",
    "    existing_gut = df_training[df_training['source_type'] == 'gut_score_rated']\n",
    "    existing_count = len(existing_gut)\n",
    "    print(f\"  Existing gut-scored tracks: {existing_count:,}\")\n",
    "else:\n",
    "    existing_count = 0\n",
    "\n",
    "# --- STEP 3: MAP ARCHIVE FILES TO DATES ---\n",
    "print(\"\\nðŸ—‚ï¸  Scanning archive files...\")\n",
    "archive_files = sorted(glob.glob('data/archived_nmf_with_features/*.csv'), reverse=True)\n",
    "\n",
    "if not archive_files:\n",
    "    print(\"âŒ No archive files found!\")\n",
    "    exit()\n",
    "\n",
    "# Create mapping: filename -> human readable date\n",
    "archive_date_map = {}\n",
    "for archive_file in archive_files:\n",
    "    filename = os.path.basename(archive_file)\n",
    "    # Extract date: \"2026-01-11_nmf_complete.csv\" -> \"2026-01-11\"\n",
    "    date_str = filename.split('_')[0]\n",
    "    \n",
    "    try:\n",
    "        # Convert to readable format: \"Jan 11, 2026\"\n",
    "        date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "        readable_date = date_obj.strftime('%b %d, %Y')\n",
    "        archive_date_map[archive_file] = readable_date\n",
    "    except:\n",
    "        archive_date_map[archive_file] = date_str\n",
    "\n",
    "print(f\"  Found {len(archive_files)} archive weeks\")\n",
    "\n",
    "# --- STEP 4: PROCESS NEW ALBUMS WITH RELEASE DATES ---\n",
    "print(\"\\nðŸŽµ Processing NEW gut-scored albums...\")\n",
    "\n",
    "tracks_added = 0\n",
    "new_albums = 0\n",
    "new_albums_info = []  # Store (artist, album, score, release_date, track_count)\n",
    "\n",
    "for _, fb_row in master_df.iterrows():\n",
    "    artist = fb_row['Artist']\n",
    "    album = fb_row['Album']\n",
    "    score = fb_row['gut_score']\n",
    "    \n",
    "    # Skip if already in training\n",
    "    already_in_training = df_training[\n",
    "        (df_training['Album Name'] == album) &\n",
    "        (df_training['Artist Name(s)'].str.contains(artist, na=False)) &\n",
    "        (df_training['source_type'] == 'gut_score_rated')\n",
    "    ]\n",
    "    \n",
    "    if len(already_in_training) > 0:\n",
    "        continue\n",
    "    \n",
    "    # Search archives\n",
    "    found_tracks = None\n",
    "    found_archive = None\n",
    "    release_date = \"Unknown\"\n",
    "    \n",
    "    for archive_file in archive_files:\n",
    "        try:\n",
    "            archive_df = pd.read_csv(archive_file)\n",
    "            album_tracks = archive_df[\n",
    "                (archive_df['Album Name'] == album) &\n",
    "                (archive_df['Artist Name(s)'].str.contains(artist, na=False))\n",
    "            ].copy()\n",
    "            \n",
    "            if len(album_tracks) > 0:\n",
    "                found_tracks = album_tracks\n",
    "                found_archive = archive_file\n",
    "                release_date = archive_date_map.get(archive_file, \"Unknown\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if found_tracks is None:\n",
    "        print(f\"  âŒ Could not find tracks for: {artist} - {album}\")\n",
    "        continue\n",
    "    \n",
    "    new_albums += 1\n",
    "    new_albums_info.append({\n",
    "        'artist': artist,\n",
    "        'album': album, \n",
    "        'score': score,\n",
    "        'release_date': release_date,\n",
    "        'tracks': len(found_tracks)\n",
    "    })\n",
    "    \n",
    "    # Add gut score\n",
    "    found_tracks['liked'] = score\n",
    "    found_tracks['source_type'] = 'gut_score_rated'\n",
    "    found_tracks['gut_score_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "    found_tracks['nmf_release_date'] = release_date\n",
    "    \n",
    "    # Add to training\n",
    "    df_training = pd.concat([df_training, found_tracks], ignore_index=True)\n",
    "    tracks_added += len(found_tracks)\n",
    "\n",
    "# --- STEP 5: SILENT DUPLICATE HANDLING ---\n",
    "if tracks_added > 0:\n",
    "    def clean_artist_name(artist_str):\n",
    "        if pd.isna(artist_str): return \"\"\n",
    "        artist = str(artist_str).strip()\n",
    "        separators = [' feat. ', ' featuring ', ' ft. ', ' with ', ' & ', ' and ', ';', ',']\n",
    "        for sep in separators:\n",
    "            if sep in artist.lower():\n",
    "                artist = artist.split(sep)[0].strip()\n",
    "        return artist\n",
    "    \n",
    "    df_training['artist_clean'] = df_training['Artist Name(s)'].apply(clean_artist_name)\n",
    "    df_training = df_training.sort_values('liked', ascending=False)\n",
    "    df_training = df_training.drop_duplicates(\n",
    "        subset=['Album Name', 'artist_clean', 'Track Name'],\n",
    "        keep='first'\n",
    "    )\n",
    "    df_training = df_training.drop(columns=['artist_clean'], errors='ignore')\n",
    "\n",
    "# --- STEP 6: ENHANCED REPORT WITH RELEASE DATES ---\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š WEEKLY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if tracks_added > 0:\n",
    "    # Create backup\n",
    "    backup_dir = 'data/backups'\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    backup_file = f\"{backup_dir}/training_backup_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "    pd.read_csv(training_file).to_csv(backup_file, index=False)\n",
    "    \n",
    "    # Save updated training\n",
    "    df_training.to_csv(training_file, index=False)\n",
    "    \n",
    "    print(f\"âœ… ADDED THIS WEEK ({len(new_albums_info)} albums):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Group by release date\n",
    "    albums_by_date = {}\n",
    "    for info in new_albums_info:\n",
    "        date = info['release_date']\n",
    "        if date not in albums_by_date:\n",
    "            albums_by_date[date] = []\n",
    "        albums_by_date[date].append(info)\n",
    "    \n",
    "    # Show by release date (most recent first)\n",
    "    for date in sorted(albums_by_date.keys(), reverse=True):\n",
    "        print(f\"\\nðŸ“… {date}:\")\n",
    "        for info in albums_by_date[date]:\n",
    "            print(f\"  â€¢ {info['artist'][:22]:<22} - {info['album'][:22]:<22}\")\n",
    "            print(f\"      Score: {info['score']} | Tracks: {info['tracks']}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  Total tracks added: {tracks_added:,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"â„¹ï¸ No new gut scores to add this week\")\n",
    "\n",
    "# Final stats with breakdown\n",
    "print(f\"\\nðŸ“ˆ OVERALL TOTALS:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Get all gut-scored tracks\n",
    "if 'nmf_release_date' in df_training.columns:\n",
    "    gut_scored = df_training[df_training['source_type'] == 'gut_score_rated']\n",
    "    \n",
    "    if len(gut_scored) > 0:\n",
    "        # Count by release date\n",
    "        date_counts = gut_scored['nmf_release_date'].value_counts()\n",
    "        \n",
    "        print(f\"  Gut-scored tracks by release week:\")\n",
    "        for date, count in date_counts.head(5).items():  # Show top 5\n",
    "            print(f\"    {date}: {count:,} tracks\")\n",
    "        \n",
    "        if len(date_counts) > 5:\n",
    "            print(f\"    ... and {len(date_counts) - 5} more weeks\")\n",
    "    \n",
    "    print(f\"  Total gut-scored tracks: {len(gut_scored):,}\")\n",
    "else:\n",
    "    gut_scored = df_training[df_training['source_type'] == 'gut_score_rated']\n",
    "    print(f\"  Total gut-scored tracks: {len(gut_scored):,}\")\n",
    "\n",
    "print(f\"  Total rated albums: {total_albums}\")\n",
    "print(f\"  Total training tracks: {len(df_training):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… THURSDAY PROCESSING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b147e-84ad-4eaa-a209-e772ee5a56c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
