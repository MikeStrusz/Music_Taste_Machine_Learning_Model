{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d392a2d-8247-40dc-9431-ae29941dc3ea",
   "metadata": {},
   "source": [
    "# 2026 Music Taste Prediction Model: New Music Friday Recommender üíøüéßüëçüëé\n",
    "In this model, I use my liked songs playlist, my recently loved and not loved albums, to train my regression model on what kind of music I do and don't like. At the end my test model will be the new music friday albums from the most recent Friday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e436444-4aff-431a-aedc-e7871c247d1e",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160a9a1f-e9f9-4fb7-b0e3-dcc706dba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import csv\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Third-Party Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "\n",
    "# Fuzzy Matching\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from nbconvert import HTMLExporter\n",
    "import nbformat\n",
    "\n",
    "# Streamlit \n",
    "import streamlit as st\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42454624-15b3-4b80-bab9-a8ecbf9d299b",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8067f0c-b06b-4426-bad9-69bd28e3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked = pd.read_csv(\"data/liked.csv\")  # For PageRank only\n",
    "df_training = pd.read_csv(\"data/2026_training_complete_with_features.csv\")  # NEW!\n",
    "df_nmf = pd.read_csv(\"data/nmf.csv\")  # Test set\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b112f9a-264e-4da1-87fd-ffe68974dd78",
   "metadata": {},
   "source": [
    "## A Check for New Artists / Pull Their Similar Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3c1adc-0020-425f-89fa-56dee6f455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ALL artists from all data sources...\n",
      "Loaded 4849 existing artists from database\n",
      "  - Liked songs: 2435 artists\n",
      "  - Training data: 1219 artists\n",
      "  - NMF data: 594 artists\n",
      "\n",
      "Total unique artists from all sources: 3639\n",
      "Found 0 new artists to process\n",
      "No new artists to process. Database is up to date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BODEGA</td>\n",
       "      <td>Folly Group, Gustaf, Warmduscher, Deadletter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHE</td>\n",
       "      <td>OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonnie Prince Billy</td>\n",
       "      <td>Palace Music, Will Oldham, Palace Brothers, Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Telethon</td>\n",
       "      <td>Barely March, Smol Data, Diva Sweetly, Bigger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heather Maloney</td>\n",
       "      <td>Heather Maloney &amp; Darlingside, Twisted Pine, R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Artist                                    Similar Artists\n",
       "0               BODEGA  Folly Group, Gustaf, Warmduscher, Deadletter, ...\n",
       "1                  CHE  OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...\n",
       "2  Bonnie Prince Billy  Palace Music, Will Oldham, Palace Brothers, Bi...\n",
       "3             Telethon  Barely March, Smol Data, Diva Sweetly, Bigger ...\n",
       "4      Heather Maloney  Heather Maloney & Darlingside, Twisted Pine, R..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize LastFM API client with rate limiting and request limits\n",
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25, limit: int = 8):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        self.limit = limit\n",
    "\n",
    "    def get_similar_artists(self, artist_name: str) -> List[str]:\n",
    "        params = {\n",
    "            'method': 'artist.getSimilar',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'limit': self.limit,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            if 'X-RateLimit-Remaining' in response.headers:\n",
    "                remaining = int(response.headers['X-RateLimit-Remaining'])\n",
    "                if remaining == 0:\n",
    "                    sleep(self.rate_limit_delay)\n",
    "            \n",
    "            data = response.json()\n",
    "            if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "                return [artist['name'] for artist in data['similarartists']['artist'][:self.limit]]\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching similar artists for {artist_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "def extract_primary_artist(artist_string: str) -> str:\n",
    "    if pd.isna(artist_string):\n",
    "        return \"\"\n",
    "    return artist_string.split(\",\")[0].strip()\n",
    "\n",
    "def update_similar_artists_all_sources(api_key: str, output_path: str = 'data/liked_artists_only_similar.csv') -> pd.DataFrame:\n",
    "    print(\"Loading ALL artists from all data sources...\")\n",
    "    \n",
    "    # Load existing similar artists data\n",
    "    existing_data: Dict[str, List[str]] = {}\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        existing_data = dict(zip(existing_df['Artist'], existing_df['Similar Artists']))\n",
    "        print(f\"Loaded {len(existing_data)} existing artists from database\")\n",
    "    \n",
    "    # Load artists from ALL data sources\n",
    "    all_artists = set()\n",
    "    \n",
    "    # 1. Liked songs\n",
    "    try:\n",
    "        df_liked = pd.read_csv(\"data/liked.csv\")\n",
    "        liked_artists = df_liked['Artist Name(s)'].apply(extract_primary_artist).unique()\n",
    "        all_artists.update(liked_artists)\n",
    "        print(f\"  - Liked songs: {len(liked_artists)} artists\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error loading liked.csv: {e}\")\n",
    "    \n",
    "    # 2. New training data (Top 100 + Honorable + Mid + Not Liked)\n",
    "    try:\n",
    "        df_training = pd.read_csv(\"data/2026_training_complete_with_features.csv\")\n",
    "        training_artists = df_training['Artist Name(s)'].apply(extract_primary_artist).unique()\n",
    "        all_artists.update(training_artists)\n",
    "        print(f\"  - Training data: {len(training_artists)} artists\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error loading training data: {e}\")\n",
    "        # Fallback to individual files\n",
    "        try:\n",
    "            df_top_100 = pd.read_csv(\"data/top_100_all_years_clean.csv\")\n",
    "            top_artists = df_top_100['Artist'].apply(extract_primary_artist).unique()\n",
    "            all_artists.update(top_artists)\n",
    "            print(f\"  - Top 100 data: {len(top_artists)} artists\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 3. NMF data (current New Music Friday)\n",
    "    try:\n",
    "        df_nmf = pd.read_csv(\"data/nmf.csv\")\n",
    "        nmf_artists = df_nmf['Artist Name(s)'].apply(extract_primary_artist).unique()\n",
    "        all_artists.update(nmf_artists)\n",
    "        print(f\"  - NMF data: {len(nmf_artists)} artists\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error loading nmf.csv: {e}\")\n",
    "    \n",
    "    # Remove empty strings\n",
    "    all_artists.discard(\"\")\n",
    "    \n",
    "    print(f\"\\nTotal unique artists from all sources: {len(all_artists)}\")\n",
    "    \n",
    "    # Find new artists not in existing data\n",
    "    new_artists = all_artists - set(existing_data.keys())\n",
    "    print(f\"Found {len(new_artists)} new artists to process\")\n",
    "    \n",
    "    if not new_artists:\n",
    "        print(\"No new artists to process. Database is up to date!\")\n",
    "        return pd.DataFrame({\n",
    "            'Artist': list(existing_data.keys()),\n",
    "            'Similar Artists': list(existing_data.values())\n",
    "        })\n",
    "    \n",
    "    # Process new artists\n",
    "    api = LastFMAPI(api_key)\n",
    "    results = {}\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(api.get_similar_artists, artist): artist \n",
    "            for artist in new_artists\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(as_completed(future_to_artist), \n",
    "                         total=len(future_to_artist),\n",
    "                         desc=\"Fetching similar artists\"):\n",
    "            artist = future_to_artist[future]\n",
    "            similar_artists = future.result()\n",
    "            results[artist] = ', '.join(similar_artists)\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    combined_data = {**existing_data, **results}\n",
    "    \n",
    "    # Create and save DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        'Artist': list(combined_data.keys()),\n",
    "        'Similar Artists': list(combined_data.values())\n",
    "    })\n",
    "    \n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n‚úÖ Successfully updated database with {len(new_artists)} new artists\")\n",
    "    print(f\"Total artists in database: {len(combined_data)}\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Main execution - UPDATED FOR 2026\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "    OUTPUT_PATH = \"data/liked_artists_only_similar.csv\"\n",
    "    \n",
    "    # Run with ALL data sources\n",
    "    df_liked_similar = update_similar_artists_all_sources(API_KEY, OUTPUT_PATH)\n",
    "    \n",
    "# Now df_liked_similar is ready to use with ALL your artists\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392df38d-c607-4196-bf48-ab735338849e",
   "metadata": {},
   "source": [
    "## Quick Glance at our Refreshed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a3b87e-513b-4d1b-995e-eafba14b0ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ LOADING 2026 RETOOLED DATASETS\n",
      "============================================================\n",
      "‚úì Liked songs (network): 5667 tracks\n",
      "‚úì Training data (retooled): 11141 tracks\n",
      "  Score range: 30.0 - 100.0\n",
      "  Unique scores: 103\n",
      "  Sources: ['top_100_ranked', 'honorable_mention', 'mid', 'not_liked']\n",
      "‚úì NMF test data: 3170 tracks\n",
      "‚úì Similar artists: 4849 artists in unified network\n",
      "\n",
      "============================================================\n",
      "üéØ 2026 RETOOLING SUMMARY\n",
      "============================================================\n",
      "TRAINING DATA NOW INCLUDES:\n",
      "  ‚Ä¢ Top 100 rankings: 550 albums (100.0-60.4 sliding scale)\n",
      "  ‚Ä¢ Honorable mentions: 323 albums (60.0 flat)\n",
      "  ‚Ä¢ Mid albums: 152 albums (45.0 flat)\n",
      "  ‚Ä¢ Not liked: 321 albums (30.0 flat)\n",
      "\n",
      "TOTAL: 11141 tracks with 103 unique scores\n",
      "\n",
      "KEY CHANGE: Liked songs (100) used for PageRank network ONLY\n",
      "            NOT included in training data (prevents bias)\n",
      "\n",
      "============================================================\n",
      "üéß NMF DATA PREVIEW (What We're Predicting)\n",
      "============================================================\n",
      "Total tracks: 3170\n",
      "Unique albums: 307\n",
      "Unique artists: 594\n",
      "Most recent release: 2025-11-07\n",
      "\n",
      "üìã Sample NMF albums (5 random):\n",
      "  ‚Ä¢ Cal in Red - The Days\n",
      "  ‚Ä¢ Hether;Orion Sun - Holy Water\n",
      "  ‚Ä¢ CRRDR;ILAMIKE;animaldistinto - LATINCORE LEGEND\n",
      "  ‚Ä¢ Rianne Downey - The Consequence Of Love\n",
      "  ‚Ä¢ Skylar Grey - Angel With Tattoos\n",
      "\n",
      "üìä DATA CHECK:\n",
      "df_training columns: ['Track URI', 'Track Name', 'Album Name', 'Artist Name(s)', 'Release Date', 'Duration (ms)', 'Popularity', 'Explicit', 'Added By', 'Added At']...\n",
      "df_nmf columns: ['Track URI', 'Track Name', 'Album Name', 'Artist Name(s)', 'Release Date', 'Duration (ms)', 'Popularity', 'Explicit', 'Added By', 'Added At']...\n",
      "df_liked_similar columns: ['Artist', 'Similar Artists']\n"
     ]
    }
   ],
   "source": [
    "# === 2026 RETOOLED DATA LOADING ===\n",
    "\n",
    "print(\"üéµ LOADING 2026 RETOOLED DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Liked songs (PageRank network ONLY - NOT for training)\n",
    "df_liked = pd.read_csv(\"data/liked.csv\")\n",
    "df_liked['liked'] = 100  # For PageRank network\n",
    "df_liked['playlist_origin'] = 'df_liked_network_only'\n",
    "print(f\"‚úì Liked songs (network): {len(df_liked)} tracks\")\n",
    "\n",
    "# 2. Complete training data (Top 100 + Honorable + Mid + Not Liked)\n",
    "df_training = pd.read_csv(\"data/2026_training_complete_with_features.csv\")\n",
    "print(f\"‚úì Training data (retooled): {len(df_training)} tracks\")\n",
    "print(f\"  Score range: {df_training['liked'].min():.1f} - {df_training['liked'].max():.1f}\")\n",
    "print(f\"  Unique scores: {df_training['liked'].nunique()}\")\n",
    "print(f\"  Sources: {df_training['source_type'].unique().tolist()}\")\n",
    "\n",
    "# 3. NMF data (what we're predicting)\n",
    "df_nmf = pd.read_csv(\"data/nmf.csv\")\n",
    "df_nmf['liked'] = np.nan  # These are our predictions\n",
    "df_nmf['playlist_origin'] = 'df_nmf_test'\n",
    "print(f\"‚úì NMF test data: {len(df_nmf)} tracks\")\n",
    "\n",
    "# 4. Similar artists (unified network - ALL artists)\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')\n",
    "print(f\"‚úì Similar artists: {len(df_liked_similar)} artists in unified network\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ 2026 RETOOLING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING DATA NOW INCLUDES:\")\n",
    "print(f\"  ‚Ä¢ Top 100 rankings: 550 albums (100.0-60.4 sliding scale)\")\n",
    "print(f\"  ‚Ä¢ Honorable mentions: 323 albums (60.0 flat)\")\n",
    "print(f\"  ‚Ä¢ Mid albums: 152 albums (45.0 flat)\")\n",
    "print(f\"  ‚Ä¢ Not liked: 321 albums (30.0 flat)\")\n",
    "print(f\"\\nTOTAL: {len(df_training)} tracks with {df_training['liked'].nunique()} unique scores\")\n",
    "print(\"\\nKEY CHANGE: Liked songs (100) used for PageRank network ONLY\")\n",
    "print(\"            NOT included in training data (prevents bias)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéß NMF DATA PREVIEW (What We're Predicting)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total tracks: {len(df_nmf)}\")\n",
    "print(f\"Unique albums: {df_nmf['Album Name'].nunique()}\")\n",
    "print(f\"Unique artists: {df_nmf['Artist Name(s)'].nunique()}\")\n",
    "\n",
    "# Get most recent NMF date\n",
    "if 'Release Date' in df_nmf.columns:\n",
    "    df_nmf['Release Date'] = pd.to_datetime(df_nmf['Release Date'], errors='coerce')\n",
    "    nmf_date = df_nmf['Release Date'].max()\n",
    "    print(f\"Most recent release: {nmf_date.date() if not pd.isna(nmf_date) else 'Unknown'}\")\n",
    "\n",
    "print(\"\\nüìã Sample NMF albums (5 random):\")\n",
    "sample_albums = df_nmf[['Artist Name(s)', 'Album Name']].drop_duplicates().sample(5, random_state=42)\n",
    "for idx, row in sample_albums.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['Artist Name(s)']} - {row['Album Name']}\")\n",
    "\n",
    "print(\"\\nüìä DATA CHECK:\")\n",
    "print(f\"df_training columns: {df_training.columns.tolist()[:10]}...\")\n",
    "print(f\"df_nmf columns: {df_nmf.columns.tolist()[:10]}...\")\n",
    "print(f\"df_liked_similar columns: {df_liked_similar.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b5d9ee-7eae-44f4-aee7-98f89b3142b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING 2026 RETOOLED DATA DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "üéØ TRAINING DATA SCORE DISTRIBUTION:\n",
      "\n",
      "Top 10 scores (highest):\n",
      "  100.0: 58 tracks\n",
      "  99.6: 86 tracks\n",
      "  99.2: 63 tracks\n",
      "  98.8: 51 tracks\n",
      "  98.4: 53 tracks\n",
      "  98.0: 76 tracks\n",
      "  97.6: 66 tracks\n",
      "  97.2: 60 tracks\n",
      "  96.8: 36 tracks\n",
      "  96.4: 42 tracks\n",
      "\n",
      "Bottom 10 scores (lowest):\n",
      "  62.8: 52 tracks\n",
      "  62.4: 43 tracks\n",
      "  62.0: 49 tracks\n",
      "  61.6: 52 tracks\n",
      "  61.2: 44 tracks\n",
      "  60.8: 47 tracks\n",
      "  60.4: 46 tracks\n",
      "  60.0: 3112 tracks\n",
      "  45.0: 1150 tracks\n",
      "  30.0: 1784 tracks\n",
      "\n",
      "üìä DISTRIBUTION BY SOURCE TYPE:\n",
      "  top_100_ranked: 5095 tracks (avg score: 80.7)\n",
      "  honorable_mention: 3112 tracks (avg score: 60.0)\n",
      "  not_liked: 1784 tracks (avg score: 30.0)\n",
      "  mid: 1150 tracks (avg score: 45.0)\n",
      "\n",
      "üéß NMF DATA CHECK:\n",
      "  Tracks: 3170\n",
      "  Unique albums: 307\n",
      "  Target 'liked' column: 3170 NaN (correct - we predict these)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ 2026 Retooled data verified!\n",
      "   Training: 11141 tracks, 103 unique scores\n",
      "   Network: 5667 liked tracks for PageRank\n",
      "   Test: 3170 NMF tracks to predict\n"
     ]
    }
   ],
   "source": [
    "# === CHECK 2026 RETOOLED DATA ===\n",
    "\n",
    "print(\"üîç CHECKING 2026 RETOOLED DATA DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check training data scores\n",
    "print(\"\\nüéØ TRAINING DATA SCORE DISTRIBUTION:\")\n",
    "score_counts = df_training['liked'].value_counts().sort_index(ascending=False)\n",
    "\n",
    "# Show top 10 and bottom 10 scores\n",
    "print(\"\\nTop 10 scores (highest):\")\n",
    "for score, count in list(score_counts.items())[:10]:\n",
    "    print(f\"  {score:.1f}: {count} tracks\")\n",
    "\n",
    "print(\"\\nBottom 10 scores (lowest):\")\n",
    "for score, count in list(score_counts.items())[-10:]:\n",
    "    print(f\"  {score:.1f}: {count} tracks\")\n",
    "\n",
    "# Show distribution by source type\n",
    "print(\"\\nüìä DISTRIBUTION BY SOURCE TYPE:\")\n",
    "source_counts = df_training['source_type'].value_counts()\n",
    "for source, count in source_counts.items():\n",
    "    avg_score = df_training[df_training['source_type'] == source]['liked'].mean()\n",
    "    print(f\"  {source}: {count} tracks (avg score: {avg_score:.1f})\")\n",
    "\n",
    "# Quick check of NMF data\n",
    "print(f\"\\nüéß NMF DATA CHECK:\")\n",
    "print(f\"  Tracks: {len(df_nmf)}\")\n",
    "print(f\"  Unique albums: {df_nmf['Album Name'].nunique()}\")\n",
    "print(f\"  Target 'liked' column: {df_nmf['liked'].isna().sum()} NaN (correct - we predict these)\")\n",
    "\n",
    "# Show a quick visualization of score distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "# Histogram of all scores\n",
    "plt.hist(df_training['liked'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Data Score Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Boxplot by source type\n",
    "source_order = ['top_100_ranked', 'honorable_mention', 'mid', 'not_liked']\n",
    "plot_data = [df_training[df_training['source_type'] == source]['liked'] for source in source_order]\n",
    "plt.boxplot(plot_data, labels=source_order)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score Distribution by Source Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ 2026 Retooled data verified!\")\n",
    "print(f\"   Training: {len(df_training)} tracks, {df_training['liked'].nunique()} unique scores\")\n",
    "print(f\"   Network: {len(df_liked)} liked tracks for PageRank\")\n",
    "print(f\"   Test: {len(df_nmf)} NMF tracks to predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f1b3f8-5d45-4d10-b9fd-3c339f558ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚öôÔ∏è  PREPARING FOR FEATURE ENGINEERING\n",
      "============================================================\n",
      "Checking available features in training data...\n",
      "Training data columns: 28 total\n",
      "\n",
      "Spotify audio features available: ['Danceability', 'Energy', 'Key', 'Loudness', 'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Popularity']\n",
      "\n",
      "üîç Checking for missing values in training data:\n",
      "  Artist Name(s): 0 missing (0.0%)\n",
      "  Album Name: 0 missing (0.0%)\n",
      "  Genres: 5534 missing (49.7%)\n",
      "  Record Label: 75 missing (0.7%)\n",
      "  liked: 0 missing (0.0%)\n",
      "\n",
      "‚úÖ Ready for feature engineering!\n"
     ]
    }
   ],
   "source": [
    "# === FEATURE ENGINEERING SETUP ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚öôÔ∏è  PREPARING FOR FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check what features we have\n",
    "print(\"Checking available features in training data...\")\n",
    "print(f\"Training data columns: {len(df_training.columns)} total\")\n",
    "\n",
    "# Identify feature columns vs metadata\n",
    "feature_cols = ['Danceability', 'Energy', 'Key', 'Loudness', 'Mode', \n",
    "                'Speechiness', 'Acousticness', 'Instrumentalness', \n",
    "                'Liveness', 'Valence', 'Tempo', 'Popularity']\n",
    "\n",
    "print(f\"\\nSpotify audio features available: {[col for col in feature_cols if col in df_training.columns]}\")\n",
    "\n",
    "# Check for missing values in key columns\n",
    "print(\"\\nüîç Checking for missing values in training data:\")\n",
    "for col in ['Artist Name(s)', 'Album Name', 'Genres', 'Record Label', 'liked']:\n",
    "    if col in df_training.columns:\n",
    "        missing = df_training[col].isna().sum()\n",
    "        print(f\"  {col}: {missing} missing ({missing/len(df_training)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready for feature engineering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2580a-e10a-4d8f-a9fc-258a2777d37f",
   "metadata": {},
   "source": [
    "#### Drop columns that won't help the model üí£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a1551b-d6a6-4ff4-b5f3-f333f2e4e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ CLEANING UNNECESSARY COLUMNS\n",
      "============================================================\n",
      "Dropping unnecessary columns...\n",
      "  df_training: Dropped 3 columns (['Added By', 'Added At', 'Time Signature'])\n",
      "  df_liked: Dropped 3 columns (['Added By', 'Added At', 'Time Signature'])\n",
      "  df_nmf: Dropped 3 columns (['Added By', 'Added At', 'Time Signature'])\n",
      "\n",
      "üìä CLEANED DATA SHAPES:\n",
      "  df_training: 11141 rows √ó 25 columns\n",
      "  df_liked: 5667 rows √ó 23 columns\n",
      "  df_nmf: 3170 rows √ó 23 columns\n",
      "\n",
      "üîç CHECKING FOR OTHER UNNECESSARY COLUMNS:\n",
      "No obvious useless columns found.\n",
      "\n",
      "‚úÖ Data cleanup complete!\n",
      "   Removed timestamp/added columns that don't help predictions.\n"
     ]
    }
   ],
   "source": [
    "# === 2026 DATA CLEANUP ===\n",
    "\n",
    "print(\"üßπ CLEANING UNNECESSARY COLUMNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Columns to drop from ALL dataframes\n",
    "columns_to_drop = ['Added By', 'Added At', 'Time Signature']\n",
    "\n",
    "# Apply to each dataframe\n",
    "print(\"Dropping unnecessary columns...\")\n",
    "for df_name, dataframe in [('df_training', df_training), ('df_liked', df_liked), ('df_nmf', df_nmf)]:\n",
    "    before = len(dataframe.columns)\n",
    "    \n",
    "    # Only drop columns that exist\n",
    "    cols_exist = [col for col in columns_to_drop if col in dataframe.columns]\n",
    "    if cols_exist:\n",
    "        dataframe.drop(columns=cols_exist, inplace=True, errors='ignore')\n",
    "        after = len(dataframe.columns)\n",
    "        print(f\"  {df_name}: Dropped {before - after} columns ({cols_exist})\")\n",
    "    else:\n",
    "        print(f\"  {df_name}: No columns to drop\")\n",
    "\n",
    "print(\"\\nüìä CLEANED DATA SHAPES:\")\n",
    "print(f\"  df_training: {df_training.shape[0]} rows √ó {df_training.shape[1]} columns\")\n",
    "print(f\"  df_liked: {df_liked.shape[0]} rows √ó {df_liked.shape[1]} columns\")\n",
    "print(f\"  df_nmf: {df_nmf.shape[0]} rows √ó {df_nmf.shape[1]} columns\")\n",
    "\n",
    "# Quick check for other unnecessary columns\n",
    "print(\"\\nüîç CHECKING FOR OTHER UNNECESSARY COLUMNS:\")\n",
    "all_columns = set(df_training.columns) | set(df_liked.columns) | set(df_nmf.columns)\n",
    "\n",
    "# Identify potentially useless columns\n",
    "useless_patterns = ['Unnamed:', 'Unnamed_', 'Unnamed ', 'index', 'id_', '_id']\n",
    "useless_cols = [col for col in all_columns if any(pattern in str(col) for pattern in useless_patterns)]\n",
    "\n",
    "if useless_cols:\n",
    "    print(f\"Found {len(useless_cols)} potentially useless columns:\")\n",
    "    for col in useless_cols[:10]:  # Show first 10\n",
    "        print(f\"  ‚Ä¢ {col}\")\n",
    "    print(\"Consider removing these if they're not needed for features.\")\n",
    "else:\n",
    "    print(\"No obvious useless columns found.\")\n",
    "\n",
    "print(\"\\n‚úÖ Data cleanup complete!\")\n",
    "print(\"   Removed timestamp/added columns that don't help predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff07c-0b26-47bf-af09-6c87b741ba13",
   "metadata": {},
   "source": [
    "#### Handle missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d7d185-71c3-4aa3-8b81-8920a76aa070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING FOR MISSING VALUES\n",
      "============================================================\n",
      "Training Data (df_training):\n",
      "Genres              5534\n",
      "training_year       2934\n",
      "Energy                81\n",
      "Tempo                 81\n",
      "Valence               81\n",
      "Liveness              81\n",
      "Instrumentalness      81\n",
      "Acousticness          81\n",
      "Speechiness           81\n",
      "Mode                  81\n",
      "Loudness              81\n",
      "Key                   81\n",
      "Danceability          81\n",
      "Record Label          75\n",
      "Explicit              75\n",
      "dtype: int64\n",
      "\n",
      "NMF Data (df_nmf):\n",
      "liked               3170\n",
      "Genres              1273\n",
      "Energy                 3\n",
      "Loudness               3\n",
      "Tempo                  3\n",
      "Valence                3\n",
      "Liveness               3\n",
      "Instrumentalness       3\n",
      "Acousticness           3\n",
      "Speechiness            3\n",
      "Danceability           3\n",
      "Mode                   3\n",
      "Key                    3\n",
      "Track URI              0\n",
      "Track Name             0\n",
      "dtype: int64\n",
      "\n",
      "Liked Songs (df_liked - PageRank only):\n",
      "Genres              2870\n",
      "Record Label           3\n",
      "Track URI              0\n",
      "Loudness               0\n",
      "liked                  0\n",
      "Tempo                  0\n",
      "Valence                0\n",
      "Liveness               0\n",
      "Instrumentalness       0\n",
      "Acousticness           0\n",
      "dtype: int64\n",
      "\n",
      "============================================================\n",
      "üéØ KEY COLUMNS MISSING VALUES CHECK\n",
      "============================================================\n",
      "\n",
      "Training:\n",
      "  Artist Name(s): 0/11141 missing (0.0%)\n",
      "  Album Name: 0/11141 missing (0.0%)\n",
      "  Genres: 5534/11141 missing (49.7%)\n",
      "  Record Label: 75/11141 missing (0.7%)\n",
      "  liked: 0/11141 missing (0.0%)\n",
      "\n",
      "NMF:\n",
      "  Artist Name(s): 0/3170 missing (0.0%)\n",
      "  Album Name: 0/3170 missing (0.0%)\n",
      "  Genres: 1273/3170 missing (40.2%)\n",
      "  Record Label: 0/3170 missing (0.0%)\n",
      "  liked: 3170/3170 missing (100.0%)\n",
      "\n",
      "Liked:\n",
      "  Artist Name(s): 0/5667 missing (0.0%)\n",
      "  Album Name: 0/5667 missing (0.0%)\n",
      "  Genres: 2870/5667 missing (50.6%)\n",
      "  Record Label: 3/5667 missing (0.1%)\n",
      "  liked: 0/5667 missing (0.0%)\n",
      "\n",
      "‚úÖ Missing values check complete!\n",
      "   Note: 'liked' should be NaN for NMF (we predict these)\n",
      "   Note: Genres/Record Label might have missing values (will be filled)\n"
     ]
    }
   ],
   "source": [
    "# === CHECK MISSING VALUES IN ALL DATAFRAMES ===\n",
    "\n",
    "print(\"üîç CHECKING FOR MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Training Data (df_training):\")\n",
    "print(df_training.isna().sum().sort_values(ascending=False).head(15))\n",
    "\n",
    "print(\"\\nNMF Data (df_nmf):\")\n",
    "print(df_nmf.isna().sum().sort_values(ascending=False).head(15))\n",
    "\n",
    "print(\"\\nLiked Songs (df_liked - PageRank only):\")\n",
    "print(df_liked.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# Focus on key columns\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ KEY COLUMNS MISSING VALUES CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "key_columns = ['Artist Name(s)', 'Album Name', 'Genres', 'Record Label', 'liked']\n",
    "\n",
    "for df_name, dataframe in [('Training', df_training), ('NMF', df_nmf), ('Liked', df_liked)]:\n",
    "    print(f\"\\n{df_name}:\")\n",
    "    for col in key_columns:\n",
    "        if col in dataframe.columns:\n",
    "            missing = dataframe[col].isna().sum()\n",
    "            total = len(dataframe)\n",
    "            pct = (missing / total * 100) if total > 0 else 0\n",
    "            print(f\"  {col}: {missing}/{total} missing ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Missing values check complete!\")\n",
    "print(\"   Note: 'liked' should be NaN for NMF (we predict these)\")\n",
    "print(\"   Note: Genres/Record Label might have missing values (will be filled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658750-d956-442d-99ed-2dca4323ec47",
   "metadata": {},
   "source": [
    "## Getting New Genre Data From Last.fm üü¢üéµ\n",
    "Since half of the genres are missing from Spotify songs, I decided to use the richer data from Last.fm's crowd-sourced genre tags. There are some silly tags in there, so I added a list of ignored tags that I update weekly based on what I see in the data. This ensures the genres are meaningful and relevant for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56682c80-8458-413a-a614-417070e35ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ 2026 Genre Data Integration\n",
      "============================================================\n",
      "Assessing genre data coverage...\n",
      "\n",
      "üìä Current Genre Coverage:\n",
      "  Training Data: 50.3% (5,534 missing)\n",
      "  NMF Data: 59.8% (1,273 missing)\n",
      "  Liked Songs: 49.4% (2,870 missing)\n",
      "\n",
      "  TOTAL: 9,677 tracks missing genres out of 19,978\n",
      "\n",
      "‚ö†Ô∏è  9,677 tracks require genre data\n",
      "Proceeding with Last.fm API integration...\n",
      "\n",
      "üîç Unique artist-album pairs to process: 5,497\n",
      "  Existing genre cache: 5,322 artist-album pairs\n",
      "\n",
      "üì° Last.fm API integration required for complete genre data\n",
      "   Implementation includes:\n",
      "   - API rate limiting and error handling\n",
      "   - Genre tag cleaning and standardization\n",
      "   - Cache management for efficient updates\n",
      "   - Fallback to artist tags when album tags unavailable\n",
      "\n",
      "‚è∏Ô∏è  Skipping API calls in this run to preserve rate limits\n",
      "   To execute full genre fetch, uncomment API implementation section\n",
      "\n",
      "============================================================\n",
      "Next Steps:\n",
      "1. If missing genres > 0: Implement Last.fm API calls\n",
      "2. Merge fetched genres into all dataframes\n",
      "3. Proceed to feature engineering\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# === 2026 GENRE DATA INTEGRATION ===\n",
    "\n",
    "print(\"üéµ 2026 Genre Data Integration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Assess current genre coverage\n",
    "print(\"Assessing genre data coverage...\")\n",
    "\n",
    "def assess_genre_coverage(dataframe, dataset_name):\n",
    "    \"\"\"Calculate percentage of tracks with genre data\"\"\"\n",
    "    if 'Genres' not in dataframe.columns:\n",
    "        return 0, len(dataframe)\n",
    "    \n",
    "    missing_genres = dataframe['Genres'].isna().sum()\n",
    "    total_tracks = len(dataframe)\n",
    "    coverage_pct = ((total_tracks - missing_genres) / total_tracks * 100) if total_tracks > 0 else 0\n",
    "    return coverage_pct, missing_genres\n",
    "\n",
    "# Calculate coverage for all datasets\n",
    "train_coverage, train_missing = assess_genre_coverage(df_training, \"Training\")\n",
    "nmf_coverage, nmf_missing = assess_genre_coverage(df_nmf, \"NMF\") \n",
    "liked_coverage, liked_missing = assess_genre_coverage(df_liked, \"Liked\")\n",
    "\n",
    "total_missing_genres = train_missing + nmf_missing + liked_missing\n",
    "total_tracks = len(df_training) + len(df_nmf) + len(df_liked)\n",
    "\n",
    "print(f\"\\nüìä Current Genre Coverage:\")\n",
    "print(f\"  Training Data: {train_coverage:.1f}% ({train_missing:,} missing)\")\n",
    "print(f\"  NMF Data: {nmf_coverage:.1f}% ({nmf_missing:,} missing)\")\n",
    "print(f\"  Liked Songs: {liked_coverage:.1f}% ({liked_missing:,} missing)\")\n",
    "print(f\"\\n  TOTAL: {total_missing_genres:,} tracks missing genres out of {total_tracks:,}\")\n",
    "\n",
    "# 2. Decision: Fetch or skip?\n",
    "if total_missing_genres > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  {total_missing_genres:,} tracks require genre data\")\n",
    "    print(\"Proceeding with Last.fm API integration...\")\n",
    "    \n",
    "    # Combine all data for processing\n",
    "    all_artist_albums = pd.concat([\n",
    "        df_training[['Artist Name(s)', 'Album Name', 'Release Date']],\n",
    "        df_nmf[['Artist Name(s)', 'Album Name', 'Release Date']],\n",
    "        df_liked[['Artist Name(s)', 'Album Name', 'Release Date']]\n",
    "    ], ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    print(f\"\\nüîç Unique artist-album pairs to process: {len(all_artist_albums):,}\")\n",
    "    \n",
    "    # Check existing genre cache\n",
    "    genre_cache_path = \"data/ten_genres.csv\"\n",
    "    if os.path.exists(genre_cache_path):\n",
    "        existing_genres = pd.read_csv(genre_cache_path)\n",
    "        print(f\"  Existing genre cache: {len(existing_genres):,} artist-album pairs\")\n",
    "    \n",
    "    # Note: Full Last.fm API implementation would go here\n",
    "    # This would include the API calls, rate limiting, and data processing\n",
    "    print(\"\\nüì° Last.fm API integration required for complete genre data\")\n",
    "    print(\"   Implementation includes:\")\n",
    "    print(\"   - API rate limiting and error handling\")\n",
    "    print(\"   - Genre tag cleaning and standardization\")\n",
    "    print(\"   - Cache management for efficient updates\")\n",
    "    print(\"   - Fallback to artist tags when album tags unavailable\")\n",
    "    \n",
    "    print(\"\\n‚è∏Ô∏è  Skipping API calls in this run to preserve rate limits\")\n",
    "    print(\"   To execute full genre fetch, uncomment API implementation section\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚úÖ All genre data present\")\n",
    "    print(\"   Proceeding to feature engineering...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Next Steps:\")\n",
    "print(\"1. If missing genres > 0: Implement Last.fm API calls\")\n",
    "print(\"2. Merge fetched genres into all dataframes\")\n",
    "print(\"3. Proceed to feature engineering\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b250a-eb92-4eb4-a0a1-c20f0550eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ 2026 GENRE DATA UPDATE\n",
      "============================================================\n",
      "Found 1394 new artist-album pairs to process.\n",
      "Processed 50/1394 artist-album pairs.\n",
      "Processed 100/1394 artist-album pairs.\n",
      "Processed 150/1394 artist-album pairs.\n",
      "Processed 200/1394 artist-album pairs.\n",
      "API request failed for params {'method': 'artist.getTopTags', 'artist': 'Fly Anakin;Demae', 'api_key': '74a510ecc9fc62bf3e0edc6adc2e99f9', 'format': 'json'}: 500 Server Error: Internal Server Error for url: http://ws.audioscrobbler.com/2.0/?method=artist.getTopTags&artist=Fly+Anakin%3BDemae&api_key=74a510ecc9fc62bf3e0edc6adc2e99f9&format=json\n",
      "API request failed for params {'method': 'artist.getTopTags', 'artist': 'Wiz Khalifa;Don Toliver', 'api_key': '74a510ecc9fc62bf3e0edc6adc2e99f9', 'format': 'json'}: 500 Server Error: Internal Server Error for url: http://ws.audioscrobbler.com/2.0/?method=artist.getTopTags&artist=Wiz+Khalifa%3BDon+Toliver&api_key=74a510ecc9fc62bf3e0edc6adc2e99f9&format=json\n",
      "API request failed for params {'method': 'artist.getTopTags', 'artist': 'Wiz Khalifa;Luh Tyler', 'api_key': '74a510ecc9fc62bf3e0edc6adc2e99f9', 'format': 'json'}: 500 Server Error: Internal Server Error for url: http://ws.audioscrobbler.com/2.0/?method=artist.getTopTags&artist=Wiz+Khalifa%3BLuh+Tyler&api_key=74a510ecc9fc62bf3e0edc6adc2e99f9&format=json\n",
      "API request failed for params {'method': 'artist.getTopTags', 'artist': 'Wiz Khalifa;Smoke DZA', 'api_key': '74a510ecc9fc62bf3e0edc6adc2e99f9', 'format': 'json'}: 500 Server Error: Internal Server Error for url: http://ws.audioscrobbler.com/2.0/?method=artist.getTopTags&artist=Wiz+Khalifa%3BSmoke+DZA&api_key=74a510ecc9fc62bf3e0edc6adc2e99f9&format=json\n",
      "API request failed for params {'method': 'artist.getTopTags', 'artist': 'Wiz Khalifa;RMR', 'api_key': '74a510ecc9fc62bf3e0edc6adc2e99f9', 'format': 'json'}: 500 Server Error: Internal Server Error for url: http://ws.audioscrobbler.com/2.0/?method=artist.getTopTags&artist=Wiz+Khalifa%3BRMR&api_key=74a510ecc9fc62bf3e0edc6adc2e99f9&format=json\n",
      "API request failed for params {'method': 'artist.getTopTags', 'artist': 'Wiz Khalifa;Larry June', 'api_key': '74a510ecc9fc62bf3e0edc6adc2e99f9', 'format': 'json'}: 500 Server Error: Internal Server Error for url: http://ws.audioscrobbler.com/2.0/?method=artist.getTopTags&artist=Wiz+Khalifa%3BLarry+June&api_key=74a510ecc9fc62bf3e0edc6adc2e99f9&format=json\n",
      "Processed 250/1394 artist-album pairs.\n",
      "Processed 300/1394 artist-album pairs.\n",
      "Processed 350/1394 artist-album pairs.\n",
      "Processed 400/1394 artist-album pairs.\n",
      "Processed 450/1394 artist-album pairs.\n",
      "Processed 500/1394 artist-album pairs.\n",
      "Processed 550/1394 artist-album pairs.\n",
      "Processed 600/1394 artist-album pairs.\n",
      "Processed 650/1394 artist-album pairs.\n",
      "Processed 700/1394 artist-album pairs.\n",
      "Processed 750/1394 artist-album pairs.\n",
      "Processed 800/1394 artist-album pairs.\n",
      "Processed 850/1394 artist-album pairs.\n"
     ]
    }
   ],
   "source": [
    "class LastFMGenreFetcher:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "\n",
    "        # Tags more about taste than genre\n",
    "        self.ignored_tags = {\n",
    "            'seen live', 'albums i own', 'favorite', 'favourites', 'favourite',\n",
    "            'my playlist', 'spotify', 'pandora', 'wish i had seen live', 'awesome',\n",
    "            'love at first listen', 'love', 'amazing', 'listened', 'personal', 'my music'\n",
    "        }\n",
    "\n",
    "        # Female vocalist standardization\n",
    "        self.female_vocalist_variants = {\n",
    "            'female vocalists', 'female vocalist', 'female vocals', 'female fronted',\n",
    "            'female voices', 'female voice', 'female singers', 'female singer'\n",
    "        }\n",
    "\n",
    "        # Genre compatibilities\n",
    "        self.genre_compatibility = {\n",
    "            'indie': ['indie pop', 'indie rock', 'indie folk', 'alternative', 'singer-songwriter'],\n",
    "            'rock': ['alternative rock', 'indie rock', 'hard rock', 'classic rock', 'punk'],\n",
    "            'electronic': ['techno', 'house', 'edm', 'ambient', 'idm', 'electronica'],\n",
    "            'metal': ['heavy metal', 'death metal', 'black metal', 'thrash metal', 'doom metal'],\n",
    "            'folk': ['indie folk', 'folk rock', 'americana', 'singer-songwriter', 'acoustic'],\n",
    "            'pop': ['indie pop', 'synth pop', 'dream pop', 'electropop', 'pop rock'],\n",
    "            'hip-hop': ['rap', 'trap', 'r&b', 'urban', 'grime'],\n",
    "            'jazz': ['fusion', 'bebop', 'smooth jazz', 'soul', 'funk'],\n",
    "            'classical': ['orchestral', 'chamber music', 'piano', 'instrumental', 'contemporary classical']\n",
    "        }\n",
    "\n",
    "        # Genres that rarely mix\n",
    "        self.genre_incompatibility = {\n",
    "            'classical': ['metal', 'rap', 'edm', 'techno', 'dubstep'],\n",
    "            'death metal': ['pop', 'r&b', 'jazz', 'folk', 'ambient'],\n",
    "            'christian': ['black metal', 'satanic', 'pagan'],\n",
    "            'country': ['techno', 'edm', 'black metal', 'death metal'],\n",
    "            'jazz': ['black metal', 'death metal', 'hardcore', 'screamo'],\n",
    "            'k-pop': ['death metal', 'black metal', 'doom metal']\n",
    "        }\n",
    "\n",
    "    def _make_request(self, params: dict) -> dict:\n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            sleep(self.rate_limit_delay)\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed for params {params}: {e}\")\n",
    "            if getattr(response, 'status_code', None) == 429:\n",
    "                self.rate_limit_delay *= 2\n",
    "                print(\"Rate limit hit, slowing down...\")\n",
    "                sleep(5)\n",
    "            return None\n",
    "\n",
    "    def get_artist_tags(self, artist_name: str) -> list[str]:\n",
    "        params = {'method': 'artist.getTopTags', 'artist': artist_name, 'api_key': self.api_key, 'format': 'json'}\n",
    "        data = self._make_request(params)\n",
    "        if not data or 'toptags' not in data:\n",
    "            return []\n",
    "\n",
    "        tags, seen_tags, has_female_vocalist = [], set(), False\n",
    "        for tag in data['toptags'].get('tag', []):\n",
    "            tag_name = tag['name'].lower()\n",
    "            if tag_name in self.ignored_tags:\n",
    "                continue\n",
    "            if tag_name in self.female_vocalist_variants:\n",
    "                if not has_female_vocalist:\n",
    "                    tags.insert(0, 'female vocalist')\n",
    "                    has_female_vocalist = True\n",
    "                continue\n",
    "            if tag_name not in seen_tags:\n",
    "                tags.append(tag_name)\n",
    "                seen_tags.add(tag_name)\n",
    "        return tags[:10]\n",
    "\n",
    "    def get_album_tags(self, artist_name: str, album_name: str, release_date: str = None) -> list[str]:\n",
    "        params = {'method': 'album.getTopTags', 'artist': artist_name, 'album': album_name, 'api_key': self.api_key, 'format': 'json'}\n",
    "        album_data = self._make_request(params)\n",
    "        artist_tags = self.get_artist_tags(artist_name)\n",
    "\n",
    "        album_tags = []\n",
    "        if album_data and 'toptags' in album_data and 'tag' in album_data['toptags']:\n",
    "            album_tags = [tag['name'].lower() for tag in album_data['toptags']['tag'] if tag['name'].lower() not in self.ignored_tags]\n",
    "\n",
    "        if album_tags and artist_tags:\n",
    "            return self._verify_tags(album_tags, artist_tags, release_date)[:10]\n",
    "        elif album_tags:\n",
    "            return album_tags[:10]\n",
    "        else:\n",
    "            return artist_tags[:10]\n",
    "\n",
    "    def _verify_tags(self, album_tags: list[str], artist_tags: list[str], release_date: str = None) -> list[str]:\n",
    "        album_set, artist_set = set(album_tags), set(artist_tags)\n",
    "        overlap_ratio = len(album_set & artist_set) / len(album_set) if album_set else 0\n",
    "        if overlap_ratio >= 0.3:\n",
    "            return album_tags\n",
    "\n",
    "        for tag in album_tags:\n",
    "            for inc_genre, inc_tags in self.genre_incompatibility.items():\n",
    "                if tag == inc_genre and any(t in inc_tags for t in artist_tags):\n",
    "                    return artist_tags\n",
    "\n",
    "        if release_date:\n",
    "            try:\n",
    "                year = int(release_date.split('-')[0])\n",
    "                current_year = datetime.now().year\n",
    "                if year >= current_year - 2:\n",
    "                    return album_tags[:7] + [t for t in artist_tags if t not in album_set][:3]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return album_tags[:7] + [t for t in artist_tags if t not in album_set][:3]\n",
    "\n",
    "\n",
    "def update_genre_data(api_key: str, dataframes: List[pd.DataFrame], output_file: str = 'data/ten_genres.csv') -> None:\n",
    "    api = LastFMGenreFetcher(api_key)\n",
    "    \n",
    "    # Cache for artist tags\n",
    "    artist_tags_cache = {}\n",
    "\n",
    "    def get_album_tags_cached(artist_name, album_name, release_date=None):\n",
    "        if artist_name not in artist_tags_cache:\n",
    "            artist_tags_cache[artist_name] = api.get_artist_tags(artist_name)\n",
    "        artist_tags = artist_tags_cache[artist_name]\n",
    "\n",
    "        params = {\n",
    "            'method': 'album.getTopTags',\n",
    "            'artist': artist_name,\n",
    "            'album': album_name,\n",
    "            'api_key': api.api_key,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        album_data = api._make_request(params)\n",
    "        \n",
    "        album_tags = []\n",
    "        if album_data and 'toptags' in album_data and 'tag' in album_data['toptags']:\n",
    "            for tag in album_data['toptags']['tag']:\n",
    "                tag_name = tag['name'].lower().strip()\n",
    "                if tag_name not in api.ignored_tags:\n",
    "                    album_tags.append(tag_name)\n",
    "        \n",
    "        if album_tags:\n",
    "            return api._verify_tags(album_tags, artist_tags, release_date)[:10]\n",
    "        else:\n",
    "            return artist_tags[:10]\n",
    "\n",
    "    # Gather all unique artist-album pairs\n",
    "    artist_album_pairs = []\n",
    "    for df in dataframes:\n",
    "        if 'Artist Name(s)' in df.columns and 'Album Name' in df.columns and 'Release Date' in df.columns:\n",
    "            pairs = df[['Artist Name(s)', 'Album Name', 'Release Date']].drop_duplicates()\n",
    "            for _, row in pairs.iterrows():\n",
    "                artist = row['Artist Name(s)'].split(',')[0].strip() if pd.notna(row['Artist Name(s)']) else None\n",
    "                album = row['Album Name'].strip() if pd.notna(row['Album Name']) else None\n",
    "                release_date = row['Release Date'] if pd.notna(row['Release Date']) else None\n",
    "                if artist and album:\n",
    "                    artist_album_pairs.append((artist.lower(), album.lower(), release_date))\n",
    "\n",
    "    # Load existing data with normalization\n",
    "    existing_data = {}\n",
    "    if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "        try:\n",
    "            df_existing = pd.read_csv(output_file)\n",
    "            df_existing['Artist'] = df_existing['Artist'].str.lower().str.strip()\n",
    "            df_existing['Album'] = df_existing['Album'].str.lower().str.strip()\n",
    "            existing_data = df_existing.set_index(['Artist', 'Album'])['Genres'].to_dict()\n",
    "        except (pd.errors.EmptyDataError, KeyError):\n",
    "            print(\"No existing genre data found or file is empty. Starting fresh.\")\n",
    "\n",
    "    # Load obscure artist genres\n",
    "    obscure_artists = pd.read_csv(\"data/obscure_artists_mike_likes.csv\", quotechar='\"')\n",
    "    obscure_artists_dict = { (row['Artist'].lower().strip(), 'any_album'): row['Genres'] for _, row in obscure_artists.iterrows() }\n",
    "    existing_data.update(obscure_artists_dict)\n",
    "\n",
    "    # Identify new artist-album pairs\n",
    "    normalized_existing = set(existing_data.keys())\n",
    "    new_pairs = [\n",
    "        (artist, album, release_date)\n",
    "        for artist, album, release_date in artist_album_pairs\n",
    "        if (artist, album) not in normalized_existing\n",
    "    ]\n",
    "\n",
    "    if not new_pairs:\n",
    "        print(\"No new artist-album pairs to process!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(new_pairs)} new artist-album pairs to process.\")\n",
    "\n",
    "    # Process new pairs in parallel\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=25) as executor:\n",
    "        future_to_pair = {\n",
    "            executor.submit(get_album_tags_cached, artist, album, release_date): (artist, album)\n",
    "            for artist, album, release_date in new_pairs\n",
    "        }\n",
    "\n",
    "        completed = 0\n",
    "        for future in as_completed(future_to_pair):\n",
    "            artist, album = future_to_pair[future]\n",
    "            try:\n",
    "                tags = future.result()\n",
    "                if tags:\n",
    "                    results[(artist, album)] = ', '.join(tags)\n",
    "                completed += 1\n",
    "                if completed % 50 == 0 or (len(new_pairs) < 50 and completed % 10 == 0):\n",
    "                    print(f\"Processed {completed}/{len(new_pairs)} artist-album pairs.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {artist} - {album}: {e}\")\n",
    "\n",
    "    # Combine existing and new data\n",
    "    all_data = {**existing_data, **results}\n",
    "\n",
    "    # Save to CSV\n",
    "    df_output = pd.DataFrame(\n",
    "        [{'Artist': artist, 'Album': album, 'Genres': genres} for (artist, album), genres in all_data.items()]\n",
    "    )\n",
    "    df_output.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSuccessfully updated {output_file} with {len(results)} new artist-album pairs!\")\n",
    "\n",
    "# Define genre cleaning function\n",
    "def clean_genres(genre_string):\n",
    "    \"\"\"\n",
    "    Clean genre strings by:\n",
    "    1. Removing duplicates\n",
    "    2. Removing '|' bars\n",
    "    3. Filtering out genres with numbers\n",
    "    4. Filtering out genres longer than 3 words\n",
    "    \"\"\"\n",
    "    if pd.isna(genre_string):\n",
    "        return genre_string\n",
    "        \n",
    "    # Split by | and flatten all genres into one list\n",
    "    all_parts = [part.strip() for part in genre_string.split('|')]\n",
    "    all_genres = []\n",
    "    for part in all_parts:\n",
    "        genres = [g.strip() for g in part.split(',')]\n",
    "        all_genres.extend(genres)\n",
    "    \n",
    "    # Remove duplicates, numbers, and long genres while preserving order\n",
    "    seen = set()\n",
    "    unique_genres = []\n",
    "    for genre in all_genres:\n",
    "        # Skip if empty\n",
    "        if not genre:\n",
    "            continue\n",
    "        \n",
    "        # Skip if contains digits\n",
    "        if any(char.isdigit() for char in genre):\n",
    "            continue\n",
    "            \n",
    "        # Skip if longer than 3 words\n",
    "        if len(genre.split()) > 3:\n",
    "            continue\n",
    "            \n",
    "        # Add if not seen before (case-insensitive check)\n",
    "        if genre.lower() not in seen:\n",
    "            unique_genres.append(genre)\n",
    "            seen.add(genre.lower())\n",
    "    \n",
    "    return ', '.join(unique_genres)\n",
    "\n",
    "# === REFACTORED 2026 GENRE FETCHER ===\n",
    "\n",
    "print(\"üéµ 2026 GENRE DATA UPDATE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine all 2026 data\n",
    "df_combined = pd.concat([\n",
    "    df_training[['Artist Name(s)', 'Album Name', 'Release Date']],\n",
    "    df_nmf[['Artist Name(s)', 'Album Name', 'Release Date']],\n",
    "    df_liked[['Artist Name(s)', 'Album Name', 'Release Date']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Run the genre fetching\n",
    "API_KEY = '74a510ecc9fc62bf3e0edc6adc2e99f9'\n",
    "update_genre_data(API_KEY, [df_combined], 'data/ten_genres.csv')\n",
    "\n",
    "# Load updated genre data\n",
    "ten_genres = pd.read_csv(\"data/ten_genres.csv\")\n",
    "ten_genres[\"Genres\"] = ten_genres[\"Genres\"].apply(clean_genres)\n",
    "ten_genres[\"Primary Artist\"] = ten_genres[\"Artist\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "print(\"\\nüîÑ Merging genres back into dataframes...\")\n",
    "\n",
    "# Update each dataframe with new genres\n",
    "for df_name, dataframe in [(\"Training\", df_training), (\"NMF\", df_nmf), (\"Liked\", df_liked)]:\n",
    "    print(f\"  Updating {df_name}...\")\n",
    "    \n",
    "    # Add primary artist column for merging\n",
    "    dataframe[\"Primary Artist\"] = dataframe[\"Artist Name(s)\"].str.split(\",\").str[0].str.strip()\n",
    "    \n",
    "    # Merge with genre data\n",
    "    merged = dataframe.merge(\n",
    "        ten_genres[[\"Primary Artist\", \"Genres\"]],\n",
    "        on=\"Primary Artist\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_new\")\n",
    "    )\n",
    "    \n",
    "    # Update genres (use new if available, otherwise keep old)\n",
    "    if \"Genres\" in merged.columns:\n",
    "        dataframe[\"Genres\"] = merged[\"Genres_new\"].combine_first(merged[\"Genres\"])\n",
    "    else:\n",
    "        dataframe[\"Genres\"] = merged[\"Genres_new\"]\n",
    "    \n",
    "    # Clean the genres\n",
    "    dataframe[\"Genres\"] = dataframe[\"Genres\"].apply(clean_genres)\n",
    "    \n",
    "    # Remove helper column\n",
    "    dataframe.drop(columns=[\"Primary Artist\"], inplace=True, errors='ignore')\n",
    "    \n",
    "    # Count updates\n",
    "    updated = merged[\"Genres_new\"].notna().sum()\n",
    "    missing = dataframe[\"Genres\"].isna().sum()\n",
    "    print(f\"    ‚Üí Updated {updated} tracks, {missing} still missing\")\n",
    "\n",
    "print(\"\\n‚úÖ All 2026 dataframes updated!\")\n",
    "print(f\"\\nüìä FINAL GENRE COVERAGE:\")\n",
    "for df_name, dataframe in [(\"Training\", df_training), (\"NMF\", df_nmf), (\"Liked\", df_liked)]:\n",
    "    missing = dataframe[\"Genres\"].isna().sum()\n",
    "    total = len(dataframe)\n",
    "    coverage = ((total - missing) / total * 100) if total > 0 else 0\n",
    "    print(f\"  {df_name}: {coverage:.1f}% ({missing}/{total} missing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85bd7777-449f-4bb8-b93d-b173dbbbbd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1395"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_pairs = set(\n",
    "    (a.strip().lower(), b.strip().lower()) \n",
    "    for a, b in ten_genres[['Artist', 'Album']].itertuples(index=False, name=None)\n",
    ")\n",
    "all_pairs = set(\n",
    "    (a.strip().lower(), b.strip().lower()) \n",
    "    for a, b in df_combined[['Artist Name(s)', 'Album Name']].itertuples(index=False, name=None)\n",
    ")\n",
    "new_pairs = all_pairs - existing_pairs\n",
    "len(new_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8f067-0f96-4c4c-8d63-7296b631a751",
   "metadata": {},
   "source": [
    "### Save a Copy of the Missing Genre Artists (Just in Case I Want to Fuss With It Later!) üïµÔ∏è‚Äç‚ôÇÔ∏èüé∂\n",
    "Even with Last.fm‚Äôs extensive data, some artists still slip through the cracks. To handle these edge cases, I‚Äôm saving a list of artists with missing genre data to a separate file. This way, I can manually review and assign genres later if needed. Think of it as a backup plan for those hard-to-categorize artists! üéß‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada40922-e667-48b7-aa4f-a87e06a9112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ten_genres.csv file\n",
    "ten_genres = pd.read_csv(\"data/ten_genres.csv\")\n",
    "\n",
    "# Extract the primary artist from both datasets\n",
    "# For artists with collaborators, we focus on the first name listed üé§\n",
    "df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0].str.strip()\n",
    "ten_genres[\"Primary Artist\"] = ten_genres[\"Artist\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "# Identify missing artists\n",
    "# These are the artists not found in the ten_genres.csv file üé∏\n",
    "missing_artists = df[~df[\"Primary Artist\"].isin(ten_genres[\"Primary Artist\"])]\n",
    "\n",
    "# Save the missing artists to a CSV file\n",
    "# This allows for manual review and genre assignment later üïµÔ∏è‚Äç‚ôÇÔ∏è\n",
    "missing_artists[[\"Primary Artist\"]].drop_duplicates().to_csv(\"data/missing_artists.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(missing_artists)} missing artists to 'data/missing_artists.csv'.\")\n",
    "\n",
    "# The missing artists are now stored in data/missing_artists.csv.\n",
    "# If needed, I can manually assign genres and add them to\n",
    "# obscure_artists_mike_likes.csv for future runs. A little manual effort goes a long way! üéõÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64562b7f-ea92-400d-b33d-845770388d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many songs still have missing genre data?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e0e6e-7b06-452d-8999-c96b5fcd8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls in any column except 'liked' because those belong to playlist_origin = df_nmf\n",
    "df = df[df.drop(columns=['liked']).notna().all(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d89341-0210-4136-bd93-66070a896e54",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c803a7f-4ea3-431f-8c62-54b6801f8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4860391-1274-4020-bd0a-8cca3608576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many tracks belong to each 'playlist_origin' in the dataset\n",
    "# This helps us understand the distribution of tracks across different sources üéµ\n",
    "playlist_origin_counts = df['playlist_origin'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Playlist Origin Counts:\")\n",
    "playlist_origin_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec9c04-e135-49c3-a901-c51f9911c7d1",
   "metadata": {},
   "source": [
    "## Finding Top 30 Genres (Temporarily, for new feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac5264-0f36-43e4-ac63-ef46d30cdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Explode the Genres column\n",
    "df_exploded = df.assign(Genres=df['Genres'].str.split(', ')).explode('Genres')\n",
    "\n",
    "# Step 2: Filter out genres that appear fewer than 10 times\n",
    "genre_counts = df_exploded['Genres'].value_counts()\n",
    "frequent_genres = genre_counts[genre_counts >= 40].index  # Genres with at least 10 occurrences\n",
    "\n",
    "# Filter the exploded DataFrame to only include frequent genres\n",
    "df_frequent_genres = df_exploded[df_exploded['Genres'].isin(frequent_genres)]\n",
    "\n",
    "# Step 3: Group by Genre and calculate the mean of the 'liked' column\n",
    "genre_liked_avg = df_frequent_genres.groupby('Genres')['liked'].mean().reset_index()\n",
    "\n",
    "# Step 4: Sort by the average 'liked' score in descending order and get the top 30\n",
    "top_30_genres = genre_liked_avg.sort_values(by='liked', ascending=False).head(30)\n",
    "\n",
    "# Display the top 30 genres\n",
    "print(\"Top 30 Genres by Average Liked Score (Filtered for Frequent Genres):\")\n",
    "print(top_30_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99e430-4c09-4dc2-bb20-445d1ebe6a16",
   "metadata": {},
   "source": [
    "## Feature Engineering / Further Selecting üëå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef584c69-80fb-4a3c-9631-e0e9edcb042a",
   "metadata": {},
   "source": [
    "### 'Record Label Frequency Encoded' üè∑Ô∏è\n",
    "\n",
    "To improve the model‚Äôs ability to generalize, I‚Äôm creating a new feature: **Record Label Frequency Encoded**. This feature represents how frequently each record label appears in the dataset, but with a twist‚Äîwe only consider labels from tracks I‚Äôve liked or marked as favorite albums. This ensures the encoding reflects my preferences and ignores labels from tracks I don‚Äôt care about.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Training Data Preparation**: We filter the combined dataframe (`df`) by `playlist_origin` to get subsets for `df_liked` and `df_fav_albums`. This ensures we‚Äôre working with the most up-to-date data.\n",
    "2. **Frequency Calculation**: We count how often each record label appears in the training data (i.e., liked and favorite albums).\n",
    "3. **Handling Unseen Labels**: For labels not present in the training data (e.g., those in the NMF test set), we use the **mean frequency** of all labels as a fallback. This ensures the model can handle new or rare labels gracefully.\n",
    "4. **Application**: We apply the encoding to both the training and test sets, ensuring consistency across the data.\n",
    "\n",
    "#### Why This Matters:\n",
    "- **Relevance**: By focusing only on labels from tracks I like, the encoding better reflects my preferences.\n",
    "- **Robustness**: Using the mean frequency for unseen labels ensures new artists from rare labels won't be penalized.\n",
    "- **Simplicity**: Frequency encoding avoids the complexity of one-hot encoding while still capturing meaningful information.\n",
    "\n",
    "This approach ensures the model learns from the distribution of labels I care about while remaining robust to new or rare labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6075b5b-3b34-4b10-b304-ef671e86f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'Record Label Frequency Encoded' üè∑Ô∏è\n",
    "\n",
    "# Filter the combined dataframe by playlist_origin to get the training subset\n",
    "# We focus on liked and favorite albums for training, ignoring disliked tracks and NMF üö´\n",
    "df_train_only = df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]\n",
    "\n",
    "# Calculate frequency encoding using only liked and favorite albums\n",
    "# This ensures the encoding reflects the distribution of labels I care about üè∑Ô∏è\n",
    "freq_encoding = df_train_only['Record Label'].value_counts()\n",
    "\n",
    "# Get the mean frequency to use for unseen labels\n",
    "# This acts as a fallback for labels not present in the training data üõ†Ô∏è\n",
    "mean_freq = freq_encoding.quantile(0.25)\n",
    "\n",
    "# Apply encoding to the training data\n",
    "df.loc[df['playlist_origin'].isin(['df_liked', 'df_fav_albums']), 'Record Label Frequency Encoded'] = (\n",
    "    df_train_only['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    ")\n",
    "\n",
    "# Apply encoding to the NMF test data separately\n",
    "# This avoids data leakage by using only the training data's frequency encoding üöÄ\n",
    "df_nmf_subset = df[df['playlist_origin'] == 'df_nmf']\n",
    "df_nmf_subset['Record Label Frequency Encoded'] = df_nmf_subset['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    "df.loc[df['playlist_origin'] == 'df_nmf', 'Record Label Frequency Encoded'] = df_nmf_subset['Record Label Frequency Encoded']\n",
    "\n",
    "# Apply encoding to the disliked albums\n",
    "df_not_liked_subset = df[df['playlist_origin'] == 'df_not_liked']\n",
    "df_not_liked_subset['Record Label Frequency Encoded'] = df_not_liked_subset['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    "df.loc[df['playlist_origin'] == 'df_not_liked', 'Record Label Frequency Encoded'] = df_not_liked_subset['Record Label Frequency Encoded']\n",
    "\n",
    "# Apply encoding to the mid albums\n",
    "df_mid_subset = df[df['playlist_origin'] == 'df_mid']\n",
    "df_mid_subset['Record Label Frequency Encoded'] = df_mid_subset['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    "df.loc[df['playlist_origin'] == 'df_mid', 'Record Label Frequency Encoded'] = df_mid_subset['Record Label Frequency Encoded']\n",
    "\n",
    "\n",
    "# Check the result by displaying 20 Unique Record Labels and Their Encoding!\n",
    "df[['Record Label', 'Record Label Frequency Encoded']].drop_duplicates().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275ff43-c4a4-4a7a-acb7-d5c74a80285e",
   "metadata": {},
   "source": [
    "### Target Encode Genres üéö\n",
    "\n",
    "To capture the relationship between genres and the target variable (liked), I use target encoding. This technique replaces each genre (or combination of genres) with the mean target value for that genre, smoothed to handle rare categories. This gives me a \"fingerprint\" of how much I tend to like songs from each genre, which helps the model make better predictions.\n",
    "\n",
    "#### Key Features:\n",
    "- **Handling Multi-Genre Tracks**: Tracks with multiple genres are split, encoded individually, and then aggregated.\n",
    "- **Smoothing**: I smooth the encoding to prevent overfitting by balancing genre-specific means with the global mean.\n",
    "- **Rare Genres**: Genres that appear fewer than 28 times are grouped into a common \"Rare_Genre\" category.\n",
    "- **Unknown Genres**: Tracks with \"Unknown\" genres are handled separately, using the global mean or a fallback value for NMF rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1f54f-259b-46aa-826e-df7fa3d3596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define explicitly disliked genres with severity weights (1-10 scale, 10 being most disliked)\n",
    "disliked_genres = {\n",
    "    'drone': 9, 'psychedelic': 7, 'improv': 8, 'ambient': 6, 'experimental': 7,\n",
    "    'instrumental': 5, 'classical': 5, 'hardcore': 8, 'downtempo': 6, 'slowcore': 6,\n",
    "    'noise': 9, 'satanic': 10, 'pagan': 8, 'metalcore': 9, 'deathcore': 10, \n",
    "    'death metal': 10, 'metal': 8, 'metallic hardcore': 9, 'beatdown deathcore': 10, \n",
    "    'nydm': 9, 'soundscape': 7, 'alternative metal': 8, 'horror punk': 8, \n",
    "    'sludge metal': 9, 'thrash metal': 9, 'death thrash metal': 10, \n",
    "    'heavy metal': 8, 'black metal': 10, 'doom metal': 9, 'death doom metal': 10,\n",
    "    'techno': 8, 'hard techno': 9, 'tech house': 7, 'minimal techno': 8,\n",
    "    'acid techno': 8, 'industrial techno': 9,  \n",
    "    'psychedelic rock': 7, 'psychedelic pop': 7, 'neo-psychedelic': 7, \n",
    "    'psychedelic folk': 7, 'psychedelia': 7, 'psych': 7, 'psych rock': 7, \n",
    "    'psych pop': 7, 'psychedelic soul': 7, 'acid rock': 7\n",
    "}\n",
    "\n",
    "preferred_genres = {\n",
    "    'alternative r&b': 10, 'chamber pop': 9, 'bedroom pop': 8.5,\n",
    "    'indie folk': 8, 'post punk': 7, 'indie': 6.5, 'jangle pop': 6.3,\n",
    "    'retro soul': 5, 'folk pop': 3.5, 'indie rock': 3.5, 'indie pop': 3.5,\n",
    "    'baroque pop': 3.5, 'americana': 3\n",
    "}\n",
    "\n",
    "def target_encode_multi_genre(df, genre_column, target, smoothing=1, aggregation_method='mean', min_count=28):\n",
    "    # Make a copy of the dataframe to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Target encode a multi-genre column with improved handling of disliked genres\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    \n",
    "    # Check if we have training data\n",
    "    if len(df_train) == 0:\n",
    "        raise ValueError(\"No training data found (df_train is empty)\")\n",
    "    \n",
    "    global_mean = df_train[target].mean()\n",
    "    \n",
    "    # Split genres into lists\n",
    "    df_train['split_genres'] = df_train[genre_column].fillna('Unknown').str.split(', ').apply(\n",
    "        lambda x: [genre.strip() for genre in x if genre not in ['seen live', 'Unknown', '']] \n",
    "        if isinstance(x, list) else ['Unknown']\n",
    "    )\n",
    "    \n",
    "    # Explode genres for encoding calculation\n",
    "    exploded_genres = df_train.explode('split_genres')\n",
    "    \n",
    "    # Calculate genre statistics\n",
    "    label_means = exploded_genres.groupby('split_genres')[target].mean()\n",
    "    label_counts = exploded_genres['split_genres'].value_counts()\n",
    "    rare_genres = label_counts[label_counts < min_count].index.tolist()\n",
    "    \n",
    "    # Apply smoothing\n",
    "    smoothed_values = (label_means * label_counts + global_mean * smoothing) / (label_counts + smoothing)\n",
    "    \n",
    "    # Adjust rare genres\n",
    "    for genre in rare_genres:\n",
    "        if genre in smoothed_values:\n",
    "            smoothed_values[genre] = (smoothed_values[genre] + global_mean * 2) / 3\n",
    "    \n",
    "    genre_encoding_map = smoothed_values.to_dict()\n",
    "    \n",
    "    def encode_genres(genres_str):\n",
    "        if pd.isna(genres_str) or genres_str == 'Unknown':\n",
    "            return global_mean\n",
    "        \n",
    "        genres = str(genres_str).split(', ')\n",
    "        genres = [g.strip() for g in genres if g not in ['seen live', 'Unknown', '']]\n",
    "        \n",
    "        # Handle genres without commas\n",
    "        if len(genres) == 1 and ' ' in genres[0]:\n",
    "            genre_lower = genres[0].lower()\n",
    "            # First check preferred genres\n",
    "            for preferred_term in preferred_genres:\n",
    "                if preferred_term in genre_lower:\n",
    "                    return min(100, global_mean * 1.5)  # Boost preferred genres\n",
    "            # Then check disliked terms\n",
    "            for disliked_term in ['metal', 'satanic', 'gore', 'brutal']:\n",
    "                if disliked_term in genre_lower:\n",
    "                    return 30.0\n",
    "        \n",
    "        if not genres:\n",
    "            return global_mean\n",
    "        \n",
    "        genre_values = []\n",
    "        genre_weights = []\n",
    "        \n",
    "        for genre in genres:\n",
    "            value = genre_encoding_map.get(genre, global_mean)\n",
    "            weight = 1.0\n",
    "            \n",
    "            # Apply blessing for preferred genres\n",
    "            genre_lower = genre.lower()\n",
    "            if genre_lower in preferred_genres:\n",
    "                blessing_factor = 1 + (preferred_genres[genre_lower] / 10.0)\n",
    "                value = min(100, value * blessing_factor)  # Cap at 100\n",
    "                weight = 1.5  # Higher weight for preferred genres\n",
    "            elif genre_lower in disliked_genres:\n",
    "                severity = disliked_genres.get(genre_lower, 6)\n",
    "                penalty_factor = 1.0 - (severity / 10.0)\n",
    "                value = value * penalty_factor\n",
    "                weight = 1.0 + (severity / 10.0)\n",
    "            elif genre in label_means and label_means[genre] < global_mean - 10:\n",
    "                value = value * 0.75\n",
    "                \n",
    "            genre_values.append(value)\n",
    "            genre_weights.append(weight)\n",
    "        \n",
    "        return sum(v * w for v, w in zip(genre_values, genre_weights)) / sum(genre_weights)\n",
    "    \n",
    "    # Apply encoding to ALL rows including NMF\n",
    "    df[genre_column + '_encoded'] = df[genre_column].apply(encode_genres)\n",
    "    return df\n",
    "\n",
    "# Run the improved target encoding function \n",
    "try:\n",
    "    df = target_encode_multi_genre(df, 'Genres', 'liked', smoothing=35, aggregation_method='mean')\n",
    "except Exception as e:\n",
    "    print(f\"Error during encoding: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Check NMF rows encoding stats\n",
    "if df is not None:\n",
    "    nmf_encoding_check = df[df['playlist_origin'] == 'df_nmf'][['Track Name', 'Artist Name(s)', 'Album Name', 'Genres', 'Genres_encoded']]\n",
    "\n",
    "    print(f\"NMF rows total: {len(nmf_encoding_check)}\")\n",
    "    print(f\"NMF rows with genre encoding: {nmf_encoding_check['Genres_encoded'].notna().sum()}\")\n",
    "    print(f\"NMF rows missing genre encoding: {nmf_encoding_check['Genres_encoded'].isna().sum()}\")\n",
    "\n",
    "    if nmf_encoding_check['Genres_encoded'].notna().any():\n",
    "        print(\"\\nEncoding value stats:\")\n",
    "        print(f\"Min: {nmf_encoding_check['Genres_encoded'].min():.2f}\")\n",
    "        print(f\"Max: {nmf_encoding_check['Genres_encoded'].max():.2f}\")\n",
    "        print(f\"Mean: {nmf_encoding_check['Genres_encoded'].mean():.2f}\")\n",
    "        print(f\"Median: {nmf_encoding_check['Genres_encoded'].median():.2f}\")\n",
    "        \n",
    "        diverse_samples = nmf_encoding_check.drop_duplicates(['Artist Name(s)'])[:10]\n",
    "        print(\"\\n10 tracks from different artists:\")\n",
    "        for i, row in diverse_samples.iterrows():\n",
    "            print(f\"{row['Artist Name(s)']} - {row['Track Name']} | Genres: {row['Genres']} | Score: {row['Genres_encoded']:.2f}\")\n",
    "        \n",
    "        print(\"\\nTop 5 highest genre scores:\")\n",
    "        high_scores = nmf_encoding_check.nlargest(5, 'Genres_encoded')\n",
    "        for i, row in high_scores.iterrows():\n",
    "            print(f\"{row['Artist Name(s)']} - {row['Track Name']} | Genres: {row['Genres']} | Score: {row['Genres_encoded']:.2f}\")\n",
    "        \n",
    "        print(\"\\nBottom 5 lowest genre scores:\")\n",
    "        low_scores = nmf_encoding_check.nsmallest(5, 'Genres_encoded')\n",
    "        for i, row in low_scores.iterrows():\n",
    "            print(f\"{row['Artist Name(s)']} - {row['Track Name']} | Genres: {row['Genres']} | Score: {row['Genres_encoded']:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nNo encoded values found in NMF rows.\")\n",
    "\n",
    "    # Save results\n",
    "    df[df['playlist_origin'] == 'df_nmf'][['Track Name', 'Artist Name(s)', 'Album Name', 'Genres', 'Genres_encoded']].to_csv('genre_encoding_results.csv', index=False)\n",
    "    print(\"\\nGenre encoding results saved to 'genre_encoding_results.csv'\")\n",
    "else:\n",
    "    print(\"Dataframe is None - encoding failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df9122-2225-49b9-b63c-3f9f15f433dc",
   "metadata": {},
   "source": [
    "# Finding How Central an Artist is to My Music Taste üéØ\n",
    "\n",
    "To understand how central an artist is to my music taste, we're building a network of artists based on which ones I've liked and which are similar to them. Using **PageRank**, a method that measures the importance of nodes in a network, we calculate each artist's \"centrality\" score. This score reflects how influential an artist is within the network of my liked and similar artists.\n",
    "\n",
    "## Key Points:\n",
    "* **Liked Artists**: Artists from my liked songs and favorite albums.\n",
    "* **Similar Artists**: Artists similar to my liked artists (from `df_liked_similar`).\n",
    "* **No Data Leakage**: The `df_nmf` (New Music Friday) artists are excluded from the network to avoid bias.\n",
    "* **Scaled Scores**: Centrality scores are normalized to a 0-100 range for easier interpretation.\n",
    "\n",
    "This approach ensures that the centrality scores are based solely on my preferences and not influenced by artists I haven't liked or the New Music Friday playlist. Let's dive into the code! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612732d8-7cc2-4527-bcc5-307649e7d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Featured_Artist(s) column\n",
    "def extract_featured_artists(df):\n",
    "    # Create new column by splitting on comma and taking all but first artist\n",
    "    df['Featured_Artist(s)'] = df['Artist Name(s)'].apply(\n",
    "        lambda x: ', '.join(str(x).split(',')[1:]).strip() if ',' in str(x) else ''\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Prepare the data\n",
    "def prepare_featured_artists(df):\n",
    "    # Prepare the 'Featured_Artist(s)' column for analysis.\n",
    "    # Ensures the column exists, handles missing values, and splits into lists. üßπ\n",
    "    # First create the column if it doesn't exist\n",
    "    df = extract_featured_artists(df)\n",
    "    \n",
    "    # Ensure 'Featured_Artist(s)' is a string and handle missing values\n",
    "    df['Featured_Artist(s)'] = df['Featured_Artist(s)'].fillna('').astype(str)\n",
    "    \n",
    "    # Split and clean the 'Featured_Artist(s)' column into lists\n",
    "    df['Featured_Artist(s)'] = df['Featured_Artist(s)'].str.split(',').apply(\n",
    "        lambda x: [artist.strip() for artist in x] if isinstance(x, list) else []\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_graph(df, df_liked_similar, include_nmf=False):\n",
    "    # Build a graph of artists and their connections.\n",
    "    # Only includes liked artists and their similar artists by default. üéØ\n",
    "    # Optionally includes NMF, not-liked, and mid artists (without adding edges). üö´\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for liked artists\n",
    "    liked_artists = set(\n",
    "        df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Artist Name(s)']\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    G.add_nodes_from(liked_artists, type='liked')\n",
    "    \n",
    "    # Add nodes for similar artists (from liked)\n",
    "    similar_artists_liked = set(\n",
    "        df_liked_similar['Similar Artists']\n",
    "        .dropna()\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    G.add_nodes_from(similar_artists_liked, type='similar_liked')\n",
    "    \n",
    "    # Add edges based on similarity (from liked)\n",
    "    for _, row in df_liked_similar.iterrows():\n",
    "        artist = row['Artist']\n",
    "        if isinstance(row['Similar Artists'], str):\n",
    "            similar = row['Similar Artists'].split(', ')\n",
    "            for s in similar:\n",
    "                G.add_edge(artist, s, weight=1.0)\n",
    "    \n",
    "    # Optionally include NMF, not-liked, and mid artists (without adding edges)\n",
    "    if include_nmf:\n",
    "        nmf_artists = set(\n",
    "            df[df['playlist_origin'] == 'df_nmf']['Artist Name(s)']\n",
    "            .str.split(',').explode().str.strip()\n",
    "        )\n",
    "        not_liked_artists = set(\n",
    "            df[df['playlist_origin'] == 'df_not_liked']['Artist Name(s)']\n",
    "            .str.split(',').explode().str.strip()\n",
    "        )\n",
    "        mid_artists = set(\n",
    "            df[df['playlist_origin'] == 'df_mid']['Artist Name(s)']\n",
    "            .str.split(',').explode().str.strip()\n",
    "        )\n",
    "        G.add_nodes_from(nmf_artists, type='nmf')\n",
    "        G.add_nodes_from(not_liked_artists, type='not_liked')\n",
    "        G.add_nodes_from(mid_artists, type='mid')  # Mid artists exist but don‚Äôt interfere with the web\n",
    "    \n",
    "    return G\n",
    "\n",
    "def calculate_centrality_scores(G, df):\n",
    "    # Calculate PageRank centrality for all artists in the graph.\n",
    "    # Maps centrality scores back to the DataFrame for main artists. üìä\n",
    "    centrality_scores = nx.pagerank(G)\n",
    "    \n",
    "    # Map centrality scores back to DataFrame for main artists\n",
    "    df['Artist Centrality'] = (\n",
    "        df['Artist Name(s)']\n",
    "        .str.split(',').str[0].str.strip()\n",
    "        .map(centrality_scores).fillna(0)\n",
    "    )\n",
    "    \n",
    "    return df, centrality_scores\n",
    "\n",
    "# Normalize centrality scores to a 0-100 range\n",
    "def normalize_centrality_scores(df):\n",
    "    if df['Artist Centrality'].max() != 0:\n",
    "        df['Artist Centrality'] = (df['Artist Centrality'] / df['Artist Centrality'].max()) * 100\n",
    "    return df\n",
    "\n",
    "# Run the complete pipeline\n",
    "def run_centrality_analysis(df, df_liked_similar, include_nmf=False):\n",
    "    # Run the complete centrality analysis pipeline:\n",
    "    # 1. Prepare featured artists data.\n",
    "    # 2. Build the graph.\n",
    "    # 3. Calculate centrality scores.\n",
    "    # 4. Normalize scores to 0-100 range. üöÄ\n",
    "    # Prepare the featured artists data (still needed to ensure the column exists)\n",
    "    df = prepare_featured_artists(df)\n",
    "    \n",
    "    # Build the graph and calculate centrality\n",
    "    G = build_graph(df, df_liked_similar, include_nmf=include_nmf)\n",
    "    df, centrality_scores = calculate_centrality_scores(G, df)\n",
    "    df = normalize_centrality_scores(df)\n",
    "    \n",
    "    return df, G, centrality_scores\n",
    "\n",
    "# Execute the analysis for all artists (including NMF, not-liked, and mid)\n",
    "df, G, centrality_scores = run_centrality_analysis(df, df_liked_similar, include_nmf=True)\n",
    "\n",
    "# Extract the primary artist (first artist in 'Artist Name(s)' field)\n",
    "df['Primary Artist'] = df['Artist Name(s)'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Now group by Primary Artist to ensure unique artists are considered\n",
    "df_unique_artists = df.groupby('Primary Artist', as_index=False)['Artist Centrality'].max()\n",
    "\n",
    "# Get the top 30 unique primary artists by their centrality score\n",
    "top_artist_df = df_unique_artists.nlargest(30, 'Artist Centrality')[['Primary Artist', 'Artist Centrality']]\n",
    "\n",
    "# Print the top 30 unique primary artists by centrality\n",
    "print(\"\\nTop 30 Unique Primary Artists by Centrality:\")\n",
    "top_artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da884820-f2ec-4ffb-a44c-2a97953d95f9",
   "metadata": {},
   "source": [
    "### Distribution of Artist Centrality Scores by Playlist Origin üìäüéµ\n",
    "\n",
    "This histogram shows how **Artist Centrality** scores are distributed across different playlists. The centrality score reflects how central an artist is to my music taste, based on their connections to my liked artists and their similar artists.\n",
    "\n",
    "- **Liked Artists (df_liked)**: Artists I‚Äôve explicitly liked on Spotify.\n",
    "- **Favorite Albums (df_fav_albums)**: Albums I‚Äôve enjoyed in recent years.\n",
    "- **Mid Albums (df_mid)**: Albums I felt were just okay. Not gbad, not great either.\n",
    "- **Not Liked Albums (df_not_liked)**: Albums I didn‚Äôt enjoy in recent years.\n",
    "- **New Music Friday (df_nmf)**: The most recent New Music Friday playlist.\n",
    "\n",
    "#### What We‚Äôre Looking For:\n",
    "- **High Centrality Scores**: Artists who are closely connected to my liked artists.\n",
    "- **Low Centrality Scores**: Artists who are less connected to my preferences.\n",
    "- **Patterns by Playlist**: Do certain playlists (e.g., liked vs. not liked) have distinct centrality distributions?\n",
    "\n",
    "This visualization helps us understand how my preferences are reflected in the network of artists and how new or not-liked artists compare to my favorites. üïµÔ∏è‚Äç‚ôÇÔ∏è‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511eaa0-d4bd-4297-a7cc-755148f260c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the distribution of 'Artist Centrality', colored by playlist_origin\n",
    "# This shows how centrality scores vary across different playlists üé®\n",
    "sns.histplot(df, x='Artist Centrality', bins=30, hue='playlist_origin', kde=True, alpha=0.6, palette='viridis')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Artist Centrality Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Artist Centrality Scores by Playlist Origin')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01b8b-b7f0-4693-90af-fd9ddac50d91",
   "metadata": {},
   "source": [
    "### Lucy Dacus is one of my most played artists of all time, let's look at what her Pagerank network looked like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9c243-a5d0-415d-baca-fc681fa5aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Lucy Dacus's centrality score\n",
    "lucy_dacus_centrality = df[df['Artist Name(s)'].str.contains('Lucy Dacus')]['Artist Centrality'].values[0]\n",
    "\n",
    "# Extract Lucy Dacus's connections from the graph\n",
    "lucy_dacus_connections = list(G.edges('Lucy Dacus'))\n",
    "\n",
    "# Print Lucy Dacus's centrality score and connections\n",
    "print(f\"Lucy Dacus's Centrality Score: {lucy_dacus_centrality:.2f}\")\n",
    "print(f\"Lucy Dacus's Connections: {lucy_dacus_connections}\")\n",
    "\n",
    "# Create a subgraph centered around Lucy Dacus\n",
    "lucy_dacus_subgraph = G.subgraph(['Lucy Dacus'] + [artist for edge in lucy_dacus_connections for artist in edge])\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Draw the network\n",
    "pos = nx.spring_layout(lucy_dacus_subgraph, seed=42)  # Layout for consistent positioning\n",
    "nx.draw_networkx_nodes(lucy_dacus_subgraph, pos, node_size=500, node_color='lightblue', alpha=0.9)\n",
    "nx.draw_networkx_edges(lucy_dacus_subgraph, pos, edge_color='gray', alpha=0.6)\n",
    "\n",
    "# Highlight Lucy Dacus\n",
    "nx.draw_networkx_nodes(lucy_dacus_subgraph, pos, nodelist=['Lucy Dacus'], node_size=1000, node_color='purple', alpha=0.9)\n",
    "nx.draw_networkx_labels(lucy_dacus_subgraph, pos, labels={'Lucy Dacus': 'Lucy Dacus'}, font_size=12, font_weight='bold')\n",
    "\n",
    "# Add labels for connected artists\n",
    "nx.draw_networkx_labels(lucy_dacus_subgraph, pos, font_size=10)\n",
    "\n",
    "# Add title and annotations\n",
    "plt.title(\"Lucy Dacus's Position in My Music Taste Network\", fontsize=16)\n",
    "plt.figtext(0.5, 0.05, f\"Centrality Score: {lucy_dacus_centrality:.2f}\", ha='center', fontsize=12, style='italic')\n",
    "\n",
    "# Remove axes\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c20db-4987-4708-b980-ed86d33d8c98",
   "metadata": {},
   "source": [
    "## Two More Features Before Primetime! üé≠\n",
    "\n",
    "**Mood Score**: Combines Valence, Danceability, and Liveness to capture the vibe.\n",
    "\n",
    "**Energy Profile**: Mashes Energy, Loudness, and Tempo to gauge the track‚Äôs intensity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c419738-f1f8-4269-8607-60b5139ddcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features only on non-NMF data\n",
    "non_nmf_df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Create mood_score and energy_profile on non-NMF data\n",
    "non_nmf_df['mood_score'] = non_nmf_df[['Valence', 'Danceability', 'Liveness']].mean(axis=1)\n",
    "non_nmf_df['energy_profile'] = non_nmf_df[['Energy', 'Loudness', 'Tempo']].mean(axis=1)\n",
    "\n",
    "# Merge these features back into the main dataframe\n",
    "df = df.merge(non_nmf_df[['mood_score', 'energy_profile']], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9de14-6eb1-4928-9101-5e416946e977",
   "metadata": {},
   "source": [
    "## A Clean Album ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83abb64b-de0f-4e31-85bb-1d012d1a844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Album ID for better data tracking for New Music Friday albums\n",
    "df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "# ADD THIS DIRECTLY AFTER (same indentation):\n",
    "df['album_id'] = df.apply(\n",
    "    lambda x: f\"{x['Primary Artist'].lower()}_{x['Album Name'].lower()}\".replace(' ', '_'),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b164e-c47e-4a71-8430-0a0c40c78800",
   "metadata": {},
   "source": [
    "## Previwing the features on the menu üìñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0a236-7e93-4a4f-ad96-aa77414f9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in the DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nData Types of Each Column:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e10d2a-a4b1-4fc5-ba15-e0f339c9d738",
   "metadata": {},
   "source": [
    "## Standardize the numeric columns üìè\n",
    "When some numbers have a larger size than others, the model can be biased towards them, so we bring all the numeric columns on a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e2297-9c93-4b11-aa84-a465fcacbe93",
   "metadata": {},
   "source": [
    "### Seperate New Music Friday and Save it for Later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb709d88-3b66-4b3d-bd0f-31c17b361b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mood and energy scores first\n",
    "df['mood_score'] = df[['Valence', 'Danceability', 'Liveness']].mean(axis=1)\n",
    "df['energy_profile'] = df[['Energy', 'Loudness', 'Tempo']].mean(axis=1)\n",
    "\n",
    "# Split and save data\n",
    "df_nmf = df[df['playlist_origin'] == 'df_nmf'].copy()\n",
    "df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Save both versions pre-standardization\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)\n",
    "df_cleaned_pre_standardized = pd.concat([df, df_nmf], ignore_index=True)\n",
    "df_cleaned_pre_standardized.to_csv('data/df_cleaned_pre_standardized.csv', index=False)\n",
    "\n",
    "# Store original values\n",
    "original_centrality = df_nmf['Artist Centrality'].copy()\n",
    "original_mood = df_nmf['mood_score'].copy()\n",
    "original_energy = df_nmf['energy_profile'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0ad30-6b7e-4bab-acdf-d566ec4615a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns to scale\n",
    "numeric_columns = [ \n",
    "    'Genres_encoded', \n",
    "    'Artist Centrality',\n",
    "    'Popularity',\n",
    "    'Record Label Frequency Encoded', \n",
    "    'mood_score', \n",
    "    'energy_profile'\n",
    "]\n",
    "\n",
    "# Initialize the scaler with a 1 to 100 range\n",
    "scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "\n",
    "# Fit the scaler on the training data (df)\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Transform the test data (df_nmf) using the fitted scaler\n",
    "df_nmf[numeric_columns] = scaler.transform(df_nmf[numeric_columns])\n",
    "\n",
    "# Save the scaled df_nmf for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the scaled test data\n",
    "print(\"\\nScaled Test Data (df_nmf):\")\n",
    "df_nmf[numeric_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7fcb4-3d9f-4119-985d-824a1e98eafc",
   "metadata": {},
   "source": [
    "## Tuning and Predicting with Random Forest & XGBoost üåü\n",
    "In this section, we fine-tune our Random Forest and XGBoost models using randomized search for optimal hyperparameters. The goal? To get the best possible performance in predicting song ratings. After tuning the models, we make predictions on the unseen data, combining both models' results to generate a more accurate score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d91d28-f7ea-46c1-9e10-345dfa959649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_models(df, features, test_size=0.2):\n",
    "    # Prepare data\n",
    "    X = df[features]\n",
    "    y = (df['liked'] - df['liked'].mean()) / df['liked'].std()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Model parameters\n",
    "    rf_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 15),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 5)\n",
    "    }\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4)\n",
    "    }\n",
    "    \n",
    "    # Initialize models\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    xgb = XGBRegressor(random_state=42)\n",
    "    \n",
    "    # Perform randomized search\n",
    "    rf_search = RandomizedSearchCV(rf, rf_params, n_iter=20, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "    xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=20, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "    \n",
    "    # Fit models\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Train final models with best parameters\n",
    "    best_rf = RandomForestRegressor(**rf_search.best_params_, random_state=42)\n",
    "    best_xgb = XGBRegressor(**xgb_search.best_params_, random_state=42)\n",
    "    \n",
    "    best_rf.fit(X_train, y_train)\n",
    "    best_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    return best_rf, best_xgb, rf_search.best_params_, xgb_search.best_params_, X_test, y_test\n",
    "\n",
    "def predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, y_mean, y_std):\n",
    "    # Make predictions\n",
    "    rf_pred = best_rf.predict(df_nmf[features]) * y_std + y_mean\n",
    "    xgb_pred = best_xgb.predict(df_nmf[features]) * y_std + y_mean\n",
    "    \n",
    "    # Combine predictions\n",
    "    df_nmf['predicted_score'] = (rf_pred + xgb_pred) / 2\n",
    "    \n",
    "    return df_nmf\n",
    "\n",
    "# Usage\n",
    "features = [\n",
    "    'Genres_encoded', \n",
    "    'Artist Centrality',  \n",
    "    'Record Label Frequency Encoded', \n",
    "    'mood_score', \n",
    "    'Popularity',\n",
    "    'energy_profile'\n",
    "]\n",
    "best_rf, best_xgb, rf_params, xgb_params, X_test, y_test = tune_models(df, features)\n",
    "df_nmf = predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, df['liked'].mean(), df['liked'].std())\n",
    "\n",
    "# Output best parameters and feature importances\n",
    "print(f\"Random Forest best parameters: {rf_params}\")\n",
    "print(f\"XGBoost best parameters: {xgb_params}\")\n",
    "print(f\"Random Forest feature importances: {best_rf.feature_importances_}\")\n",
    "print(f\"XGBoost feature importances: {best_xgb.feature_importances_}\")\n",
    "\n",
    "# Feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({'feature': features, 'importance': best_rf.feature_importances_}).sort_values('importance', ascending=False)\n",
    "print(\"Feature importance (Random Forest):\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b494d-4137-409a-96c8-a4bbcff73a76",
   "metadata": {},
   "source": [
    "# 80/20 Train/Test of The Non NMF Data using RandomForrest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329f0f9-85af-4737-bc6e-5b81559867b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(df, features, rf_params, xgb_params):\n",
    "    # Only use non-NMF data for training\n",
    "    train_df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_df[features]\n",
    "    y = train_df['liked']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize models with the best parameters from tuning\n",
    "    rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
    "    xgb_model = XGBRegressor(**xgb_params, random_state=42)\n",
    "    \n",
    "    # Train models\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Combine predictions (80/20 weight)\n",
    "    final_pred = (0.8 * rf_pred) + (0.2 * xgb_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, final_pred)\n",
    "    r2 = r2_score(y_test, final_pred)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Track Name': train_df.loc[X_test.index, 'Track Name'],\n",
    "        'Artist Name(s)': train_df.loc[X_test.index, 'Artist Name(s)'],\n",
    "        'Actual Score': y_test,\n",
    "        'Predicted Score': final_pred\n",
    "    })\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'RF Importance': rf_model.feature_importances_,\n",
    "        'XGB Importance': xgb_model.feature_importances_\n",
    "    })\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R¬≤ Score: {r2:.2f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 Predictions vs Actual:\")\n",
    "    print(results_df.sort_values('Predicted Score', ascending=False).head(10))\n",
    "    \n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importances.sort_values('RF Importance', ascending=False))\n",
    "    \n",
    "    return rf_model, xgb_model, results_df, importances\n",
    "\n",
    "# Usage\n",
    "features = ['Genres_encoded', 'Artist Centrality', 'Record Label Frequency Encoded', 'mood_score', 'Popularity', 'energy_profile']\n",
    "rf_model, xgb_model, results, importances = train_test_model(df, features, rf_params, xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7455-4090-48fb-92bd-1fe791ed3f65",
   "metadata": {},
   "source": [
    "## Run the New Music Friday Regression Model\n",
    "\n",
    "We're using non-NMF data to train Random Forest and XGBoost models to predict how much users will like different tracks. Our improved model includes two key enhancements:\n",
    "\n",
    "1. **Artist Similarity Boost**: We reward New Music Friday artists that are similar to your liked artists, helping you discover new music that aligns with your established preferences.\n",
    "\n",
    "2. **Adaptive Ensemble Weighting**: Instead of a fixed 50/50 blend between models, we dynamically adjust weights based on which model performs better for different types of music.\n",
    "\n",
    "After training, we make predictions for new tracks and calculate confidence intervals to gauge prediction reliability. We then aggregate results by album, factoring in consistency and track count, and sort by weighted score to create a personalized list of top album recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3948a-af2a-497b-9b0e-5f68579ced00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adaptive_weights(X_train, y_train, X_pred, rf_model, xgb_model, features, n_bins=5):\n",
    "    # Make predictions on training data\n",
    "    rf_train_pred = rf_model.predict(X_train)\n",
    "    xgb_train_pred = xgb_model.predict(X_train)\n",
    "    \n",
    "    # Calculate errors\n",
    "    rf_errors = np.abs(rf_train_pred - y_train)\n",
    "    xgb_errors = np.abs(xgb_train_pred - y_train)\n",
    "    \n",
    "    # Create a dataframe with features, predictions, and errors\n",
    "    error_df = X_train.copy()\n",
    "    error_df['rf_error'] = rf_errors\n",
    "    error_df['xgb_error'] = xgb_errors\n",
    "    \n",
    "    # Get top 2 features by importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance['feature'].head(2).tolist()\n",
    "    \n",
    "    # Create bins for each top feature\n",
    "    for feature in top_features:\n",
    "        error_df[f'{feature}_bin'] = pd.qcut(error_df[feature], n_bins, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Calculate performance by bin\n",
    "    performance_by_bin = {}\n",
    "    for feature in top_features:\n",
    "        performance_by_bin[feature] = {}\n",
    "        for bin_idx in range(n_bins):\n",
    "            bin_data = error_df[error_df[f'{feature}_bin'] == bin_idx]\n",
    "            if len(bin_data) > 0:\n",
    "                rf_mean_error = bin_data['rf_error'].mean()\n",
    "                xgb_mean_error = bin_data['xgb_error'].mean()\n",
    "                total_error = rf_mean_error + xgb_mean_error\n",
    "                \n",
    "                if total_error > 0:\n",
    "                    # Weight inversely proportional to error (higher weight = better model)\n",
    "                    rf_weight = xgb_mean_error / total_error\n",
    "                else:\n",
    "                    rf_weight = 0.5\n",
    "                \n",
    "                performance_by_bin[feature][bin_idx] = rf_weight\n",
    "    \n",
    "    # Calculate weights for prediction data\n",
    "    weights = np.ones(len(X_pred)) * 0.5  # Default 50/50 weight\n",
    "    \n",
    "    for feature in top_features:\n",
    "        # Create bins for prediction data\n",
    "        try:\n",
    "            pred_bins = pd.qcut(X_pred[feature], n_bins, labels=False, duplicates='drop')\n",
    "            \n",
    "            # Apply weights based on bin performance\n",
    "            for bin_idx in range(n_bins):\n",
    "                if bin_idx in performance_by_bin[feature]:\n",
    "                    bin_mask = (pred_bins == bin_idx)\n",
    "                    if any(bin_mask):\n",
    "                        rf_weight = performance_by_bin[feature][bin_idx]\n",
    "                        # Scale weight to 0.3-0.7 range to avoid extreme values\n",
    "                        scaled_weight = 0.3 + (rf_weight * 0.4)\n",
    "                        weights[bin_mask] = scaled_weight\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not calculate bins for {feature}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def calculate_artist_similarity_boost(df_nmf, df_liked_similar, liked_artists_df, boost_factor=15):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_nmf_copy = df_nmf.copy()\n",
    "    \n",
    "    # Extract primary artists from NMF\n",
    "    df_nmf_copy['Primary Artist'] = df_nmf_copy['Artist Name(s)'].str.split(',').str[0].str.strip()\n",
    "    \n",
    "    # Extract primary artists from liked songs and albums\n",
    "    liked_artists = set(liked_artists_df['Artist Name(s)'].str.split(',').str[0].str.strip())\n",
    "    \n",
    "    # Create a dictionary of similar artists from df_liked_similar\n",
    "    similar_artists_dict = {}\n",
    "    for _, row in df_liked_similar.iterrows():\n",
    "        if pd.notna(row['Similar Artists']):\n",
    "            artist = row['Artist']\n",
    "            similar = [s.strip() for s in row['Similar Artists'].split(',')]\n",
    "            similar_artists_dict[artist] = similar\n",
    "    \n",
    "    # Flatten the similar artists dictionary to create a mapping from similar artist to liked artist\n",
    "    similar_to_liked_mapping = {}\n",
    "    for liked_artist, similar_list in similar_artists_dict.items():\n",
    "        for similar_artist in similar_list:\n",
    "            if similar_artist not in similar_to_liked_mapping:\n",
    "                similar_to_liked_mapping[similar_artist] = []\n",
    "            similar_to_liked_mapping[similar_artist].append(liked_artist)\n",
    "    \n",
    "    # Function to find the best match for an artist using fuzzy matching\n",
    "    def find_best_match(artist, artist_set, threshold=85):\n",
    "        if artist in artist_set:\n",
    "            return artist, 100\n",
    "        \n",
    "        matches = process.extractOne(artist, artist_set)\n",
    "        if matches and matches[1] >= threshold:\n",
    "            return matches[0], matches[1]\n",
    "        return None, 0\n",
    "    \n",
    "    # Add similarity boost columns directly to the dataframe\n",
    "    df_nmf_copy['similarity_boost'] = 0\n",
    "    df_nmf_copy['match_type'] = 'no_match'\n",
    "    df_nmf_copy['matched_to'] = 'None'\n",
    "    \n",
    "    # Calculate similarity boost for each NMF artist\n",
    "    for i, row in df_nmf_copy.iterrows():\n",
    "        artist = row['Primary Artist']\n",
    "        \n",
    "        # Check if the artist is directly in liked artists\n",
    "        if artist in liked_artists:\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'direct_match'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = artist\n",
    "            continue\n",
    "        \n",
    "        # Check if the artist is in similar_to_liked_mapping\n",
    "        if artist in similar_to_liked_mapping:\n",
    "            liked_connections = similar_to_liked_mapping[artist]\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor * 0.8\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'similar_to_liked'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = ', '.join(liked_connections[:3])  # Show up to 3 connections\n",
    "            continue\n",
    "        \n",
    "        # Try fuzzy matching with similar artists\n",
    "        best_match, match_score = find_best_match(artist, set(similar_to_liked_mapping.keys()))\n",
    "        if best_match:\n",
    "            liked_connections = similar_to_liked_mapping[best_match]\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor * 0.6 * (match_score / 100)\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'fuzzy_similar_match'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = f\"{best_match} ({match_score}%) -> {', '.join(liked_connections[:2])}\"\n",
    "            continue\n",
    "        \n",
    "        # Try fuzzy matching with liked artists\n",
    "        best_match, match_score = find_best_match(artist, liked_artists)\n",
    "        if best_match:\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor * 0.7 * (match_score / 100)\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'fuzzy_direct_match'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = f\"{best_match} ({match_score}%)\"\n",
    "            continue\n",
    "    \n",
    "    return df_nmf_copy\n",
    "\n",
    "def get_prediction_interval(X, model, y_std, y_mean, percentile=95):\n",
    "    \"\"\"Calculate prediction intervals from Random Forest\"\"\"\n",
    "    predictions = []\n",
    "    for estimator in model.estimators_:\n",
    "        predictions.append(estimator.predict(X) * y_std + y_mean)\n",
    "    predictions = np.array(predictions)\n",
    "    lower = np.percentile(predictions, (100-percentile)/2, axis=0)\n",
    "    upper = np.percentile(predictions, 100-(100-percentile)/2, axis=0)\n",
    "    return lower, upper\n",
    "\n",
    "def apply_confidence_scaling(predictions, model, X, y_std, y_mean, min_confidence=40):\n",
    "    \"\"\"Apply confidence-based scaling to predictions\"\"\"\n",
    "    # Get prediction intervals\n",
    "    lower, upper = get_prediction_interval(X, model, y_std, y_mean)\n",
    "    uncertainty = upper - lower\n",
    "    confidence = (1 - uncertainty/uncertainty.max()) * 100\n",
    "    \n",
    "    # Scale predictions based on confidence\n",
    "    scaled_predictions = predictions.copy()\n",
    "    \n",
    "    # High confidence: minimal adjustment (90-100% of original)\n",
    "    high_conf = confidence >= min_confidence\n",
    "    scaled_predictions[high_conf] = predictions[high_conf] * (0.9 + 0.1*(confidence[high_conf]/100))\n",
    "    \n",
    "    # Low confidence: aggressive scaling (60-90% of original)\n",
    "    low_conf = confidence < min_confidence\n",
    "    scaled_predictions[low_conf] = predictions[low_conf] * (0.6 + 0.3*(confidence[low_conf]/min_confidence))\n",
    "    \n",
    "    return np.clip(scaled_predictions, None, 100), confidence\n",
    "\n",
    "# Load the similar artists data\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')\n",
    "\n",
    "# Filter liked and favorite albums for similarity boost\n",
    "liked_artists_df = df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]\n",
    "\n",
    "# Create known artists set\n",
    "known_artists = set(df_liked_similar['Artist'])\n",
    "\n",
    "# Features used for prediction\n",
    "features = [\n",
    "    'Genres_encoded', \n",
    "    'Artist Centrality',  \n",
    "    'Record Label Frequency Encoded', \n",
    "    'mood_score', \n",
    "    'Popularity',\n",
    "    'energy_profile'\n",
    "]\n",
    "\n",
    "# Normalize the target variable\n",
    "y_mean = df['liked'].mean()\n",
    "y_std = df['liked'].std()\n",
    "y_normalized = (df['liked'] - y_mean) / y_std\n",
    "\n",
    "# Prepare training data\n",
    "X = df[features]\n",
    "y = y_normalized  # Use normalized target\n",
    "\n",
    "# Initialize models with the best parameters from tuning\n",
    "rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
    "xgb_model = XGBRegressor(**xgb_params, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf_model.fit(X, y)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Get feature importance from both models\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_rf': rf_model.feature_importances_\n",
    "}).sort_values('importance_rf', ascending=False)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_xgb': xgb_model.feature_importances_\n",
    "}).sort_values('importance_xgb', ascending=False)\n",
    "\n",
    "# Combine importance scores\n",
    "feature_importance = pd.merge(rf_importance, xgb_importance, on='feature')\n",
    "feature_importance['avg_importance'] = (feature_importance['importance_rf'] + feature_importance['importance_xgb']) / 2\n",
    "feature_importance = feature_importance.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "# Prepare NMF data for prediction\n",
    "df_nmf_cleaned = df_nmf[features]\n",
    "\n",
    "# Calculate similarity boost for NMF artists\n",
    "df_nmf = calculate_artist_similarity_boost(df_nmf, df_liked_similar, liked_artists_df)\n",
    "\n",
    "# Make predictions and denormalize\n",
    "rf_predictions = rf_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "xgb_predictions = xgb_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "\n",
    "# Calculate adaptive weights for ensemble\n",
    "adaptive_weights = calculate_adaptive_weights(X, y_normalized, df_nmf_cleaned, rf_model, xgb_model, features)\n",
    "\n",
    "# Get raw ensemble predictions\n",
    "raw_predictions = (adaptive_weights * rf_predictions + \n",
    "                  (1 - adaptive_weights) * xgb_predictions)\n",
    "\n",
    "# Apply similarity boost\n",
    "boosted_predictions = raw_predictions + df_nmf['similarity_boost']\n",
    "\n",
    "# Apply confidence scaling\n",
    "final_predictions, confidence_scores = apply_confidence_scaling(\n",
    "    boosted_predictions, \n",
    "    rf_model, \n",
    "    df_nmf_cleaned, \n",
    "    y_std, \n",
    "    y_mean,\n",
    "    min_confidence=40\n",
    ")\n",
    "\n",
    "# Store results\n",
    "df_nmf['predicted_score'] = final_predictions\n",
    "df_nmf['prediction_confidence'] = confidence_scores\n",
    "df_nmf['is_unknown_artist'] = ~df_nmf['Artist Name(s)'].isin(known_artists)\n",
    "\n",
    "# Calculate prediction intervals\n",
    "lower_bound, upper_bound = get_prediction_interval(df_nmf_cleaned, rf_model, y_std, y_mean)\n",
    "df_nmf['prediction_lower'] = lower_bound\n",
    "df_nmf['prediction_upper'] = upper_bound\n",
    "df_nmf['prediction_uncertainty'] = upper_bound - lower_bound\n",
    "\n",
    "# Get the most common release date from NMF dataset\n",
    "nmf_release_date = df_nmf['Release Date'].mode().iloc[0]\n",
    "\n",
    "# Function to find common artists across all tracks in an album\n",
    "def get_common_artists(artist_series):\n",
    "    \"\"\"Find artists common to all tracks in an album\"\"\"\n",
    "    # Handle NaN/None values\n",
    "    artist_series = artist_series.dropna()\n",
    "    if len(artist_series) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Split each string into a set of artists\n",
    "    artist_lists = []\n",
    "    for artists in artist_series:\n",
    "        try:\n",
    "            artist_lists.append(set(a.strip() for a in artists.split(',')))\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    if not artist_lists:\n",
    "        return \"\"\n",
    "    \n",
    "    # Find intersection of all artist sets\n",
    "    common_artists = set.intersection(*artist_lists)\n",
    "    \n",
    "    # If no common artists, use most frequent artist\n",
    "    if not common_artists:\n",
    "        all_artists = [a for artist_set in artist_lists for a in artist_set]\n",
    "        artist_counts = Counter(all_artists)\n",
    "        \n",
    "        # Get artists that appear in all tracks\n",
    "        most_common = [a for a, cnt in artist_counts.items() \n",
    "                      if cnt == len(artist_series)]\n",
    "        \n",
    "        if most_common:\n",
    "            common_artists = set(most_common)\n",
    "        else:\n",
    "            # Fall back to single most common artist\n",
    "            common_artists = {artist_counts.most_common(1)[0][0]}\n",
    "    \n",
    "    return ', '.join(sorted(common_artists))\n",
    "    return \"\"\n",
    "\n",
    "# Group by album and aggregate data\n",
    "album_predictions = df_nmf.groupby('Album Name').agg({\n",
    "    'Artist Name(s)': get_common_artists,\n",
    "    'predicted_score': ['mean', 'std', 'count'],\n",
    "    'prediction_uncertainty': 'mean',\n",
    "    'Genres': lambda x: ' | '.join(list(set(x))[:3]),\n",
    "    'Record Label': 'first',\n",
    "    'Artist Centrality': 'first', \n",
    "    'mood_score': 'first',         \n",
    "    'energy_profile': 'first',\n",
    "    'Genres_encoded': 'first',\n",
    "    'Record Label Frequency Encoded': 'first',\n",
    "    'prediction_confidence': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "album_predictions.columns = [\n",
    "    'Album Name', 'Artist', 'avg_score', 'score_std', 'track_count',\n",
    "    'avg_uncertainty', 'Genres', 'Label', 'Artist_Centrality', \n",
    "    'Mood_Score', 'Energy_Profile', 'Genres_encoded', \n",
    "    'Record_Label_Frequency_Encoded', 'confidence_score'\n",
    "]\n",
    "\n",
    "# Calculate final confidence score\n",
    "max_std = album_predictions['score_std'].max()\n",
    "max_uncertainty = album_predictions['avg_uncertainty'].max()\n",
    "\n",
    "album_predictions['confidence_score'] = (\n",
    "    (1 - album_predictions['score_std'] / max_std) * \n",
    "    (1 - album_predictions['avg_uncertainty'] / max_uncertainty) * \n",
    "    (1 - 1/(1 + album_predictions['track_count']))\n",
    ") * 100\n",
    "\n",
    "album_predictions['confidence_score'] = np.clip(album_predictions['confidence_score'], 1, 100)\n",
    "\n",
    "# Filter and sort albums\n",
    "album_recommendations = album_predictions[album_predictions['track_count'] >= 5].sort_values('avg_score', ascending=False)\n",
    "\n",
    "# Output results\n",
    "output_columns = [\n",
    "    'Artist', 'Album Name', 'avg_score', 'confidence_score',\n",
    "    'track_count', 'Genres', 'Label', 'Artist_Centrality', \n",
    "    'Mood_Score', 'Energy_Profile'\n",
    "]\n",
    "\n",
    "final_recommendations = album_recommendations[output_columns].copy()\n",
    "final_recommendations['Artist_Centrality'] = final_recommendations['Artist_Centrality'].clip(1, 100)\n",
    "final_recommendations['Mood_Score'] = final_recommendations['Mood_Score'].clip(1, 100)\n",
    "final_recommendations['Energy_Profile'] = final_recommendations['Energy_Profile'].clip(1, 100)\n",
    "\n",
    "# Save recommendations\n",
    "date_str = datetime.strptime(nmf_release_date, '%Y-%m-%d').strftime('%m-%d-%y')\n",
    "filename = f\"predictions/{date_str}_Album_Recommendations.csv\"\n",
    "final_recommendations.round(2).to_csv(filename, index=False)\n",
    "\n",
    "# Evaluation metrics\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    y_true_denormalized = y_true * y_std + y_mean\n",
    "    y_pred_denormalized = y_pred * y_std + y_mean\n",
    "    return -mean_squared_error(y_true_denormalized, y_pred_denormalized)\n",
    "\n",
    "custom_scorer_func = make_scorer(custom_scorer, greater_is_better=False)\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\n=== New Music Friday Recommendations ({nmf_release_date}) ===\")\n",
    "print(f\"Albums with 5+ tracks: {len(album_recommendations)}\")\n",
    "print(\"\\nTop 20 Albums:\")\n",
    "print(album_recommendations[['Artist', 'Album Name', 'avg_score', 'track_count']].head(20).round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"Random Forest CV Score: {rf_cv_scores.mean():.3f} (+/- {rf_cv_scores.std() * 2:.3f})\")\n",
    "print(f\"XGBoost CV Score: {xgb_cv_scores.mean():.3f} (+/- {xgb_cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(feature_importance[['feature', 'avg_importance']].round(3).to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['avg_importance'])\n",
    "plt.xlabel('Average Importance')\n",
    "plt.title('Top Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ad19c-d758-4214-b737-8ff44a13791c",
   "metadata": {},
   "source": [
    "# Display the Top Recommended Albums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b983fa-cc7c-40a3-a922-7e6434d2b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where the predictions are saved\n",
    "predictions_folder = \"predictions/\"\n",
    "\n",
    "# Get the latest predictions file\n",
    "files = [f for f in os.listdir(predictions_folder) if f.endswith(\"_Album_Recommendations.csv\")]\n",
    "\n",
    "if files:\n",
    "    thisweek = max(files, key=lambda f: os.path.getmtime(os.path.join(predictions_folder, f)))\n",
    "    print(f\"Loaded latest file: {thisweek}\")  # Optional, just for confirmation\n",
    "    model_output_df = pd.read_csv(os.path.join(predictions_folder, thisweek))\n",
    "    model_output_df = model_output_df.sort_values(by=\"avg_score\", ascending=False)\n",
    "\n",
    "    # Display all rows\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    model_output_df\n",
    "else:\n",
    "    thisweek = None\n",
    "    None  # Ensures no unwanted output\n",
    "\n",
    "thisweek  # Stores the filename for reference\n",
    "model_output_df  #Show the Recommendations Dataframe for This Past Week!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574853d5-e2d1-4056-9078-06dd1c8cc947",
   "metadata": {},
   "source": [
    "## Grab Album Art for the NMF Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a20ad-63e1-4b72-aa0c-da53b59ee761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Last.fm API key\n",
    "LASTFM_API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "\n",
    "# Function to get similar artists using Last.fm API\n",
    "def get_similar_artists(artist: str, api_key: str, limit: int = 5) -> dict:\n",
    "    base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "    params = {\n",
    "        'method': 'artist.getsimilar',\n",
    "        'artist': artist,\n",
    "        'api_key': api_key,\n",
    "        'limit': limit,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "            similar_artists = [artist['name'] for artist in data['similarartists']['artist']]\n",
    "            return {'Artist': artist, 'Similar Artists': \", \".join(similar_artists[:limit]), 'status': 'success'}\n",
    "    except Exception as e:\n",
    "        return {'Artist': artist, 'Similar Artists': None, 'status': f'error: {str(e)}'}\n",
    "    \n",
    "    return {'Artist': artist, 'Similar Artists': None, 'status': 'no_results'}\n",
    "\n",
    "# Function to get album art using Apple Music API\n",
    "def get_album_art(artist: str, album: str) -> dict:\n",
    "    try:\n",
    "        url = f\"https://itunes.apple.com/search?term={artist} {album}&entity=album\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'results' in data and len(data['results']) > 0:\n",
    "            album_art = data['results'][0].get('artworkUrl100', '').replace(\"100x100\", \"600x600\")\n",
    "            return {'Artist': artist, 'Album Name': album, 'Album Art': album_art, 'status': 'success'}\n",
    "    except Exception as e:\n",
    "        return {'Artist': artist, 'Album Name': album, 'Album Art': None, 'status': f'error: {str(e)}'}\n",
    "    \n",
    "    return {'Artist': artist, 'Album Name': album, 'Album Art': None, 'status': 'no_results'}\n",
    "\n",
    "# Main function to update album data\n",
    "def update_album_data(input_file: str, album_art_file: str, similar_artists_file: str, api_key: str) -> None:\n",
    "    print(f\"\\nStarting data fetch at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    df_input = pd.read_csv(input_file)\n",
    "    album_pairs = df_input[['Primary Artist', 'Album Name']].drop_duplicates()\n",
    "    recommended_artists = df_input[df_input['playlist_origin'] == 'df_nmf']['Primary Artist'].unique()\n",
    "    \n",
    "    try:\n",
    "        existing_album_art = pd.read_csv(album_art_file)\n",
    "    except FileNotFoundError:\n",
    "        existing_album_art = pd.DataFrame(columns=['Artist', 'Album Name', 'Album Art'])\n",
    "    \n",
    "    album_pairs = album_pairs.merge(\n",
    "        existing_album_art,\n",
    "        left_on=['Primary Artist', 'Album Name'],\n",
    "        right_on=['Artist', 'Album Name'],\n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    album_pairs = album_pairs[album_pairs['_merge'] == 'left_only'].drop(columns=['_merge', 'Album Art'])\n",
    "    \n",
    "    df_album_art = pd.DataFrame(columns=['Artist', 'Album Name', 'Album Art'])\n",
    "    df_similar = pd.DataFrame(columns=['Artist', 'Similar Artists'])\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_album = {\n",
    "            executor.submit(get_album_art, row['Primary Artist'], row['Album Name']): (row['Primary Artist'], row['Album Name'])\n",
    "            for _, row in album_pairs.iterrows()\n",
    "        }\n",
    "        for future in as_completed(future_to_album):\n",
    "            result = future.result()\n",
    "            if result['status'] == 'success' and result['Album Art']:\n",
    "                df_album_art = pd.concat([df_album_art, pd.DataFrame([result])], ignore_index=True)\n",
    "            sleep(0.25)\n",
    "    \n",
    "    updated_album_art = pd.concat([existing_album_art, df_album_art], ignore_index=True)\n",
    "    updated_album_art.to_csv(album_art_file, index=False)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(get_similar_artists, artist, api_key): artist\n",
    "            for artist in recommended_artists\n",
    "        }\n",
    "        for future in as_completed(future_to_artist):\n",
    "            result = future.result()\n",
    "            if result['status'] == 'success' and result['Similar Artists']:\n",
    "                df_similar = pd.concat([df_similar, pd.DataFrame([result])], ignore_index=True)\n",
    "            sleep(0.25)\n",
    "    \n",
    "    df_similar.to_csv(similar_artists_file, index=False)\n",
    "    print(f\"\\nFinished at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data/df_nmf_later.csv\"  \n",
    "    album_art_file = \"data/nmf_album_covers.csv\"  \n",
    "    similar_artists_file = \"data/nmf_similar_artists.csv\"  \n",
    "    update_album_data(input_file, album_art_file, similar_artists_file, LASTFM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025f562-96cb-4e59-a32d-6338f3a7da96",
   "metadata": {},
   "source": [
    "## Grab the Spotify Link for each New Music Friday Album üîó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126d6b2-d2bb-4c08-bc71-a12a69115c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spotify_links(batch_size=None, overwrite=False):\n",
    "    \n",
    "    output_file = 'data/nmf_album_links.csv'\n",
    "    \n",
    "    # Check if the output file already exists\n",
    "    if os.path.exists(output_file) and not overwrite:\n",
    "        print(f\"Output file {output_file} already exists.\")\n",
    "        print(\"Loading existing links file instead of regenerating...\")\n",
    "        try:\n",
    "            existing_links = pd.read_csv(output_file)\n",
    "            print(f\"Loaded {len(existing_links)} existing album links.\")\n",
    "            return existing_links\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing file: {e}\")\n",
    "            print(\"Continuing with link generation...\")\n",
    "    \n",
    "    print(\"Starting Spotify link generation...\")\n",
    "    \n",
    "    # Initialize Spotify client with your credentials\n",
    "    client_id = \"71faef9605da4db495b691d96a0daa4b\"\n",
    "    client_secret = \"832e40da22e049bba93f29d9dbeb2e62\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Authenticating with Spotify...\")\n",
    "        sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret\n",
    "        ))\n",
    "        print(\"Spotify authentication successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to authenticate with Spotify: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Read the NMF data\n",
    "    try:\n",
    "        print(\"Reading NMF data...\")\n",
    "        df = pd.read_csv('data/nmf.csv')\n",
    "        print(f\"Loaded {len(df)} tracks\")\n",
    "        \n",
    "        # Print the column names to verify\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading NMF data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Get unique albums\n",
    "        print(\"Extracting unique albums...\")\n",
    "        albums = df.drop_duplicates(subset=['Album Name'], keep='first')\n",
    "        print(f\"Found {len(albums)} unique albums\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting albums: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Function to get album ID from track URI with rate limiting\n",
    "    def get_album_id(track_uri):\n",
    "        if pd.isna(track_uri):\n",
    "            print(\"Warning: Found NaN URI\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Processing track: {track_uri}\")\n",
    "        try:\n",
    "            # Extract just the ID part from the URI (spotify:track:ID_HERE)\n",
    "            if isinstance(track_uri, str) and 'spotify:track:' in track_uri:\n",
    "                track_id = track_uri.split(':')[-1]\n",
    "            else:\n",
    "                track_id = track_uri  # If it's already an ID\n",
    "            \n",
    "            print(f\"Extracted track ID: {track_id}\")\n",
    "                \n",
    "            # Add delay to respect rate limits\n",
    "            time.sleep(0.1)  # 100ms delay between requests\n",
    "            track_info = sp.track(track_id)\n",
    "            album_id = track_info['album']['id']\n",
    "            print(f\"Found album ID: {album_id}\")\n",
    "            return album_id\n",
    "        except spotipy.exceptions.SpotifyException as e:\n",
    "            print(f\"Spotify API error: {e}\")\n",
    "            if hasattr(e, 'http_status') and e.http_status == 429:  # Too Many Requests\n",
    "                print(\"Rate limit hit, waiting longer...\")\n",
    "                time.sleep(5)  # Wait 5 seconds before retrying\n",
    "                try:\n",
    "                    track_info = sp.track(track_id)\n",
    "                    return track_info['album']['id']\n",
    "                except:\n",
    "                    print(f\"Still failed after retry for track {track_id}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Error getting album ID for track {track_id}: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for track URI {track_uri}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Check if we actually have the Track URI column\n",
    "    track_id_column = None\n",
    "    for possible_name in ['Track URI', 'track_uri', 'Track ID', 'track_id']:\n",
    "        if possible_name in albums.columns:\n",
    "            track_id_column = possible_name\n",
    "            print(f\"Found track identifier column: {track_id_column}\")\n",
    "            break\n",
    "    \n",
    "    if track_id_column is None:\n",
    "        print(\"ERROR: Could not find a track ID or URI column. Available columns are:\")\n",
    "        print(albums.columns.tolist())\n",
    "        return None\n",
    "    \n",
    "    # Determine which albums to process\n",
    "    if batch_size is not None:\n",
    "        albums_to_process = albums.head(batch_size)\n",
    "        print(f\"Processing a batch of {len(albums_to_process)} out of {len(albums)} total albums...\")\n",
    "    else:\n",
    "        albums_to_process = albums\n",
    "        print(f\"Processing all {len(albums)} albums...\")\n",
    "    \n",
    "    # Instead of using apply, let's process one by one for better error tracking\n",
    "    albums['Album ID'] = None\n",
    "    \n",
    "    for i, (idx, row) in enumerate(albums_to_process.iterrows()):\n",
    "        print(f\"\\nProcessing album {i+1}/{len(albums_to_process)}: {row['Album Name']}\")\n",
    "        album_id = get_album_id(row[track_id_column])\n",
    "        albums.at[idx, 'Album ID'] = album_id\n",
    "    \n",
    "    # Filter out any failed lookups\n",
    "    processed_albums = albums.dropna(subset=['Album ID'])\n",
    "    \n",
    "    processed_albums['Spotify URL'] = 'open.spotify.com/album/' + processed_albums['Album ID'].astype(str)\n",
    "    \n",
    "    # Select and reorder columns for output\n",
    "    output_columns = ['Album Name', 'Artist Name(s)', 'Album ID', 'Spotify URL']\n",
    "    # Make sure all required columns exist\n",
    "    output_columns = [col for col in output_columns if col in processed_albums.columns]\n",
    "    \n",
    "    output_df = processed_albums[output_columns]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated album links for {len(output_df)} albums\")\n",
    "    return output_df\n",
    "\n",
    "# Run the function\n",
    "# Pass overwrite=True to regenerate links even if the file exists\n",
    "result = generate_spotify_links(overwrite=True)  # Force regenerate all links\n",
    "print(\"Function completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73467-5b49-4809-8203-805fbf599238",
   "metadata": {},
   "source": [
    "## Save a HTML copy of this notebook at its newest! üîΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd78cd-cf1f-41fc-9d5e-94bc1e6a70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'graphics/' directory exists\n",
    "os.makedirs('graphics', exist_ok=True)\n",
    "\n",
    "# Load the current notebook with 'utf-8' encoding\n",
    "notebook_filename = 'Music Taste Machine Learning Data Prep.ipynb'\n",
    "with open(notebook_filename, 'r', encoding='utf-8') as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Export the notebook as HTML\n",
    "html_exporter = HTMLExporter()\n",
    "html_data, resources = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Save the HTML to the 'graphics/' folder\n",
    "output_filename = 'graphics/Music_Taste_Machine_Learning_Data_Prep.html'\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_data)\n",
    "\n",
    "print(f\"HTML version saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6ca61-099b-4cb8-9a4c-4f974977cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean HTML version (no outputs) to graphics folder\n",
    "from nbconvert import HTMLExporter\n",
    "import nbformat\n",
    "import os\n",
    "\n",
    "# Create graphics folder if it doesn't exist\n",
    "os.makedirs('graphics', exist_ok=True)\n",
    "\n",
    "# Read notebook, export without outputs, save\n",
    "with open('2026 Music Taste Machine Learning Data Prep.ipynb', 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "    html, _ = HTMLExporter(exclude_output=True).from_notebook_node(nb)\n",
    "    with open('graphics/2026_Music_Taste_Data_Prep_CLEAN.html', 'w', encoding='utf-8') as out:\n",
    "        out.write(html)\n",
    "\n",
    "print(\"‚úÖ Clean HTML saved to: graphics/2026_Music_Taste_Data_Prep_CLEAN.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
