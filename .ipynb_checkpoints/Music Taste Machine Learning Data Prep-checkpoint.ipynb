{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d392a2d-8247-40dc-9431-ae29941dc3ea",
   "metadata": {},
   "source": [
    "# Music Taste Prediction Model: New Music Friday Recommender üíøüéßüëçüëé\n",
    "In this model, I use my liked songs playlist, my recently loved and not loved albums, to train my regression model on what kind of music I do and don't like. At the end my test model will be the new music friday albums from the most recent Friday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e436444-4aff-431a-aedc-e7871c247d1e",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160a9a1f-e9f9-4fb7-b0e3-dcc706dba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Third-Party Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "\n",
    "# Fuzzy Matching\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from nbconvert import HTMLExporter\n",
    "import nbformat\n",
    "\n",
    "# Streamlit \n",
    "import streamlit as st\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42454624-15b3-4b80-bab9-a8ecbf9d299b",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8067f0c-b06b-4426-bad9-69bd28e3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked = pd.read_csv(\"data/liked.csv\")  # Liked playlist on Spotify\n",
    "df_fav_albums = pd.read_csv(\"data/liked_albums.csv\")  # Albums I've Liked in Recent Years\n",
    "df_not_liked = pd.read_csv(\"data/did_not_like.csv\")  # Albums I've not liked in Recent Years\n",
    "df_nmf = pd.read_csv(\"data/nmf.csv\")  # The most recent New Music Friday Playlist\n",
    "df_mid = pd.read_csv(\"data/mid.csv\") #Albums I neither enjoyed or hated, but were simply Mid\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv') #Similar Artisits to My Liked Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b112f9a-264e-4da1-87fd-ffe68974dd78",
   "metadata": {},
   "source": [
    "## A Check for New Artists / Pull Their Similar Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae3c1adc-0020-425f-89fa-56dee6f455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing and new data...\n",
      "Loaded 3828 existing artists from database\n",
      "Found 0 new artists to process\n",
      "No new artists to process. Database is up to date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BODEGA</td>\n",
       "      <td>Folly Group, Gustaf, Warmduscher, Deadletter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHE</td>\n",
       "      <td>OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonnie Prince Billy</td>\n",
       "      <td>Palace Music, Will Oldham, Palace Brothers, Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Telethon</td>\n",
       "      <td>Barely March, Smol Data, Diva Sweetly, Bigger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heather Maloney</td>\n",
       "      <td>Heather Maloney &amp; Darlingside, Twisted Pine, R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Artist                                    Similar Artists\n",
       "0               BODEGA  Folly Group, Gustaf, Warmduscher, Deadletter, ...\n",
       "1                  CHE  OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...\n",
       "2  Bonnie Prince Billy  Palace Music, Will Oldham, Palace Brothers, Bi...\n",
       "3             Telethon  Barely March, Smol Data, Diva Sweetly, Bigger ...\n",
       "4      Heather Maloney  Heather Maloney & Darlingside, Twisted Pine, R..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize LastFM API client with rate limiting and request limits\n",
    "# This ensures we don't overload the API and stay within usage guidelines ‚è≥\n",
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25, limit: int = 8):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        self.limit = limit\n",
    "\n",
    "    # Fetch similar artists for a given artist from LastFM API\n",
    "    # This is the core function that interacts with the API üé§\n",
    "    def get_similar_artists(self, artist_name: str) -> List[str]:\n",
    "        params = {\n",
    "            'method': 'artist.getSimilar',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'limit': self.limit,  # Limit the number of similar artists returned üéØ\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Handle rate limiting to avoid API bans ‚ö†Ô∏è\n",
    "            if 'X-RateLimit-Remaining' in response.headers:\n",
    "                remaining = int(response.headers['X-RateLimit-Remaining'])\n",
    "                if remaining == 0:\n",
    "                    sleep(self.rate_limit_delay)\n",
    "            \n",
    "            # Extract and return similar artists from the API response üé∂\n",
    "            data = response.json()\n",
    "            if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "                return [artist['name'] for artist in data['similarartists']['artist'][:self.limit]]\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching similar artists for {artist_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "# Extract the primary artist name from a string\n",
    "# This handles cases where multiple artists are listed (e.g., \"Artist A, Artist B\") üé§\n",
    "def extract_primary_artist(artist_string: str) -> str:\n",
    "    if pd.isna(artist_string):\n",
    "        return \"\"\n",
    "    return artist_string.split(\",\")[0].strip()\n",
    "\n",
    "# Update the similar artists database with new artists from liked playlists\n",
    "# This function ensures the database stays up-to-date with my latest music preferences üîÑ\n",
    "def update_similar_artists(liked_path: str, \n",
    "                         albums_path: str, \n",
    "                         output_path: str, \n",
    "                         api_key: str) -> pd.DataFrame:\n",
    "    print(\"Loading existing and new data...\")\n",
    "    \n",
    "    # Load existing similar artists data\n",
    "    # This ensures we don't duplicate work for artists already in the database üìÇ\n",
    "    existing_data: Dict[str, List[str]] = {}\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        existing_data = dict(zip(existing_df['Artist'], existing_df['Similar Artists']))\n",
    "        print(f\"Loaded {len(existing_data)} existing artists from database\")\n",
    "    \n",
    "    # Load and process current playlists\n",
    "    # This combines liked songs and albums into a single set of artists üéß\n",
    "    df_liked = pd.read_csv(liked_path)\n",
    "    df_albums = pd.read_csv(albums_path)\n",
    "    \n",
    "    # Extract and combine primary artists\n",
    "    current_artists = set(\n",
    "        pd.concat([\n",
    "            df_liked['Artist Name(s)'].apply(extract_primary_artist),\n",
    "            df_albums['Artist Name(s)'].apply(extract_primary_artist)\n",
    "        ]).unique()\n",
    "    )\n",
    "    current_artists.discard(\"\")  # Remove empty strings\n",
    "    \n",
    "    # Find new artists not in existing data\n",
    "    # This ensures we only process artists we haven't seen before ÔøΩ\n",
    "    new_artists = current_artists - set(existing_data.keys())\n",
    "    print(f\"Found {len(new_artists)} new artists to process\")\n",
    "    \n",
    "    if not new_artists:\n",
    "        print(\"No new artists to process. Database is up to date!\")\n",
    "        # Create and return DataFrame even if no updates\n",
    "        return pd.DataFrame({\n",
    "            'Artist': list(existing_data.keys()),\n",
    "            'Similar Artists': list(existing_data.values())\n",
    "        })\n",
    "    \n",
    "    # Initialize LastFM API client\n",
    "    # This is where the magic happens ‚ú®\n",
    "    api = LastFMAPI(api_key)\n",
    "    \n",
    "    # Process artists with concurrent requests\n",
    "    # This speeds up the process by fetching data in parallel ‚ö°\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(api.get_similar_artists, artist): artist \n",
    "            for artist in new_artists\n",
    "        }\n",
    "        \n",
    "        # Show progress bar while processing\n",
    "        # This keeps you informed about the progress of the task üìä\n",
    "        for future in tqdm(as_completed(future_to_artist), \n",
    "                         total=len(future_to_artist),\n",
    "                         desc=\"Fetching similar artists\"):\n",
    "            artist = future_to_artist[future]\n",
    "            similar_artists = future.result()\n",
    "            results[artist] = ', '.join(similar_artists)\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    # This ensures the final dataset includes all artists, old and new üîó\n",
    "    combined_data = {**existing_data, **results}\n",
    "    \n",
    "    # Create DataFrame\n",
    "    # This formats the data for easy saving and future use üìÑ\n",
    "    output_df = pd.DataFrame({\n",
    "        'Artist': list(combined_data.keys()),\n",
    "        'Similar Artists': list(combined_data.values())\n",
    "    })\n",
    "    \n",
    "    # Save updated data\n",
    "    # This ensures the database is persisted for future runs üíæ\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    print(f\"Successfully updated database with {len(new_artists)} new artists\")\n",
    "    print(f\"Total artists in database: {len(combined_data)}\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Main execution block\n",
    "# This runs the update process when the script is executed directly üöÄ\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "    LIKED_PATH = \"data/liked.csv\"\n",
    "    ALBUMS_PATH = \"data/liked_albums.csv\"\n",
    "    OUTPUT_PATH = \"data/liked_artists_only_similar.csv\"\n",
    "    \n",
    "    # Run the update and get the DataFrame\n",
    "    df_liked_similar = update_similar_artists(\n",
    "        LIKED_PATH, \n",
    "        ALBUMS_PATH, \n",
    "        OUTPUT_PATH, \n",
    "        API_KEY\n",
    "    )\n",
    "    \n",
    "# Now df_liked_similar is ready to use\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392df38d-c607-4196-bf48-ab735338849e",
   "metadata": {},
   "source": [
    "## Quick Glance at our Refreshed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "929ec508-7fe2-43be-ac08-f08bb640aca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track URI</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:3FRVbgqA7pVAJ0VBnXsrIK</td>\n",
       "      <td>There‚Äôs No More Underground</td>\n",
       "      <td>There‚Äôs No More Underground</td>\n",
       "      <td>Master Peace</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>134131</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-10T16:11:31Z</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.349</td>\n",
       "      <td>157.717</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:7luWKxbZUJCksnGaW5Tves</td>\n",
       "      <td>Come Back Different</td>\n",
       "      <td>Come Back Different</td>\n",
       "      <td>Nina Keith;Julie Byrne;Taryn Blake Miller</td>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>246190</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-08T19:58:53Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.143</td>\n",
       "      <td>129.449</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:4jNS5tuvZxy4OYYn8Mlhvm</td>\n",
       "      <td>The Old Black Hen</td>\n",
       "      <td>I Will Swim to You: A Tribute to Jason Molina</td>\n",
       "      <td>Sadurn</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>345429</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-06T11:17:46Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.276</td>\n",
       "      <td>107.569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:0bJWzUD0myg94ZebxFqTTg</td>\n",
       "      <td>Spackle</td>\n",
       "      <td>A Welcome Kind of Weakness</td>\n",
       "      <td>Runnner</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>335413</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-02T19:47:24Z</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.155</td>\n",
       "      <td>148.044</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:4GFUQmNAuhdjhANvbjwwLw</td>\n",
       "      <td>The Jamie Oliver Petrol Station</td>\n",
       "      <td>EURO-COUNTRY</td>\n",
       "      <td>CMAT</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>323960</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-31T19:28:36Z</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>-3.674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.141</td>\n",
       "      <td>122.993</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Track URI                       Track Name  \\\n",
       "0  spotify:track:3FRVbgqA7pVAJ0VBnXsrIK      There‚Äôs No More Underground   \n",
       "1  spotify:track:7luWKxbZUJCksnGaW5Tves              Come Back Different   \n",
       "2  spotify:track:4jNS5tuvZxy4OYYn8Mlhvm                The Old Black Hen   \n",
       "3  spotify:track:0bJWzUD0myg94ZebxFqTTg                          Spackle   \n",
       "4  spotify:track:4GFUQmNAuhdjhANvbjwwLw  The Jamie Oliver Petrol Station   \n",
       "\n",
       "                                      Album Name  \\\n",
       "0                    There‚Äôs No More Underground   \n",
       "1                            Come Back Different   \n",
       "2  I Will Swim to You: A Tribute to Jason Molina   \n",
       "3                     A Welcome Kind of Weakness   \n",
       "4                                   EURO-COUNTRY   \n",
       "\n",
       "                              Artist Name(s) Release Date  Duration (ms)  \\\n",
       "0                               Master Peace   2025-09-05         134131   \n",
       "1  Nina Keith;Julie Byrne;Taryn Blake Miller   2024-11-22         246190   \n",
       "2                                     Sadurn   2025-09-05         345429   \n",
       "3                                    Runnner   2025-08-29         335413   \n",
       "4                                       CMAT   2025-08-29         323960   \n",
       "\n",
       "   Popularity  Explicit  Added By              Added At  ... Key Loudness  \\\n",
       "0          47      True       NaN  2025-09-10T16:11:31Z  ...   9   -4.007   \n",
       "1          12     False       NaN  2025-09-08T19:58:53Z  ...   0  -14.269   \n",
       "2          22     False       NaN  2025-09-06T11:17:46Z  ...   0  -11.451   \n",
       "3          31      True       NaN  2025-09-02T19:47:24Z  ...   3   -7.515   \n",
       "4          58      True       NaN  2025-08-31T19:28:36Z  ...  10   -3.674   \n",
       "\n",
       "   Mode  Speechiness  Acousticness  Instrumentalness  Liveness  Valence  \\\n",
       "0     1       0.0716      0.000552          0.007000     0.113    0.349   \n",
       "1     1       0.0424      0.479000          0.745000     0.575    0.143   \n",
       "2     1       0.0259      0.317000          0.033500     0.299    0.276   \n",
       "3     1       0.0292      0.011200          0.000201     0.122    0.155   \n",
       "4     0       0.1770      0.007240          0.000000     0.151    0.141   \n",
       "\n",
       "     Tempo  Time Signature  \n",
       "0  157.717               4  \n",
       "1  129.449               4  \n",
       "2  107.569               3  \n",
       "3  148.044               4  \n",
       "4  122.993               4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d80b875a-ebab-472e-82b5-85568f036a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track URI</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:0UOeq7bSskoJa4cJaJOmFS</td>\n",
       "      <td>Ticking</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>186949</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.291</td>\n",
       "      <td>175.574</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:02bA26OEe0nNFyE3YcNx4K</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>207409</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.00435</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.0877</td>\n",
       "      <td>0.189</td>\n",
       "      <td>88.581</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:7IPDhCIQlpvxVxtC1Q7Jq4</td>\n",
       "      <td>Cathedral</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>179694</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.00978</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.397</td>\n",
       "      <td>119.056</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:65fPteG9ctHt2rrJxlbMr8</td>\n",
       "      <td>Shaking Their Hands</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>222489</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.551</td>\n",
       "      <td>89.485</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:4UgkFdXpJD0fhw06BMk0bz</td>\n",
       "      <td>Adore Adore Adore</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>157766</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.402</td>\n",
       "      <td>176.054</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Track URI           Track Name      Album Name  \\\n",
       "0  spotify:track:0UOeq7bSskoJa4cJaJOmFS              Ticking  Letter to Self   \n",
       "1  spotify:track:02bA26OEe0nNFyE3YcNx4K                Heavy  Letter to Self   \n",
       "2  spotify:track:7IPDhCIQlpvxVxtC1Q7Jq4            Cathedral  Letter to Self   \n",
       "3  spotify:track:65fPteG9ctHt2rrJxlbMr8  Shaking Their Hands  Letter to Self   \n",
       "4  spotify:track:4UgkFdXpJD0fhw06BMk0bz    Adore Adore Adore  Letter to Self   \n",
       "\n",
       "  Artist Name(s) Release Date  Duration (ms)  Popularity  Explicit  \\\n",
       "0        SPRINTS   2024-01-05         186949          29     False   \n",
       "1        SPRINTS   2024-01-05         207409          46     False   \n",
       "2        SPRINTS   2024-01-05         179694          31     False   \n",
       "3        SPRINTS   2024-01-05         222489          29     False   \n",
       "4        SPRINTS   2024-01-05         157766          38     False   \n",
       "\n",
       "                    Added By              Added At  ...   Key Loudness  Mode  \\\n",
       "0  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T00:53:10Z  ...  11.0   -6.490   1.0   \n",
       "1  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T00:53:10Z  ...  11.0   -5.925   1.0   \n",
       "2  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T00:53:10Z  ...   7.0   -6.231   1.0   \n",
       "3  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T00:53:10Z  ...   4.0   -5.658   0.0   \n",
       "4  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T00:53:10Z  ...   4.0   -4.401   0.0   \n",
       "\n",
       "   Speechiness  Acousticness  Instrumentalness  Liveness  Valence    Tempo  \\\n",
       "0       0.3440       0.02500          0.076500    0.0934    0.291  175.574   \n",
       "1       0.0591       0.00435          0.000738    0.0877    0.189   88.581   \n",
       "2       0.0473       0.00978          0.002700    0.0887    0.397  119.056   \n",
       "3       0.0533       0.19900          0.108000    0.1330    0.551   89.485   \n",
       "4       0.2570       0.01070          0.000107    0.1010    0.402  176.054   \n",
       "\n",
       "   Time Signature  \n",
       "0             4.0  \n",
       "1             4.0  \n",
       "2             4.0  \n",
       "3             4.0  \n",
       "4             4.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liked Albums in Recent Years\n",
    "df_fav_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0d6345-80d1-4b33-a4c5-10b1e138bbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track URI</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:54KEm0VI9i3ic7VHHKHKRx</td>\n",
       "      <td>¬øC√≥mo As√≠?</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>169654</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.04170</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.379</td>\n",
       "      <td>135.985</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:5mVkTPlTPxlQOn7kEvuM3j</td>\n",
       "      <td>Me Pongo Loca</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>177815</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.03710</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.407</td>\n",
       "      <td>114.999</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:6XaJfhwof7qIgbbXO5tIQI</td>\n",
       "      <td>Igual Que Un √Ångel (with Peso Pluma)</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis;Peso Pluma</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>260370</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.482</td>\n",
       "      <td>108.001</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:52x8HIGuk1gGTlvO8CuLNS</td>\n",
       "      <td>Pensamientos Intrusivos</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>192027</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.511</td>\n",
       "      <td>119.994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:3RleMgz4iO0BNezGdSxDnY</td>\n",
       "      <td>Diosa</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>156037</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.06750</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.698</td>\n",
       "      <td>107.994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Track URI                            Track Name  \\\n",
       "0  spotify:track:54KEm0VI9i3ic7VHHKHKRx                            ¬øC√≥mo As√≠?   \n",
       "1  spotify:track:5mVkTPlTPxlQOn7kEvuM3j                         Me Pongo Loca   \n",
       "2  spotify:track:6XaJfhwof7qIgbbXO5tIQI  Igual Que Un √Ångel (with Peso Pluma)   \n",
       "3  spotify:track:52x8HIGuk1gGTlvO8CuLNS               Pensamientos Intrusivos   \n",
       "4  spotify:track:3RleMgz4iO0BNezGdSxDnY                                 Diosa   \n",
       "\n",
       "  Album Name         Artist Name(s) Release Date  Duration (ms)  Popularity  \\\n",
       "0  ORQU√çDEAS             Kali Uchis   2024-01-12         169654          58   \n",
       "1  ORQU√çDEAS             Kali Uchis   2024-01-12         177815          58   \n",
       "2  ORQU√çDEAS  Kali Uchis;Peso Pluma   2024-01-12         260370          77   \n",
       "3  ORQU√çDEAS             Kali Uchis   2024-01-12         192027          63   \n",
       "4  ORQU√çDEAS             Kali Uchis   2024-01-12         156037          60   \n",
       "\n",
       "   Explicit                   Added By              Added At  ...  Key  \\\n",
       "0     False  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z  ...  6.0   \n",
       "1      True  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z  ...  7.0   \n",
       "2     False  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z  ...  5.0   \n",
       "3     False  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z  ...  9.0   \n",
       "4     False  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z  ...  5.0   \n",
       "\n",
       "  Loudness  Mode  Speechiness  Acousticness  Instrumentalness  Liveness  \\\n",
       "0   -7.662   0.0       0.0892       0.04170          0.346000     0.154   \n",
       "1   -8.680   0.0       0.0426       0.03710          0.152000     0.106   \n",
       "2   -5.340   0.0       0.0320       0.00449          0.000663     0.185   \n",
       "3   -8.333   0.0       0.0394       0.57500          0.012900     0.110   \n",
       "4   -5.518   0.0       0.0668       0.06750          0.000101     0.078   \n",
       "\n",
       "   Valence    Tempo  Time Signature  \n",
       "0    0.379  135.985             4.0  \n",
       "1    0.407  114.999             4.0  \n",
       "2    0.482  108.001             4.0  \n",
       "3    0.511  119.994             4.0  \n",
       "4    0.698  107.994             4.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Albums Not Liked in Recent Years\n",
    "df_not_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c4a16f-a5d1-4a67-8091-49d5f29084b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track URI</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:0eW1qPRpYEOhivcuNhpqzn</td>\n",
       "      <td>Totally Blue</td>\n",
       "      <td>Georgie</td>\n",
       "      <td>Twin Shadow</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>183779</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-03-21T13:44:16Z</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>-9.777</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.251</td>\n",
       "      <td>124.042</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:5U0U5yYXmFDlguWdk8kpv1</td>\n",
       "      <td>Good Times</td>\n",
       "      <td>Georgie</td>\n",
       "      <td>Twin Shadow</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>176582</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-03-21T13:44:16Z</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.546</td>\n",
       "      <td>157.936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:7yZnudvNop0nP8DrHxAxBF</td>\n",
       "      <td>As Soon As You Can</td>\n",
       "      <td>Georgie</td>\n",
       "      <td>Twin Shadow</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>225384</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-03-21T13:44:16Z</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.187</td>\n",
       "      <td>77.793</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:67I1Z6RFau36Uh4FeXpUur</td>\n",
       "      <td>Funny Games</td>\n",
       "      <td>Georgie</td>\n",
       "      <td>Twin Shadow</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>142702</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-03-21T13:44:16Z</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.821</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.322</td>\n",
       "      <td>145.989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:3nd5lvsXMNxK8ch0Q52vNN</td>\n",
       "      <td>Geor(g.i.e.)</td>\n",
       "      <td>Georgie</td>\n",
       "      <td>Twin Shadow</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>95696</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-03-21T13:44:16Z</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>-17.813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.647</td>\n",
       "      <td>78.907</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Track URI          Track Name Album Name  \\\n",
       "0  spotify:track:0eW1qPRpYEOhivcuNhpqzn        Totally Blue    Georgie   \n",
       "1  spotify:track:5U0U5yYXmFDlguWdk8kpv1          Good Times    Georgie   \n",
       "2  spotify:track:7yZnudvNop0nP8DrHxAxBF  As Soon As You Can    Georgie   \n",
       "3  spotify:track:67I1Z6RFau36Uh4FeXpUur         Funny Games    Georgie   \n",
       "4  spotify:track:3nd5lvsXMNxK8ch0Q52vNN        Geor(g.i.e.)    Georgie   \n",
       "\n",
       "  Artist Name(s) Release Date  Duration (ms)  Popularity  Explicit  \\\n",
       "0    Twin Shadow   2025-03-14         183779          24     False   \n",
       "1    Twin Shadow   2025-03-14         176582          22     False   \n",
       "2    Twin Shadow   2025-03-14         225384          23     False   \n",
       "3    Twin Shadow   2025-03-14         142702          18     False   \n",
       "4    Twin Shadow   2025-03-14          95696          19     False   \n",
       "\n",
       "                    Added By              Added At  ... Key Loudness  Mode  \\\n",
       "0  mmr4r23xnc6oh1c77lysfbqg4  2025-03-21T13:44:16Z  ...  11   -9.777     1   \n",
       "1  mmr4r23xnc6oh1c77lysfbqg4  2025-03-21T13:44:16Z  ...   9   -4.492     1   \n",
       "2  mmr4r23xnc6oh1c77lysfbqg4  2025-03-21T13:44:16Z  ...  10  -12.039     0   \n",
       "3  mmr4r23xnc6oh1c77lysfbqg4  2025-03-21T13:44:16Z  ...   2   -9.821     1   \n",
       "4  mmr4r23xnc6oh1c77lysfbqg4  2025-03-21T13:44:16Z  ...   9  -17.813     1   \n",
       "\n",
       "   Speechiness  Acousticness  Instrumentalness  Liveness  Valence    Tempo  \\\n",
       "0       0.0347         0.716          0.008000    0.1000    0.251  124.042   \n",
       "1       0.0301         0.668          0.000374    0.1070    0.546  157.936   \n",
       "2       0.0431         0.722          0.001650    0.1090    0.187   77.793   \n",
       "3       0.0671         0.762          0.094100    0.0994    0.322  145.989   \n",
       "4       0.0332         0.989          0.928000    0.0997    0.647   78.907   \n",
       "\n",
       "   Time Signature  \n",
       "0               4  \n",
       "1               4  \n",
       "2               4  \n",
       "3               4  \n",
       "4               4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Albums I neither enjoyed or hated, but were simply Mid\n",
    "df_mid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a190ec91-73e0-40c5-95b4-fc212abd1730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track URI</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:66wM8T14qRselu34qFBhC2</td>\n",
       "      <td>Bloodsport</td>\n",
       "      <td>Pain to Power</td>\n",
       "      <td>Maruja</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>222720</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-09-12T13:58:27Z</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-5.002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.02150</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>89.395</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:3KQFlED2WlEBOFRK61eI05</td>\n",
       "      <td>Look Down On Us</td>\n",
       "      <td>Pain to Power</td>\n",
       "      <td>Maruja</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>598360</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-09-12T13:58:27Z</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.05120</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>155.871</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:3g0xd9m1MxKRiIC2Xw4998</td>\n",
       "      <td>Saoirse</td>\n",
       "      <td>Pain to Power</td>\n",
       "      <td>Maruja</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>313746</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-09-12T13:58:27Z</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-7.537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.47100</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>137.695</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:3mBuyTkisnYVbkyDwo8DtV</td>\n",
       "      <td>Born to Die</td>\n",
       "      <td>Pain to Power</td>\n",
       "      <td>Maruja</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>604146</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-09-12T13:58:27Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-8.128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.48300</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>119.095</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:6A5288oCKM2gN3tqzAqiYI</td>\n",
       "      <td>Break the Tension</td>\n",
       "      <td>Pain to Power</td>\n",
       "      <td>Maruja</td>\n",
       "      <td>2025-09-12</td>\n",
       "      <td>225186</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>jaytroymo</td>\n",
       "      <td>2025-09-12T13:58:27Z</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-4.498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>160.353</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Track URI         Track Name     Album Name  \\\n",
       "0  spotify:track:66wM8T14qRselu34qFBhC2         Bloodsport  Pain to Power   \n",
       "1  spotify:track:3KQFlED2WlEBOFRK61eI05    Look Down On Us  Pain to Power   \n",
       "2  spotify:track:3g0xd9m1MxKRiIC2Xw4998            Saoirse  Pain to Power   \n",
       "3  spotify:track:3mBuyTkisnYVbkyDwo8DtV        Born to Die  Pain to Power   \n",
       "4  spotify:track:6A5288oCKM2gN3tqzAqiYI  Break the Tension  Pain to Power   \n",
       "\n",
       "  Artist Name(s) Release Date  Duration (ms)  Popularity  Explicit   Added By  \\\n",
       "0         Maruja   2025-09-12         222720          42      True  jaytroymo   \n",
       "1         Maruja   2025-09-12         598360          39      True  jaytroymo   \n",
       "2         Maruja   2025-09-12         313746          37     False  jaytroymo   \n",
       "3         Maruja   2025-09-12         604146          37     False  jaytroymo   \n",
       "4         Maruja   2025-09-12         225186          35      True  jaytroymo   \n",
       "\n",
       "               Added At  ...   Key Loudness  Mode  Speechiness  Acousticness  \\\n",
       "0  2025-09-12T13:58:27Z  ...   7.0   -5.002   1.0       0.2240       0.02150   \n",
       "1  2025-09-12T13:58:27Z  ...   2.0   -5.961   0.0       0.0594       0.05120   \n",
       "2  2025-09-12T13:58:27Z  ...  10.0   -7.537   1.0       0.0391       0.47100   \n",
       "3  2025-09-12T13:58:27Z  ...   4.0   -8.128   0.0       0.0447       0.48300   \n",
       "4  2025-09-12T13:58:27Z  ...  11.0   -4.498   1.0       0.0908       0.00678   \n",
       "\n",
       "   Instrumentalness  Liveness  Valence    Tempo  Time Signature  \n",
       "0          0.001540     0.405   0.3220   89.395             4.0  \n",
       "1          0.079900     0.339   0.1460  155.871             4.0  \n",
       "2          0.327000     0.108   0.2510  137.695             3.0  \n",
       "3          0.120000     0.158   0.0713  119.095             4.0  \n",
       "4          0.000364     0.388   0.1200  160.353             4.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New Music Friday Playlist\n",
    "df_nmf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64bfbf76-1649-4542-b001-2fedd527ecd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BODEGA</td>\n",
       "      <td>Folly Group, Gustaf, Warmduscher, Deadletter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHE</td>\n",
       "      <td>OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonnie Prince Billy</td>\n",
       "      <td>Palace Music, Will Oldham, Palace Brothers, Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Telethon</td>\n",
       "      <td>Barely March, Smol Data, Diva Sweetly, Bigger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heather Maloney</td>\n",
       "      <td>Heather Maloney &amp; Darlingside, Twisted Pine, R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Artist                                    Similar Artists\n",
       "0               BODEGA  Folly Group, Gustaf, Warmduscher, Deadletter, ...\n",
       "1                  CHE  OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...\n",
       "2  Bonnie Prince Billy  Palace Music, Will Oldham, Palace Brothers, Bi...\n",
       "3             Telethon  Barely March, Smol Data, Diva Sweetly, Bigger ...\n",
       "4      Heather Maloney  Heather Maloney & Darlingside, Twisted Pine, R..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar Artists to Recently Played Artists (Last.fm)\n",
    "\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30386-5197-4245-9871-cffbe4952a33",
   "metadata": {},
   "source": [
    "> A quick reminder of the standard columns of a spotify export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a3f0c33-76f1-4d7b-95c3-988b1ca941a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track URI', 'Track Name', 'Album Name', 'Artist Name(s)',\n",
       "       'Release Date', 'Duration (ms)', 'Popularity', 'Explicit', 'Added By',\n",
       "       'Added At', 'Genres', 'Record Label', 'Danceability', 'Energy', 'Key',\n",
       "       'Loudness', 'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness',\n",
       "       'Liveness', 'Valence', 'Tempo', 'Time Signature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694749b-c05c-45c8-8c17-6f30a6ffc54d",
   "metadata": {},
   "source": [
    "> What's available in the Similar dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fe763b3-50c4-474d-8363-a5c41461ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Artist', 'Similar Artists'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25a6b9-e488-4c3a-9e27-4cf15e57c504",
   "metadata": {},
   "source": [
    "### Add Target Labels for Training Feature\n",
    "We need to assign a score to songs I've faved on spotify (100), albums I've enjoyed in recent years (65), albums that were mid (45), and albums that I have not enjoyed in recent years (30) to train the model on the types of songs I don't like, like, and love. 'liked' will be our target variable, later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a802d4-ff06-4dab-886d-059ed0ee2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign liked scores before combining\n",
    "df_liked['liked'] = 100\n",
    "df_fav_albums['liked'] = 65\n",
    "df_mid['liked'] = 45\n",
    "df_not_liked['liked'] = 30\n",
    "df_nmf['liked'] = np.nan \n",
    "\n",
    "# Add playlist_origin column before combining\n",
    "df_liked['playlist_origin'] = 'df_liked'\n",
    "df_fav_albums['playlist_origin'] = 'df_fav_albums'\n",
    "df_not_liked['playlist_origin'] = 'df_not_liked'\n",
    "df_mid['playlist_origin'] = 'df_mid'\n",
    "df_nmf['playlist_origin'] = 'df_nmf'\n",
    "df_liked_similar['source'] = 'liked_similar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10e0ba-5881-4cd4-91e0-630063a72dd8",
   "metadata": {},
   "source": [
    "### Check application of the target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4add9e6b-4a3c-46f0-bc43-4bb4215cd97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0    100        df_liked\n",
       "1    100        df_liked\n",
       "2    100        df_liked\n",
       "3    100        df_liked\n",
       "4    100        df_liked"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6cb7c2-b08e-4d00-9cd7-fcea6eec1ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0     65   df_fav_albums\n",
       "1     65   df_fav_albums\n",
       "2     65   df_fav_albums\n",
       "3     65   df_fav_albums\n",
       "4     65   df_fav_albums"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fav_albums[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ca431aa-e88b-4857-8d9a-4d09a71b3866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>df_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>df_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>df_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>df_mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>df_mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0     45          df_mid\n",
       "1     45          df_mid\n",
       "2     45          df_mid\n",
       "3     45          df_mid\n",
       "4     45          df_mid"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mid[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b72fb6-dac5-4d75-b6fd-b3ca1d8973f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0     30    df_not_liked\n",
       "1     30    df_not_liked\n",
       "2     30    df_not_liked\n",
       "3     30    df_not_liked\n",
       "4     30    df_not_liked"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c75164a9-8182-463f-a450-2534f52aeb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0    NaN          df_nmf\n",
       "1    NaN          df_nmf\n",
       "2    NaN          df_nmf\n",
       "3    NaN          df_nmf\n",
       "4    NaN          df_nmf"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e40fa4a1-a55a-42c6-b3b1-8994b44c3602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BODEGA</td>\n",
       "      <td>Folly Group, Gustaf, Warmduscher, Deadletter, ...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHE</td>\n",
       "      <td>OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonnie Prince Billy</td>\n",
       "      <td>Palace Music, Will Oldham, Palace Brothers, Bi...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Telethon</td>\n",
       "      <td>Barely March, Smol Data, Diva Sweetly, Bigger ...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heather Maloney</td>\n",
       "      <td>Heather Maloney &amp; Darlingside, Twisted Pine, R...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Artist                                    Similar Artists  \\\n",
       "0               BODEGA  Folly Group, Gustaf, Warmduscher, Deadletter, ...   \n",
       "1                  CHE  OsamaSon, 1oneam, prettifun, ohsxnta, nettspen...   \n",
       "2  Bonnie Prince Billy  Palace Music, Will Oldham, Palace Brothers, Bi...   \n",
       "3             Telethon  Barely March, Smol Data, Diva Sweetly, Bigger ...   \n",
       "4      Heather Maloney  Heather Maloney & Darlingside, Twisted Pine, R...   \n",
       "\n",
       "          source  \n",
       "0  liked_similar  \n",
       "1  liked_similar  \n",
       "2  liked_similar  \n",
       "3  liked_similar  \n",
       "4  liked_similar  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar[['Artist', 'Similar Artists', 'source']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4bb9c-a4ea-4286-bf9b-9a7575d9ffcf",
   "metadata": {},
   "source": [
    "## Data Cleaning üßπ\n",
    "Before diving into modeling, I need to clean and prepare the data to ensure it‚Äôs ready for analysis. This section focuses on merging my datasets, handling duplicates, filling missing values, and making sure the data is in the best possible shape. Here‚Äôs what I‚Äôll tackle:\n",
    "\n",
    "1. **Merging Datasets**: I‚Äôll combine my liked songs, favorite albums, not-liked albums, and New Music Friday tracks into a single dataframe.\n",
    "2. **Removing Duplicates**: I‚Äôll ensure each track is unique, prioritizing higher \"liked\" scores for duplicates.\n",
    "3. **Handling Missing Values**: I‚Äôll fill gaps in genres using Last.fm‚Äôs richer data and save a backup of missing artists for manual review later.\n",
    "4. **Dropping Irrelevant Columns**: I‚Äôll remove columns that won‚Äôt contribute to the model.\n",
    "5. **Final Checks**: I‚Äôll verify the dataset‚Äôs integrity and distribution before moving to modeling.\n",
    "\n",
    "By the end of this section, I‚Äôll have a clean, unified dataset ready for feature engineering and model training. Let‚Äôs get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44856ee-a472-41f3-8622-01d76e370849",
   "metadata": {},
   "source": [
    "## Merge The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34bd66a5-2ed8-4eda-b8df-09a5feaa782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_liked, df_fav_albums, df_mid, df_not_liked, df_nmf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f9b1007-6bfe-429b-bf10-5de0241f9e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18905, 26)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How Large is the Dataset, Now?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035bf83-b7da-4fbb-bc26-f1ed816a5798",
   "metadata": {},
   "source": [
    "#### Remove the Duplicates üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "861de4ff-4fb7-421b-8923-419d750172bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16172, 26)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates: Keep the highest 'liked' score (100 > 65)\n",
    "df = df.sort_values(by='liked', ascending=False)  # Ensures 100-rated songs come first\n",
    "df = df.drop_duplicates(subset=['Track Name', 'Artist Name(s)'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2580a-e10a-4d8f-a9fc-258a2777d37f",
   "metadata": {},
   "source": [
    "#### Drop columns that won't help the model üí£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a1551b-d6a6-4ff4-b5f3-f333f2e4e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Added By', 'Added At', 'Time Signature'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff07c-0b26-47bf-af09-6c87b741ba13",
   "metadata": {},
   "source": [
    "#### Handle missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34d7d185-71c3-4aa3-8b81-8920a76aa070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track URI              0\n",
       "Track Name             0\n",
       "Album Name             0\n",
       "Artist Name(s)         0\n",
       "Release Date           0\n",
       "Duration (ms)          0\n",
       "Popularity             0\n",
       "Explicit               0\n",
       "Genres              7443\n",
       "Record Label           3\n",
       "Danceability          11\n",
       "Energy                11\n",
       "Key                   11\n",
       "Loudness              11\n",
       "Mode                  11\n",
       "Speechiness           11\n",
       "Acousticness          11\n",
       "Instrumentalness      11\n",
       "Liveness              11\n",
       "Valence               11\n",
       "Tempo                 11\n",
       "liked               1174\n",
       "playlist_origin        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658750-d956-442d-99ed-2dca4323ec47",
   "metadata": {},
   "source": [
    "## Getting New Genre Data From Last.fm üü¢üéµ\n",
    "Since half of the genres are missing from Spotify songs, I decided to use the richer data from Last.fm's crowd-sourced genre tags. There are some silly tags in there, so I added a list of ignored tags that I update weekly based on what I see in the data. This ensures the genres are meaningful and relevant for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b250a-eb92-4eb4-a0a1-c20f0550eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2392 new artist-album pairs.\n",
      "Found 1864 new artist-album pairs to process.\n",
      "Processed 50/1864 artist-album pairs.\n"
     ]
    }
   ],
   "source": [
    "class LastFMGenreFetcher:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        \n",
    "        # Define tags to ignore\n",
    "        # These are the crowd-sourced tags that are more about personal taste than actual genres\n",
    "        self.ignored_tags = {\n",
    "            'seen live',\n",
    "            'albums i own',\n",
    "            'favorite',\n",
    "            'favourites',\n",
    "            'favourite',\n",
    "            'my playlist',\n",
    "            'spotify',\n",
    "            'pandora',\n",
    "            'wish i had seen live',\n",
    "            'awesome',\n",
    "            'love at first listen',\n",
    "            'love',\n",
    "            'amazing',\n",
    "            'listened',\n",
    "            'personal',\n",
    "            'my music'\n",
    "        }\n",
    "        \n",
    "        # Define variations of female vocalist to standardize\n",
    "        # Because Last.fm users love to tag the same thing in 10 different ways üé§\n",
    "        self.female_vocalist_variants = {\n",
    "            'female vocalists',\n",
    "            'female vocalist',\n",
    "            'female vocals',\n",
    "            'female fronted',\n",
    "            'female voices',\n",
    "            'female voice',\n",
    "            'female singers',\n",
    "            'female singer'\n",
    "        }\n",
    "        \n",
    "        # Genre groups that typically appear together\n",
    "        self.genre_compatibility = {\n",
    "            'indie': ['indie pop', 'indie rock', 'indie folk', 'alternative', 'singer-songwriter'],\n",
    "            'rock': ['alternative rock', 'indie rock', 'hard rock', 'classic rock', 'punk'],\n",
    "            'electronic': ['techno', 'house', 'edm', 'ambient', 'idm', 'electronica'],\n",
    "            'metal': ['heavy metal', 'death metal', 'black metal', 'thrash metal', 'doom metal'],\n",
    "            'folk': ['indie folk', 'folk rock', 'americana', 'singer-songwriter', 'acoustic'],\n",
    "            'pop': ['indie pop', 'synth pop', 'dream pop', 'electropop', 'pop rock'],\n",
    "            'hip-hop': ['rap', 'trap', 'r&b', 'urban', 'grime'],\n",
    "            'jazz': ['fusion', 'bebop', 'smooth jazz', 'soul', 'funk'],\n",
    "            'classical': ['orchestral', 'chamber music', 'piano', 'instrumental', 'contemporary classical']\n",
    "        }\n",
    "        \n",
    "        # This identifies genres that rarely appear together\n",
    "        self.genre_incompatibility = {\n",
    "            'classical': ['metal', 'rap', 'edm', 'techno', 'dubstep'],\n",
    "            'death metal': ['pop', 'r&b', 'jazz', 'folk', 'ambient'],\n",
    "            'christian': ['black metal', 'satanic', 'pagan'],\n",
    "            'country': ['techno', 'edm', 'black metal', 'death metal'],\n",
    "            'jazz': ['black metal', 'death metal', 'hardcore', 'screamo'],\n",
    "            'k-pop': ['death metal', 'black metal', 'doom metal']\n",
    "        }\n",
    "        \n",
    "    def _make_request(self, params: Dict)  -> Dict:\n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            sleep(self.rate_limit_delay)  # Basic rate limiting to avoid angering the Last.fm API gods\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed for params {params}: {e}\")\n",
    "            if getattr(response, 'status_code', None) == 429:\n",
    "                print(\"Rate limit exceeded, increasing delay. Patience is a virtue!\")\n",
    "                self.rate_limit_delay *= 2\n",
    "                sleep(5)  # Wait before retry\n",
    "            return None\n",
    "\n",
    "    def get_artist_tags(self, artist_name: str) -> List[str]:\n",
    "        params = {\n",
    "            'method': 'artist.getTopTags',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        data = self._make_request(params)\n",
    "        \n",
    "        if not data or 'toptags' not in data:\n",
    "            return []  # Sometimes Last.fm just doesn't have the data ü§∑‚Äç‚ôÇÔ∏è\n",
    "            \n",
    "        tags = []\n",
    "        seen_tags = set()  # Track unique tags to avoid duplicates\n",
    "        has_female_vocalist = False\n",
    "        \n",
    "        for tag in data['toptags'].get('tag', []):\n",
    "            tag_name = tag['name'].lower()\n",
    "            \n",
    "            # Skip if tag is in ignored list\n",
    "            if tag_name in self.ignored_tags:\n",
    "                continue  # Bye-bye, irrelevant tags!\n",
    "                \n",
    "            # Handle female vocalist variations\n",
    "            if tag_name in self.female_vocalist_variants:\n",
    "                if not has_female_vocalist:\n",
    "                    tags.insert(0, 'female vocalist')  # Standardize and prioritize this tag\n",
    "                    has_female_vocalist = True\n",
    "                continue\n",
    "            \n",
    "            # Only add tag if we haven't seen it before\n",
    "            if tag_name not in seen_tags:\n",
    "                tags.append(tag_name)\n",
    "                seen_tags.add(tag_name)\n",
    "                \n",
    "        return tags[:10]  # Return up to 10 tags because less is more, right?\n",
    "        \n",
    "    def get_album_tags(self, artist_name: str, album_name: str, release_date: str = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get tags specifically for an album, with verification against artist tags.\n",
    "        \"\"\"\n",
    "        # Try to get album-specific tags first\n",
    "        params = {\n",
    "            'method': 'album.getTopTags',\n",
    "            'artist': artist_name,\n",
    "            'album': album_name,\n",
    "            'api_key': self.api_key,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        album_data = self._make_request(params)\n",
    "        \n",
    "        # Get artist tags for comparison\n",
    "        artist_tags = self.get_artist_tags(artist_name)\n",
    "        \n",
    "        # Extract album tags if available\n",
    "        album_tags = []\n",
    "        if album_data and 'toptags' in album_data and 'tag' in album_data['toptags']:\n",
    "            for tag in album_data['toptags'].get('tag', []):\n",
    "                tag_name = tag['name'].lower()\n",
    "                if tag_name not in self.ignored_tags:\n",
    "                    album_tags.append(tag_name)\n",
    "        \n",
    "        # This verifies tags when we have both album and artist data\n",
    "        if album_tags and artist_tags:\n",
    "            verified_tags = self._verify_tags(album_tags, artist_tags, release_date)\n",
    "            return verified_tags[:10]\n",
    "        elif album_tags:\n",
    "            return album_tags[:10]\n",
    "        else:\n",
    "            return artist_tags[:10]\n",
    "    \n",
    "    def _verify_tags(self, album_tags: List[str], artist_tags: List[str], release_date: str = None) -> List[str]:\n",
    "        # Convert to sets for easier comparison\n",
    "        album_tag_set = set(album_tags)\n",
    "        artist_tag_set = set(artist_tags)\n",
    "        \n",
    "        # Calculate overlap between tags\n",
    "        overlap = album_tag_set.intersection(artist_tag_set)\n",
    "        overlap_ratio = len(overlap) / len(album_tag_set) if album_tag_set else 0\n",
    "        \n",
    "        # This means we have good tag agreement\n",
    "        if overlap_ratio >= 0.3:\n",
    "            return album_tags\n",
    "        \n",
    "        # Check for incompatible genres\n",
    "        for tag in album_tags:\n",
    "            for incompatible_genre, incompatible_tags in self.genre_incompatibility.items():\n",
    "                if tag == incompatible_genre:\n",
    "                    for artist_tag in artist_tags:\n",
    "                        if artist_tag in incompatible_tags:\n",
    "                            # This indicates a likely mismatch\n",
    "                            return artist_tags\n",
    "        \n",
    "        # Use release date as tiebreaker if available\n",
    "        if release_date:\n",
    "            try:\n",
    "                year = int(release_date.split('-')[0])\n",
    "                current_year = datetime.now().year\n",
    "                \n",
    "                # This prioritizes album tags for recent releases\n",
    "                if year >= current_year - 2:\n",
    "                    merged_tags = album_tags[:7] + [tag for tag in artist_tags if tag not in album_tag_set][:3]\n",
    "                    return merged_tags\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Merge tags with preference to album tags\n",
    "        merged_tags = album_tags[:7] + [tag for tag in artist_tags if tag not in album_tag_set][:3]\n",
    "        return merged_tags\n",
    "\n",
    "def update_genre_data(api_key: str, dataframes: List[pd.DataFrame], output_file: str = 'data/ten_genres.csv') -> None:\n",
    "    # Initialize the API client\n",
    "    api = LastFMGenreFetcher(api_key)\n",
    "    \n",
    "    # Get all unique artist-album pairs from the dataframes\n",
    "    artist_album_pairs = []\n",
    "    for df in dataframes:\n",
    "        if 'Artist Name(s)' in df.columns and 'Album Name' in df.columns and 'Release Date' in df.columns:\n",
    "            pairs = df[['Artist Name(s)', 'Album Name', 'Release Date']].drop_duplicates()\n",
    "            for _, row in pairs.iterrows():\n",
    "                artist = row['Artist Name(s)'].split(',')[0].strip() if pd.notna(row['Artist Name(s)']) else None\n",
    "                album = row['Album Name'] if pd.notna(row['Album Name']) else None\n",
    "                release_date = row['Release Date'] if pd.notna(row['Release Date']) else None\n",
    "                if artist and album:\n",
    "                    artist_album_pairs.append((artist, album, release_date))\n",
    "    \n",
    "    # Load existing data\n",
    "    existing_data = {}\n",
    "    try:\n",
    "        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "            existing_data = pd.read_csv(output_file).set_index(['Artist', 'Album'])['Genres'].to_dict()\n",
    "    except (pd.errors.EmptyDataError, KeyError):\n",
    "        print(\"No existing genre data found or file is empty. Starting fresh.\")\n",
    "    \n",
    "    # Load obscure artist genres and merge\n",
    "    obscure_artists = pd.read_csv(\"data/obscure_artists_mike_likes.csv\", quotechar='\"')\n",
    "    obscure_artists_dict = {}\n",
    "    for _, row in obscure_artists.iterrows():\n",
    "        obscure_artists_dict[(row['Artist'], 'ANY_ALBUM')] = row['Genres']\n",
    "    \n",
    "    # Merge genres from obscure artists with existing data\n",
    "    existing_data.update(obscure_artists_dict)\n",
    "    \n",
    "    # Identify new artist-album pairs that aren't in existing data\n",
    "    new_pairs = [(artist, album, release_date) for artist, album, release_date in artist_album_pairs]\n",
    "    \n",
    "    if not new_pairs:\n",
    "        print(\"No new artist-album pairs to process!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(new_pairs)} new artist-album pairs to process.\")\n",
    "    \n",
    "    # Process new pairs with ThreadPoolExecutor\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_pair = {\n",
    "            executor.submit(api.get_album_tags, artist, album, release_date): (artist, album) \n",
    "            for artist, album, release_date in new_pairs\n",
    "        }\n",
    "        \n",
    "        completed = 0\n",
    "        for future in as_completed(future_to_pair):\n",
    "            artist, album = future_to_pair[future]\n",
    "            try:\n",
    "                tags = future.result()\n",
    "                if tags:\n",
    "                    results[(artist, album)] = ', '.join(tags)\n",
    "                completed += 1\n",
    "                if completed % 50 == 0 or (len(new_pairs) < 50 and completed % 10 == 0):\n",
    "                    print(f\"Processed {completed}/{len(new_pairs)} artist-album pairs.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {artist} - {album}: {e}\")\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    all_data = {**existing_data, **results}\n",
    "    \n",
    "    # Save to CSV with multi-index\n",
    "    df_output = pd.DataFrame(\n",
    "        [{'Artist': artist, 'Album': album, 'Genres': genres} \n",
    "         for (artist, album), genres in all_data.items()]\n",
    "    )\n",
    "    df_output.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSuccessfully updated {output_file} with {len(results)} new artist-album pairs!\")\n",
    "\n",
    "# Define genre cleaning function\n",
    "def clean_genres(genre_string):\n",
    "    \"\"\"\n",
    "    Clean genre strings by:\n",
    "    1. Removing duplicates\n",
    "    2. Removing '|' bars\n",
    "    3. Filtering out genres with numbers\n",
    "    4. Filtering out genres longer than 3 words\n",
    "    \"\"\"\n",
    "    if pd.isna(genre_string):\n",
    "        return genre_string\n",
    "        \n",
    "    # Split by | and flatten all genres into one list\n",
    "    all_parts = [part.strip() for part in genre_string.split('|')]\n",
    "    all_genres = []\n",
    "    for part in all_parts:\n",
    "        genres = [g.strip() for g in part.split(',')]\n",
    "        all_genres.extend(genres)\n",
    "    \n",
    "    # Remove duplicates, numbers, and long genres while preserving order\n",
    "    seen = set()\n",
    "    unique_genres = []\n",
    "    for genre in all_genres:\n",
    "        # Skip if empty\n",
    "        if not genre:\n",
    "            continue\n",
    "        \n",
    "        # Skip if contains digits\n",
    "        if any(char.isdigit() for char in genre):\n",
    "            continue\n",
    "            \n",
    "        # Skip if longer than 3 words\n",
    "        if len(genre.split()) > 3:\n",
    "            continue\n",
    "            \n",
    "        # Add if not seen before (case-insensitive check)\n",
    "        if genre.lower() not in seen:\n",
    "            unique_genres.append(genre)\n",
    "            seen.add(genre.lower())\n",
    "    \n",
    "    return ', '.join(unique_genres)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = '74a510ecc9fc62bf3e0edc6adc2e99f9'\n",
    "\n",
    "    # === Add this snippet here ===\n",
    "    cache_file = \"data/ten_genres.csv\"\n",
    "    if os.path.exists(cache_file) and os.path.getsize(cache_file) > 0:\n",
    "        cached_df = pd.read_csv(cache_file)\n",
    "        cached_pairs = set(zip(cached_df['Artist'], cached_df['Album']))\n",
    "        cached_any_album = set((artist, 'ANY_ALBUM') for artist in cached_df['Artist'].unique())\n",
    "        df_new = df[~df.apply(\n",
    "            lambda r: ((r['Artist Name(s)'].split(',')[0].strip(), r['Album Name']) in cached_pairs) or \n",
    "                      ((r['Artist Name(s)'].split(',')[0].strip(), 'ANY_ALBUM') in cached_any_album),\n",
    "            axis=1\n",
    "        )]\n",
    "    else:\n",
    "        df_new = df.copy()\n",
    "\n",
    "    print(f\"Processing {len(df_new)} new artist-album pairs.\")\n",
    "\n",
    "    # Update genre data\n",
    "    update_genre_data(API_KEY, [df_new], 'data/ten_genres.csv')\n",
    "\n",
    "    # Load the ten_genres.csv file\n",
    "    ten_genres = pd.read_csv(\"data/ten_genres.csv\")\n",
    "    \n",
    "    # Clean genres in the ten_genres DataFrame\n",
    "    ten_genres[\"Genres\"] = ten_genres[\"Genres\"].apply(clean_genres)\n",
    "    \n",
    "    # Save the cleaned ten_genres back to CSV\n",
    "    ten_genres.to_csv(\"data/ten_genres.csv\", index=False)\n",
    "\n",
    "    # Extract the primary artist (before the comma)\n",
    "    df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0]\n",
    "    ten_genres[\"Primary Artist\"] = ten_genres[\"Artist\"].str.split(\",\").str[0]\n",
    "\n",
    "    # Merge, prioritizing ten_genres\n",
    "    df = df.merge(ten_genres[[\"Primary Artist\", \"Genres\"]], on=\"Primary Artist\", how=\"left\", suffixes=(\"\", \"_ten\"))\n",
    "\n",
    "    # If ten_genres has a match, use it; otherwise, keep the original\n",
    "    df[\"Genres\"] = df[\"Genres_ten\"].combine_first(df[\"Genres\"])\n",
    "\n",
    "    # Apply the cleaning function to clean up genre data\n",
    "    df[\"Genres\"] = df[\"Genres\"].apply(clean_genres)\n",
    "\n",
    "    # Drop the extra columns\n",
    "    df.drop(columns=[\"Genres_ten\", \"Primary Artist\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8f067-0f96-4c4c-8d63-7296b631a751",
   "metadata": {},
   "source": [
    "### Save a Copy of the Missing Genre Artists (Just in Case I Want to Fuss With It Later!) üïµÔ∏è‚Äç‚ôÇÔ∏èüé∂\n",
    "Even with Last.fm‚Äôs extensive data, some artists still slip through the cracks. To handle these edge cases, I‚Äôm saving a list of artists with missing genre data to a separate file. This way, I can manually review and assign genres later if needed. Think of it as a backup plan for those hard-to-categorize artists! üéß‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada40922-e667-48b7-aa4f-a87e06a9112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ten_genres.csv file\n",
    "ten_genres = pd.read_csv(\"data/ten_genres.csv\")\n",
    "\n",
    "# Extract the primary artist from both datasets\n",
    "# For artists with collaborators, we focus on the first name listed üé§\n",
    "df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0].str.strip()\n",
    "ten_genres[\"Primary Artist\"] = ten_genres[\"Artist\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "# Identify missing artists\n",
    "# These are the artists not found in the ten_genres.csv file üé∏\n",
    "missing_artists = df[~df[\"Primary Artist\"].isin(ten_genres[\"Primary Artist\"])]\n",
    "\n",
    "# Save the missing artists to a CSV file\n",
    "# This allows for manual review and genre assignment later üïµÔ∏è‚Äç‚ôÇÔ∏è\n",
    "missing_artists[[\"Primary Artist\"]].drop_duplicates().to_csv(\"data/missing_artists.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(missing_artists)} missing artists to 'data/missing_artists.csv'.\")\n",
    "\n",
    "# The missing artists are now stored in data/missing_artists.csv.\n",
    "# If needed, I can manually assign genres and add them to\n",
    "# obscure_artists_mike_likes.csv for future runs. A little manual effort goes a long way! üéõÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64562b7f-ea92-400d-b33d-845770388d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many songs still have missing genre data?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e0e6e-7b06-452d-8999-c96b5fcd8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls in any column except 'liked' because those belong to playlist_origin = df_nmf\n",
    "df = df[df.drop(columns=['liked']).notna().all(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d89341-0210-4136-bd93-66070a896e54",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c803a7f-4ea3-431f-8c62-54b6801f8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4860391-1274-4020-bd0a-8cca3608576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many tracks belong to each 'playlist_origin' in the dataset\n",
    "# This helps us understand the distribution of tracks across different sources üéµ\n",
    "playlist_origin_counts = df['playlist_origin'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Playlist Origin Counts:\")\n",
    "playlist_origin_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec9c04-e135-49c3-a901-c51f9911c7d1",
   "metadata": {},
   "source": [
    "## Finding Top 30 Genres (Temporarily, for new feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac5264-0f36-43e4-ac63-ef46d30cdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Explode the Genres column\n",
    "df_exploded = df.assign(Genres=df['Genres'].str.split(', ')).explode('Genres')\n",
    "\n",
    "# Step 2: Filter out genres that appear fewer than 10 times\n",
    "genre_counts = df_exploded['Genres'].value_counts()\n",
    "frequent_genres = genre_counts[genre_counts >= 40].index  # Genres with at least 10 occurrences\n",
    "\n",
    "# Filter the exploded DataFrame to only include frequent genres\n",
    "df_frequent_genres = df_exploded[df_exploded['Genres'].isin(frequent_genres)]\n",
    "\n",
    "# Step 3: Group by Genre and calculate the mean of the 'liked' column\n",
    "genre_liked_avg = df_frequent_genres.groupby('Genres')['liked'].mean().reset_index()\n",
    "\n",
    "# Step 4: Sort by the average 'liked' score in descending order and get the top 30\n",
    "top_30_genres = genre_liked_avg.sort_values(by='liked', ascending=False).head(30)\n",
    "\n",
    "# Display the top 30 genres\n",
    "print(\"Top 30 Genres by Average Liked Score (Filtered for Frequent Genres):\")\n",
    "print(top_30_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99e430-4c09-4dc2-bb20-445d1ebe6a16",
   "metadata": {},
   "source": [
    "## Feature Engineering / Further Selecting üëå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef584c69-80fb-4a3c-9631-e0e9edcb042a",
   "metadata": {},
   "source": [
    "### 'Record Label Frequency Encoded' üè∑Ô∏è\n",
    "\n",
    "To improve the model‚Äôs ability to generalize, I‚Äôm creating a new feature: **Record Label Frequency Encoded**. This feature represents how frequently each record label appears in the dataset, but with a twist‚Äîwe only consider labels from tracks I‚Äôve liked or marked as favorite albums. This ensures the encoding reflects my preferences and ignores labels from tracks I don‚Äôt care about.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Training Data Preparation**: We filter the combined dataframe (`df`) by `playlist_origin` to get subsets for `df_liked` and `df_fav_albums`. This ensures we‚Äôre working with the most up-to-date data.\n",
    "2. **Frequency Calculation**: We count how often each record label appears in the training data (i.e., liked and favorite albums).\n",
    "3. **Handling Unseen Labels**: For labels not present in the training data (e.g., those in the NMF test set), we use the **mean frequency** of all labels as a fallback. This ensures the model can handle new or rare labels gracefully.\n",
    "4. **Application**: We apply the encoding to both the training and test sets, ensuring consistency across the data.\n",
    "\n",
    "#### Why This Matters:\n",
    "- **Relevance**: By focusing only on labels from tracks I like, the encoding better reflects my preferences.\n",
    "- **Robustness**: Using the mean frequency for unseen labels ensures new artists from rare labels won't be penalized.\n",
    "- **Simplicity**: Frequency encoding avoids the complexity of one-hot encoding while still capturing meaningful information.\n",
    "\n",
    "This approach ensures the model learns from the distribution of labels I care about while remaining robust to new or rare labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6075b5b-3b34-4b10-b304-ef671e86f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'Record Label Frequency Encoded' üè∑Ô∏è\n",
    "\n",
    "# Filter the combined dataframe by playlist_origin to get the training subset\n",
    "# We focus on liked and favorite albums for training, ignoring disliked tracks and NMF üö´\n",
    "df_train_only = df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]\n",
    "\n",
    "# Calculate frequency encoding using only liked and favorite albums\n",
    "# This ensures the encoding reflects the distribution of labels I care about üè∑Ô∏è\n",
    "freq_encoding = df_train_only['Record Label'].value_counts()\n",
    "\n",
    "# Get the mean frequency to use for unseen labels\n",
    "# This acts as a fallback for labels not present in the training data üõ†Ô∏è\n",
    "mean_freq = freq_encoding.quantile(0.25)\n",
    "\n",
    "# Apply encoding to the training data\n",
    "df.loc[df['playlist_origin'].isin(['df_liked', 'df_fav_albums']), 'Record Label Frequency Encoded'] = (\n",
    "    df_train_only['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    ")\n",
    "\n",
    "# Apply encoding to the NMF test data separately\n",
    "# This avoids data leakage by using only the training data's frequency encoding üöÄ\n",
    "df_nmf_subset = df[df['playlist_origin'] == 'df_nmf']\n",
    "df_nmf_subset['Record Label Frequency Encoded'] = df_nmf_subset['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    "df.loc[df['playlist_origin'] == 'df_nmf', 'Record Label Frequency Encoded'] = df_nmf_subset['Record Label Frequency Encoded']\n",
    "\n",
    "# Apply encoding to the disliked albums\n",
    "df_not_liked_subset = df[df['playlist_origin'] == 'df_not_liked']\n",
    "df_not_liked_subset['Record Label Frequency Encoded'] = df_not_liked_subset['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    "df.loc[df['playlist_origin'] == 'df_not_liked', 'Record Label Frequency Encoded'] = df_not_liked_subset['Record Label Frequency Encoded']\n",
    "\n",
    "# Apply encoding to the mid albums\n",
    "df_mid_subset = df[df['playlist_origin'] == 'df_mid']\n",
    "df_mid_subset['Record Label Frequency Encoded'] = df_mid_subset['Record Label'].map(freq_encoding).fillna(mean_freq)\n",
    "df.loc[df['playlist_origin'] == 'df_mid', 'Record Label Frequency Encoded'] = df_mid_subset['Record Label Frequency Encoded']\n",
    "\n",
    "\n",
    "# Check the result by displaying 20 Unique Record Labels and Their Encoding!\n",
    "df[['Record Label', 'Record Label Frequency Encoded']].drop_duplicates().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275ff43-c4a4-4a7a-acb7-d5c74a80285e",
   "metadata": {},
   "source": [
    "### Target Encode Genres üéö\n",
    "\n",
    "To capture the relationship between genres and the target variable (liked), I use target encoding. This technique replaces each genre (or combination of genres) with the mean target value for that genre, smoothed to handle rare categories. This gives me a \"fingerprint\" of how much I tend to like songs from each genre, which helps the model make better predictions.\n",
    "\n",
    "#### Key Features:\n",
    "- **Handling Multi-Genre Tracks**: Tracks with multiple genres are split, encoded individually, and then aggregated.\n",
    "- **Smoothing**: I smooth the encoding to prevent overfitting by balancing genre-specific means with the global mean.\n",
    "- **Rare Genres**: Genres that appear fewer than 28 times are grouped into a common \"Rare_Genre\" category.\n",
    "- **Unknown Genres**: Tracks with \"Unknown\" genres are handled separately, using the global mean or a fallback value for NMF rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1f54f-259b-46aa-826e-df7fa3d3596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define explicitly disliked genres with severity weights (1-10 scale, 10 being most disliked)\n",
    "disliked_genres = {\n",
    "    'drone': 9, 'psychedelic': 7, 'improv': 8, 'ambient': 6, 'experimental': 7,\n",
    "    'instrumental': 5, 'classical': 5, 'hardcore': 8, 'downtempo': 6, 'slowcore': 6,\n",
    "    'noise': 9, 'satanic': 10, 'pagan': 8, 'metalcore': 9, 'deathcore': 10, \n",
    "    'death metal': 10, 'metal': 8, 'metallic hardcore': 9, 'beatdown deathcore': 10, \n",
    "    'nydm': 9, 'soundscape': 7, 'alternative metal': 8, 'horror punk': 8, \n",
    "    'sludge metal': 9, 'thrash metal': 9, 'death thrash metal': 10, \n",
    "    'heavy metal': 8, 'black metal': 10, 'doom metal': 9, 'death doom metal': 10,\n",
    "    'techno': 8, 'hard techno': 9, 'tech house': 7, 'minimal techno': 8,\n",
    "    'acid techno': 8, 'industrial techno': 9,  \n",
    "    'psychedelic rock': 7, 'psychedelic pop': 7, 'neo-psychedelic': 7, \n",
    "    'psychedelic folk': 7, 'psychedelia': 7, 'psych': 7, 'psych rock': 7, \n",
    "    'psych pop': 7, 'psychedelic soul': 7, 'acid rock': 7\n",
    "}\n",
    "\n",
    "preferred_genres = {\n",
    "    'alternative r&b': 10, 'chamber pop': 9, 'bedroom pop': 8.5,\n",
    "    'indie folk': 8, 'post punk': 7, 'indie': 6.5, 'jangle pop': 6.3,\n",
    "    'retro soul': 5, 'folk pop': 3.5, 'indie rock': 3.5, 'indie pop': 3.5,\n",
    "    'baroque pop': 3.5, 'americana': 3\n",
    "}\n",
    "\n",
    "def target_encode_multi_genre(df, genre_column, target, smoothing=1, aggregation_method='mean', min_count=28):\n",
    "    # Make a copy of the dataframe to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Target encode a multi-genre column with improved handling of disliked genres\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    \n",
    "    # Check if we have training data\n",
    "    if len(df_train) == 0:\n",
    "        raise ValueError(\"No training data found (df_train is empty)\")\n",
    "    \n",
    "    global_mean = df_train[target].mean()\n",
    "    \n",
    "    # Split genres into lists\n",
    "    df_train['split_genres'] = df_train[genre_column].fillna('Unknown').str.split(', ').apply(\n",
    "        lambda x: [genre.strip() for genre in x if genre not in ['seen live', 'Unknown', '']] \n",
    "        if isinstance(x, list) else ['Unknown']\n",
    "    )\n",
    "    \n",
    "    # Explode genres for encoding calculation\n",
    "    exploded_genres = df_train.explode('split_genres')\n",
    "    \n",
    "    # Calculate genre statistics\n",
    "    label_means = exploded_genres.groupby('split_genres')[target].mean()\n",
    "    label_counts = exploded_genres['split_genres'].value_counts()\n",
    "    rare_genres = label_counts[label_counts < min_count].index.tolist()\n",
    "    \n",
    "    # Apply smoothing\n",
    "    smoothed_values = (label_means * label_counts + global_mean * smoothing) / (label_counts + smoothing)\n",
    "    \n",
    "    # Adjust rare genres\n",
    "    for genre in rare_genres:\n",
    "        if genre in smoothed_values:\n",
    "            smoothed_values[genre] = (smoothed_values[genre] + global_mean * 2) / 3\n",
    "    \n",
    "    genre_encoding_map = smoothed_values.to_dict()\n",
    "    \n",
    "    def encode_genres(genres_str):\n",
    "        if pd.isna(genres_str) or genres_str == 'Unknown':\n",
    "            return global_mean\n",
    "        \n",
    "        genres = str(genres_str).split(', ')\n",
    "        genres = [g.strip() for g in genres if g not in ['seen live', 'Unknown', '']]\n",
    "        \n",
    "        # Handle genres without commas\n",
    "        if len(genres) == 1 and ' ' in genres[0]:\n",
    "            genre_lower = genres[0].lower()\n",
    "            # First check preferred genres\n",
    "            for preferred_term in preferred_genres:\n",
    "                if preferred_term in genre_lower:\n",
    "                    return min(100, global_mean * 1.5)  # Boost preferred genres\n",
    "            # Then check disliked terms\n",
    "            for disliked_term in ['metal', 'satanic', 'gore', 'brutal']:\n",
    "                if disliked_term in genre_lower:\n",
    "                    return 30.0\n",
    "        \n",
    "        if not genres:\n",
    "            return global_mean\n",
    "        \n",
    "        genre_values = []\n",
    "        genre_weights = []\n",
    "        \n",
    "        for genre in genres:\n",
    "            value = genre_encoding_map.get(genre, global_mean)\n",
    "            weight = 1.0\n",
    "            \n",
    "            # Apply blessing for preferred genres\n",
    "            genre_lower = genre.lower()\n",
    "            if genre_lower in preferred_genres:\n",
    "                blessing_factor = 1 + (preferred_genres[genre_lower] / 10.0)\n",
    "                value = min(100, value * blessing_factor)  # Cap at 100\n",
    "                weight = 1.5  # Higher weight for preferred genres\n",
    "            elif genre_lower in disliked_genres:\n",
    "                severity = disliked_genres.get(genre_lower, 6)\n",
    "                penalty_factor = 1.0 - (severity / 10.0)\n",
    "                value = value * penalty_factor\n",
    "                weight = 1.0 + (severity / 10.0)\n",
    "            elif genre in label_means and label_means[genre] < global_mean - 10:\n",
    "                value = value * 0.75\n",
    "                \n",
    "            genre_values.append(value)\n",
    "            genre_weights.append(weight)\n",
    "        \n",
    "        return sum(v * w for v, w in zip(genre_values, genre_weights)) / sum(genre_weights)\n",
    "    \n",
    "    # Apply encoding to ALL rows including NMF\n",
    "    df[genre_column + '_encoded'] = df[genre_column].apply(encode_genres)\n",
    "    return df\n",
    "\n",
    "# Run the improved target encoding function \n",
    "try:\n",
    "    df = target_encode_multi_genre(df, 'Genres', 'liked', smoothing=35, aggregation_method='mean')\n",
    "except Exception as e:\n",
    "    print(f\"Error during encoding: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Check NMF rows encoding stats\n",
    "if df is not None:\n",
    "    nmf_encoding_check = df[df['playlist_origin'] == 'df_nmf'][['Track Name', 'Artist Name(s)', 'Album Name', 'Genres', 'Genres_encoded']]\n",
    "\n",
    "    print(f\"NMF rows total: {len(nmf_encoding_check)}\")\n",
    "    print(f\"NMF rows with genre encoding: {nmf_encoding_check['Genres_encoded'].notna().sum()}\")\n",
    "    print(f\"NMF rows missing genre encoding: {nmf_encoding_check['Genres_encoded'].isna().sum()}\")\n",
    "\n",
    "    if nmf_encoding_check['Genres_encoded'].notna().any():\n",
    "        print(\"\\nEncoding value stats:\")\n",
    "        print(f\"Min: {nmf_encoding_check['Genres_encoded'].min():.2f}\")\n",
    "        print(f\"Max: {nmf_encoding_check['Genres_encoded'].max():.2f}\")\n",
    "        print(f\"Mean: {nmf_encoding_check['Genres_encoded'].mean():.2f}\")\n",
    "        print(f\"Median: {nmf_encoding_check['Genres_encoded'].median():.2f}\")\n",
    "        \n",
    "        diverse_samples = nmf_encoding_check.drop_duplicates(['Artist Name(s)'])[:10]\n",
    "        print(\"\\n10 tracks from different artists:\")\n",
    "        for i, row in diverse_samples.iterrows():\n",
    "            print(f\"{row['Artist Name(s)']} - {row['Track Name']} | Genres: {row['Genres']} | Score: {row['Genres_encoded']:.2f}\")\n",
    "        \n",
    "        print(\"\\nTop 5 highest genre scores:\")\n",
    "        high_scores = nmf_encoding_check.nlargest(5, 'Genres_encoded')\n",
    "        for i, row in high_scores.iterrows():\n",
    "            print(f\"{row['Artist Name(s)']} - {row['Track Name']} | Genres: {row['Genres']} | Score: {row['Genres_encoded']:.2f}\")\n",
    "        \n",
    "        print(\"\\nBottom 5 lowest genre scores:\")\n",
    "        low_scores = nmf_encoding_check.nsmallest(5, 'Genres_encoded')\n",
    "        for i, row in low_scores.iterrows():\n",
    "            print(f\"{row['Artist Name(s)']} - {row['Track Name']} | Genres: {row['Genres']} | Score: {row['Genres_encoded']:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nNo encoded values found in NMF rows.\")\n",
    "\n",
    "    # Save results\n",
    "    df[df['playlist_origin'] == 'df_nmf'][['Track Name', 'Artist Name(s)', 'Album Name', 'Genres', 'Genres_encoded']].to_csv('genre_encoding_results.csv', index=False)\n",
    "    print(\"\\nGenre encoding results saved to 'genre_encoding_results.csv'\")\n",
    "else:\n",
    "    print(\"Dataframe is None - encoding failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df9122-2225-49b9-b63c-3f9f15f433dc",
   "metadata": {},
   "source": [
    "# Finding How Central an Artist is to My Music Taste üéØ\n",
    "\n",
    "To understand how central an artist is to my music taste, we're building a network of artists based on which ones I've liked and which are similar to them. Using **PageRank**, a method that measures the importance of nodes in a network, we calculate each artist's \"centrality\" score. This score reflects how influential an artist is within the network of my liked and similar artists.\n",
    "\n",
    "## Key Points:\n",
    "* **Liked Artists**: Artists from my liked songs and favorite albums.\n",
    "* **Similar Artists**: Artists similar to my liked artists (from `df_liked_similar`).\n",
    "* **No Data Leakage**: The `df_nmf` (New Music Friday) artists are excluded from the network to avoid bias.\n",
    "* **Scaled Scores**: Centrality scores are normalized to a 0-100 range for easier interpretation.\n",
    "\n",
    "This approach ensures that the centrality scores are based solely on my preferences and not influenced by artists I haven't liked or the New Music Friday playlist. Let's dive into the code! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612732d8-7cc2-4527-bcc5-307649e7d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Featured_Artist(s) column\n",
    "def extract_featured_artists(df):\n",
    "    # Create new column by splitting on comma and taking all but first artist\n",
    "    df['Featured_Artist(s)'] = df['Artist Name(s)'].apply(\n",
    "        lambda x: ', '.join(str(x).split(',')[1:]).strip() if ',' in str(x) else ''\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Prepare the data\n",
    "def prepare_featured_artists(df):\n",
    "    # Prepare the 'Featured_Artist(s)' column for analysis.\n",
    "    # Ensures the column exists, handles missing values, and splits into lists. üßπ\n",
    "    # First create the column if it doesn't exist\n",
    "    df = extract_featured_artists(df)\n",
    "    \n",
    "    # Ensure 'Featured_Artist(s)' is a string and handle missing values\n",
    "    df['Featured_Artist(s)'] = df['Featured_Artist(s)'].fillna('').astype(str)\n",
    "    \n",
    "    # Split and clean the 'Featured_Artist(s)' column into lists\n",
    "    df['Featured_Artist(s)'] = df['Featured_Artist(s)'].str.split(',').apply(\n",
    "        lambda x: [artist.strip() for artist in x] if isinstance(x, list) else []\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_graph(df, df_liked_similar, include_nmf=False):\n",
    "    # Build a graph of artists and their connections.\n",
    "    # Only includes liked artists and their similar artists by default. üéØ\n",
    "    # Optionally includes NMF, not-liked, and mid artists (without adding edges). üö´\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for liked artists\n",
    "    liked_artists = set(\n",
    "        df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Artist Name(s)']\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    G.add_nodes_from(liked_artists, type='liked')\n",
    "    \n",
    "    # Add nodes for similar artists (from liked)\n",
    "    similar_artists_liked = set(\n",
    "        df_liked_similar['Similar Artists']\n",
    "        .dropna()\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    G.add_nodes_from(similar_artists_liked, type='similar_liked')\n",
    "    \n",
    "    # Add edges based on similarity (from liked)\n",
    "    for _, row in df_liked_similar.iterrows():\n",
    "        artist = row['Artist']\n",
    "        if isinstance(row['Similar Artists'], str):\n",
    "            similar = row['Similar Artists'].split(', ')\n",
    "            for s in similar:\n",
    "                G.add_edge(artist, s, weight=1.0)\n",
    "    \n",
    "    # Optionally include NMF, not-liked, and mid artists (without adding edges)\n",
    "    if include_nmf:\n",
    "        nmf_artists = set(\n",
    "            df[df['playlist_origin'] == 'df_nmf']['Artist Name(s)']\n",
    "            .str.split(',').explode().str.strip()\n",
    "        )\n",
    "        not_liked_artists = set(\n",
    "            df[df['playlist_origin'] == 'df_not_liked']['Artist Name(s)']\n",
    "            .str.split(',').explode().str.strip()\n",
    "        )\n",
    "        mid_artists = set(\n",
    "            df[df['playlist_origin'] == 'df_mid']['Artist Name(s)']\n",
    "            .str.split(',').explode().str.strip()\n",
    "        )\n",
    "        G.add_nodes_from(nmf_artists, type='nmf')\n",
    "        G.add_nodes_from(not_liked_artists, type='not_liked')\n",
    "        G.add_nodes_from(mid_artists, type='mid')  # Mid artists exist but don‚Äôt interfere with the web\n",
    "    \n",
    "    return G\n",
    "\n",
    "def calculate_centrality_scores(G, df):\n",
    "    # Calculate PageRank centrality for all artists in the graph.\n",
    "    # Maps centrality scores back to the DataFrame for main artists. üìä\n",
    "    centrality_scores = nx.pagerank(G)\n",
    "    \n",
    "    # Map centrality scores back to DataFrame for main artists\n",
    "    df['Artist Centrality'] = (\n",
    "        df['Artist Name(s)']\n",
    "        .str.split(',').str[0].str.strip()\n",
    "        .map(centrality_scores).fillna(0)\n",
    "    )\n",
    "    \n",
    "    return df, centrality_scores\n",
    "\n",
    "# Normalize centrality scores to a 0-100 range\n",
    "def normalize_centrality_scores(df):\n",
    "    if df['Artist Centrality'].max() != 0:\n",
    "        df['Artist Centrality'] = (df['Artist Centrality'] / df['Artist Centrality'].max()) * 100\n",
    "    return df\n",
    "\n",
    "# Run the complete pipeline\n",
    "def run_centrality_analysis(df, df_liked_similar, include_nmf=False):\n",
    "    # Run the complete centrality analysis pipeline:\n",
    "    # 1. Prepare featured artists data.\n",
    "    # 2. Build the graph.\n",
    "    # 3. Calculate centrality scores.\n",
    "    # 4. Normalize scores to 0-100 range. üöÄ\n",
    "    # Prepare the featured artists data (still needed to ensure the column exists)\n",
    "    df = prepare_featured_artists(df)\n",
    "    \n",
    "    # Build the graph and calculate centrality\n",
    "    G = build_graph(df, df_liked_similar, include_nmf=include_nmf)\n",
    "    df, centrality_scores = calculate_centrality_scores(G, df)\n",
    "    df = normalize_centrality_scores(df)\n",
    "    \n",
    "    return df, G, centrality_scores\n",
    "\n",
    "# Execute the analysis for all artists (including NMF, not-liked, and mid)\n",
    "df, G, centrality_scores = run_centrality_analysis(df, df_liked_similar, include_nmf=True)\n",
    "\n",
    "# Extract the primary artist (first artist in 'Artist Name(s)' field)\n",
    "df['Primary Artist'] = df['Artist Name(s)'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Now group by Primary Artist to ensure unique artists are considered\n",
    "df_unique_artists = df.groupby('Primary Artist', as_index=False)['Artist Centrality'].max()\n",
    "\n",
    "# Get the top 30 unique primary artists by their centrality score\n",
    "top_artist_df = df_unique_artists.nlargest(30, 'Artist Centrality')[['Primary Artist', 'Artist Centrality']]\n",
    "\n",
    "# Print the top 30 unique primary artists by centrality\n",
    "print(\"\\nTop 30 Unique Primary Artists by Centrality:\")\n",
    "top_artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da884820-f2ec-4ffb-a44c-2a97953d95f9",
   "metadata": {},
   "source": [
    "### Distribution of Artist Centrality Scores by Playlist Origin üìäüéµ\n",
    "\n",
    "This histogram shows how **Artist Centrality** scores are distributed across different playlists. The centrality score reflects how central an artist is to my music taste, based on their connections to my liked artists and their similar artists.\n",
    "\n",
    "- **Liked Artists (df_liked)**: Artists I‚Äôve explicitly liked on Spotify.\n",
    "- **Favorite Albums (df_fav_albums)**: Albums I‚Äôve enjoyed in recent years.\n",
    "- **Mid Albums (df_mid)**: Albums I felt were just okay. Not gbad, not great either.\n",
    "- **Not Liked Albums (df_not_liked)**: Albums I didn‚Äôt enjoy in recent years.\n",
    "- **New Music Friday (df_nmf)**: The most recent New Music Friday playlist.\n",
    "\n",
    "#### What We‚Äôre Looking For:\n",
    "- **High Centrality Scores**: Artists who are closely connected to my liked artists.\n",
    "- **Low Centrality Scores**: Artists who are less connected to my preferences.\n",
    "- **Patterns by Playlist**: Do certain playlists (e.g., liked vs. not liked) have distinct centrality distributions?\n",
    "\n",
    "This visualization helps us understand how my preferences are reflected in the network of artists and how new or not-liked artists compare to my favorites. üïµÔ∏è‚Äç‚ôÇÔ∏è‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511eaa0-d4bd-4297-a7cc-755148f260c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the distribution of 'Artist Centrality', colored by playlist_origin\n",
    "# This shows how centrality scores vary across different playlists üé®\n",
    "sns.histplot(df, x='Artist Centrality', bins=30, hue='playlist_origin', kde=True, alpha=0.6, palette='viridis')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Artist Centrality Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Artist Centrality Scores by Playlist Origin')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01b8b-b7f0-4693-90af-fd9ddac50d91",
   "metadata": {},
   "source": [
    "### Lucy Dacus is one of my most played artists of all time, let's look at what her Pagerank network looked like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9c243-a5d0-415d-baca-fc681fa5aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Lucy Dacus's centrality score\n",
    "lucy_dacus_centrality = df[df['Artist Name(s)'].str.contains('Lucy Dacus')]['Artist Centrality'].values[0]\n",
    "\n",
    "# Extract Lucy Dacus's connections from the graph\n",
    "lucy_dacus_connections = list(G.edges('Lucy Dacus'))\n",
    "\n",
    "# Print Lucy Dacus's centrality score and connections\n",
    "print(f\"Lucy Dacus's Centrality Score: {lucy_dacus_centrality:.2f}\")\n",
    "print(f\"Lucy Dacus's Connections: {lucy_dacus_connections}\")\n",
    "\n",
    "# Create a subgraph centered around Lucy Dacus\n",
    "lucy_dacus_subgraph = G.subgraph(['Lucy Dacus'] + [artist for edge in lucy_dacus_connections for artist in edge])\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Draw the network\n",
    "pos = nx.spring_layout(lucy_dacus_subgraph, seed=42)  # Layout for consistent positioning\n",
    "nx.draw_networkx_nodes(lucy_dacus_subgraph, pos, node_size=500, node_color='lightblue', alpha=0.9)\n",
    "nx.draw_networkx_edges(lucy_dacus_subgraph, pos, edge_color='gray', alpha=0.6)\n",
    "\n",
    "# Highlight Lucy Dacus\n",
    "nx.draw_networkx_nodes(lucy_dacus_subgraph, pos, nodelist=['Lucy Dacus'], node_size=1000, node_color='purple', alpha=0.9)\n",
    "nx.draw_networkx_labels(lucy_dacus_subgraph, pos, labels={'Lucy Dacus': 'Lucy Dacus'}, font_size=12, font_weight='bold')\n",
    "\n",
    "# Add labels for connected artists\n",
    "nx.draw_networkx_labels(lucy_dacus_subgraph, pos, font_size=10)\n",
    "\n",
    "# Add title and annotations\n",
    "plt.title(\"Lucy Dacus's Position in My Music Taste Network\", fontsize=16)\n",
    "plt.figtext(0.5, 0.05, f\"Centrality Score: {lucy_dacus_centrality:.2f}\", ha='center', fontsize=12, style='italic')\n",
    "\n",
    "# Remove axes\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c20db-4987-4708-b980-ed86d33d8c98",
   "metadata": {},
   "source": [
    "## Two More Features Before Primetime! üé≠\n",
    "\n",
    "**Mood Score**: Combines Valence, Danceability, and Liveness to capture the vibe.\n",
    "\n",
    "**Energy Profile**: Mashes Energy, Loudness, and Tempo to gauge the track‚Äôs intensity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c419738-f1f8-4269-8607-60b5139ddcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features only on non-NMF data\n",
    "non_nmf_df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Create mood_score and energy_profile on non-NMF data\n",
    "non_nmf_df['mood_score'] = non_nmf_df[['Valence', 'Danceability', 'Liveness']].mean(axis=1)\n",
    "non_nmf_df['energy_profile'] = non_nmf_df[['Energy', 'Loudness', 'Tempo']].mean(axis=1)\n",
    "\n",
    "# Merge these features back into the main dataframe\n",
    "df = df.merge(non_nmf_df[['mood_score', 'energy_profile']], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9de14-6eb1-4928-9101-5e416946e977",
   "metadata": {},
   "source": [
    "## A Clean Album ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83abb64b-de0f-4e31-85bb-1d012d1a844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Album ID for better data tracking for New Music Friday albums\n",
    "df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "# ADD THIS DIRECTLY AFTER (same indentation):\n",
    "df['album_id'] = df.apply(\n",
    "    lambda x: f\"{x['Primary Artist'].lower()}_{x['Album Name'].lower()}\".replace(' ', '_'),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b164e-c47e-4a71-8430-0a0c40c78800",
   "metadata": {},
   "source": [
    "## Previwing the features on the menu üìñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0a236-7e93-4a4f-ad96-aa77414f9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in the DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nData Types of Each Column:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e10d2a-a4b1-4fc5-ba15-e0f339c9d738",
   "metadata": {},
   "source": [
    "## Standardize the numeric columns üìè\n",
    "When some numbers have a larger size than others, the model can be biased towards them, so we bring all the numeric columns on a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e2297-9c93-4b11-aa84-a465fcacbe93",
   "metadata": {},
   "source": [
    "### Seperate New Music Friday and Save it for Later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb709d88-3b66-4b3d-bd0f-31c17b361b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mood and energy scores first\n",
    "df['mood_score'] = df[['Valence', 'Danceability', 'Liveness']].mean(axis=1)\n",
    "df['energy_profile'] = df[['Energy', 'Loudness', 'Tempo']].mean(axis=1)\n",
    "\n",
    "# Split and save data\n",
    "df_nmf = df[df['playlist_origin'] == 'df_nmf'].copy()\n",
    "df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Save both versions pre-standardization\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)\n",
    "df_cleaned_pre_standardized = pd.concat([df, df_nmf], ignore_index=True)\n",
    "df_cleaned_pre_standardized.to_csv('data/df_cleaned_pre_standardized.csv', index=False)\n",
    "\n",
    "# Store original values\n",
    "original_centrality = df_nmf['Artist Centrality'].copy()\n",
    "original_mood = df_nmf['mood_score'].copy()\n",
    "original_energy = df_nmf['energy_profile'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0ad30-6b7e-4bab-acdf-d566ec4615a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns to scale\n",
    "numeric_columns = [ \n",
    "    'Genres_encoded', \n",
    "    'Artist Centrality',\n",
    "    'Popularity',\n",
    "    'Record Label Frequency Encoded', \n",
    "    'mood_score', \n",
    "    'energy_profile'\n",
    "]\n",
    "\n",
    "# Initialize the scaler with a 1 to 100 range\n",
    "scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "\n",
    "# Fit the scaler on the training data (df)\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Transform the test data (df_nmf) using the fitted scaler\n",
    "df_nmf[numeric_columns] = scaler.transform(df_nmf[numeric_columns])\n",
    "\n",
    "# Save the scaled df_nmf for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the scaled test data\n",
    "print(\"\\nScaled Test Data (df_nmf):\")\n",
    "df_nmf[numeric_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7fcb4-3d9f-4119-985d-824a1e98eafc",
   "metadata": {},
   "source": [
    "## Tuning and Predicting with Random Forest & XGBoost üåü\n",
    "In this section, we fine-tune our Random Forest and XGBoost models using randomized search for optimal hyperparameters. The goal? To get the best possible performance in predicting song ratings. After tuning the models, we make predictions on the unseen data, combining both models' results to generate a more accurate score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d91d28-f7ea-46c1-9e10-345dfa959649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_models(df, features, test_size=0.2):\n",
    "    # Prepare data\n",
    "    X = df[features]\n",
    "    y = (df['liked'] - df['liked'].mean()) / df['liked'].std()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Model parameters\n",
    "    rf_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 15),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 5)\n",
    "    }\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4)\n",
    "    }\n",
    "    \n",
    "    # Initialize models\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    xgb = XGBRegressor(random_state=42)\n",
    "    \n",
    "    # Perform randomized search\n",
    "    rf_search = RandomizedSearchCV(rf, rf_params, n_iter=20, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "    xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=20, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "    \n",
    "    # Fit models\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Train final models with best parameters\n",
    "    best_rf = RandomForestRegressor(**rf_search.best_params_, random_state=42)\n",
    "    best_xgb = XGBRegressor(**xgb_search.best_params_, random_state=42)\n",
    "    \n",
    "    best_rf.fit(X_train, y_train)\n",
    "    best_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    return best_rf, best_xgb, rf_search.best_params_, xgb_search.best_params_, X_test, y_test\n",
    "\n",
    "def predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, y_mean, y_std):\n",
    "    # Make predictions\n",
    "    rf_pred = best_rf.predict(df_nmf[features]) * y_std + y_mean\n",
    "    xgb_pred = best_xgb.predict(df_nmf[features]) * y_std + y_mean\n",
    "    \n",
    "    # Combine predictions\n",
    "    df_nmf['predicted_score'] = (rf_pred + xgb_pred) / 2\n",
    "    \n",
    "    return df_nmf\n",
    "\n",
    "# Usage\n",
    "features = [\n",
    "    'Genres_encoded', \n",
    "    'Artist Centrality',  \n",
    "    'Record Label Frequency Encoded', \n",
    "    'mood_score', \n",
    "    'Popularity',\n",
    "    'energy_profile'\n",
    "]\n",
    "best_rf, best_xgb, rf_params, xgb_params, X_test, y_test = tune_models(df, features)\n",
    "df_nmf = predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, df['liked'].mean(), df['liked'].std())\n",
    "\n",
    "# Output best parameters and feature importances\n",
    "print(f\"Random Forest best parameters: {rf_params}\")\n",
    "print(f\"XGBoost best parameters: {xgb_params}\")\n",
    "print(f\"Random Forest feature importances: {best_rf.feature_importances_}\")\n",
    "print(f\"XGBoost feature importances: {best_xgb.feature_importances_}\")\n",
    "\n",
    "# Feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({'feature': features, 'importance': best_rf.feature_importances_}).sort_values('importance', ascending=False)\n",
    "print(\"Feature importance (Random Forest):\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b494d-4137-409a-96c8-a4bbcff73a76",
   "metadata": {},
   "source": [
    "# 80/20 Train/Test of The Non NMF Data using RandomForrest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329f0f9-85af-4737-bc6e-5b81559867b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(df, features, rf_params, xgb_params):\n",
    "    # Only use non-NMF data for training\n",
    "    train_df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_df[features]\n",
    "    y = train_df['liked']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize models with the best parameters from tuning\n",
    "    rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
    "    xgb_model = XGBRegressor(**xgb_params, random_state=42)\n",
    "    \n",
    "    # Train models\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Combine predictions (80/20 weight)\n",
    "    final_pred = (0.8 * rf_pred) + (0.2 * xgb_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, final_pred)\n",
    "    r2 = r2_score(y_test, final_pred)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Track Name': train_df.loc[X_test.index, 'Track Name'],\n",
    "        'Artist Name(s)': train_df.loc[X_test.index, 'Artist Name(s)'],\n",
    "        'Actual Score': y_test,\n",
    "        'Predicted Score': final_pred\n",
    "    })\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'RF Importance': rf_model.feature_importances_,\n",
    "        'XGB Importance': xgb_model.feature_importances_\n",
    "    })\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R¬≤ Score: {r2:.2f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 Predictions vs Actual:\")\n",
    "    print(results_df.sort_values('Predicted Score', ascending=False).head(10))\n",
    "    \n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importances.sort_values('RF Importance', ascending=False))\n",
    "    \n",
    "    return rf_model, xgb_model, results_df, importances\n",
    "\n",
    "# Usage\n",
    "features = ['Genres_encoded', 'Artist Centrality', 'Record Label Frequency Encoded', 'mood_score', 'Popularity', 'energy_profile']\n",
    "rf_model, xgb_model, results, importances = train_test_model(df, features, rf_params, xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7455-4090-48fb-92bd-1fe791ed3f65",
   "metadata": {},
   "source": [
    "## Run the New Music Friday Regression Model\n",
    "\n",
    "We're using non-NMF data to train Random Forest and XGBoost models to predict how much users will like different tracks. Our improved model includes two key enhancements:\n",
    "\n",
    "1. **Artist Similarity Boost**: We reward New Music Friday artists that are similar to your liked artists, helping you discover new music that aligns with your established preferences.\n",
    "\n",
    "2. **Adaptive Ensemble Weighting**: Instead of a fixed 50/50 blend between models, we dynamically adjust weights based on which model performs better for different types of music.\n",
    "\n",
    "After training, we make predictions for new tracks and calculate confidence intervals to gauge prediction reliability. We then aggregate results by album, factoring in consistency and track count, and sort by weighted score to create a personalized list of top album recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3948a-af2a-497b-9b0e-5f68579ced00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adaptive_weights(X_train, y_train, X_pred, rf_model, xgb_model, features, n_bins=5):\n",
    "    # Make predictions on training data\n",
    "    rf_train_pred = rf_model.predict(X_train)\n",
    "    xgb_train_pred = xgb_model.predict(X_train)\n",
    "    \n",
    "    # Calculate errors\n",
    "    rf_errors = np.abs(rf_train_pred - y_train)\n",
    "    xgb_errors = np.abs(xgb_train_pred - y_train)\n",
    "    \n",
    "    # Create a dataframe with features, predictions, and errors\n",
    "    error_df = X_train.copy()\n",
    "    error_df['rf_error'] = rf_errors\n",
    "    error_df['xgb_error'] = xgb_errors\n",
    "    \n",
    "    # Get top 2 features by importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance['feature'].head(2).tolist()\n",
    "    \n",
    "    # Create bins for each top feature\n",
    "    for feature in top_features:\n",
    "        error_df[f'{feature}_bin'] = pd.qcut(error_df[feature], n_bins, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Calculate performance by bin\n",
    "    performance_by_bin = {}\n",
    "    for feature in top_features:\n",
    "        performance_by_bin[feature] = {}\n",
    "        for bin_idx in range(n_bins):\n",
    "            bin_data = error_df[error_df[f'{feature}_bin'] == bin_idx]\n",
    "            if len(bin_data) > 0:\n",
    "                rf_mean_error = bin_data['rf_error'].mean()\n",
    "                xgb_mean_error = bin_data['xgb_error'].mean()\n",
    "                total_error = rf_mean_error + xgb_mean_error\n",
    "                \n",
    "                if total_error > 0:\n",
    "                    # Weight inversely proportional to error (higher weight = better model)\n",
    "                    rf_weight = xgb_mean_error / total_error\n",
    "                else:\n",
    "                    rf_weight = 0.5\n",
    "                \n",
    "                performance_by_bin[feature][bin_idx] = rf_weight\n",
    "    \n",
    "    # Calculate weights for prediction data\n",
    "    weights = np.ones(len(X_pred)) * 0.5  # Default 50/50 weight\n",
    "    \n",
    "    for feature in top_features:\n",
    "        # Create bins for prediction data\n",
    "        try:\n",
    "            pred_bins = pd.qcut(X_pred[feature], n_bins, labels=False, duplicates='drop')\n",
    "            \n",
    "            # Apply weights based on bin performance\n",
    "            for bin_idx in range(n_bins):\n",
    "                if bin_idx in performance_by_bin[feature]:\n",
    "                    bin_mask = (pred_bins == bin_idx)\n",
    "                    if any(bin_mask):\n",
    "                        rf_weight = performance_by_bin[feature][bin_idx]\n",
    "                        # Scale weight to 0.3-0.7 range to avoid extreme values\n",
    "                        scaled_weight = 0.3 + (rf_weight * 0.4)\n",
    "                        weights[bin_mask] = scaled_weight\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not calculate bins for {feature}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def calculate_artist_similarity_boost(df_nmf, df_liked_similar, liked_artists_df, boost_factor=15):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_nmf_copy = df_nmf.copy()\n",
    "    \n",
    "    # Extract primary artists from NMF\n",
    "    df_nmf_copy['Primary Artist'] = df_nmf_copy['Artist Name(s)'].str.split(',').str[0].str.strip()\n",
    "    \n",
    "    # Extract primary artists from liked songs and albums\n",
    "    liked_artists = set(liked_artists_df['Artist Name(s)'].str.split(',').str[0].str.strip())\n",
    "    \n",
    "    # Create a dictionary of similar artists from df_liked_similar\n",
    "    similar_artists_dict = {}\n",
    "    for _, row in df_liked_similar.iterrows():\n",
    "        if pd.notna(row['Similar Artists']):\n",
    "            artist = row['Artist']\n",
    "            similar = [s.strip() for s in row['Similar Artists'].split(',')]\n",
    "            similar_artists_dict[artist] = similar\n",
    "    \n",
    "    # Flatten the similar artists dictionary to create a mapping from similar artist to liked artist\n",
    "    similar_to_liked_mapping = {}\n",
    "    for liked_artist, similar_list in similar_artists_dict.items():\n",
    "        for similar_artist in similar_list:\n",
    "            if similar_artist not in similar_to_liked_mapping:\n",
    "                similar_to_liked_mapping[similar_artist] = []\n",
    "            similar_to_liked_mapping[similar_artist].append(liked_artist)\n",
    "    \n",
    "    # Function to find the best match for an artist using fuzzy matching\n",
    "    def find_best_match(artist, artist_set, threshold=85):\n",
    "        if artist in artist_set:\n",
    "            return artist, 100\n",
    "        \n",
    "        matches = process.extractOne(artist, artist_set)\n",
    "        if matches and matches[1] >= threshold:\n",
    "            return matches[0], matches[1]\n",
    "        return None, 0\n",
    "    \n",
    "    # Add similarity boost columns directly to the dataframe\n",
    "    df_nmf_copy['similarity_boost'] = 0\n",
    "    df_nmf_copy['match_type'] = 'no_match'\n",
    "    df_nmf_copy['matched_to'] = 'None'\n",
    "    \n",
    "    # Calculate similarity boost for each NMF artist\n",
    "    for i, row in df_nmf_copy.iterrows():\n",
    "        artist = row['Primary Artist']\n",
    "        \n",
    "        # Check if the artist is directly in liked artists\n",
    "        if artist in liked_artists:\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'direct_match'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = artist\n",
    "            continue\n",
    "        \n",
    "        # Check if the artist is in similar_to_liked_mapping\n",
    "        if artist in similar_to_liked_mapping:\n",
    "            liked_connections = similar_to_liked_mapping[artist]\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor * 0.8\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'similar_to_liked'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = ', '.join(liked_connections[:3])  # Show up to 3 connections\n",
    "            continue\n",
    "        \n",
    "        # Try fuzzy matching with similar artists\n",
    "        best_match, match_score = find_best_match(artist, set(similar_to_liked_mapping.keys()))\n",
    "        if best_match:\n",
    "            liked_connections = similar_to_liked_mapping[best_match]\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor * 0.6 * (match_score / 100)\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'fuzzy_similar_match'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = f\"{best_match} ({match_score}%) -> {', '.join(liked_connections[:2])}\"\n",
    "            continue\n",
    "        \n",
    "        # Try fuzzy matching with liked artists\n",
    "        best_match, match_score = find_best_match(artist, liked_artists)\n",
    "        if best_match:\n",
    "            df_nmf_copy.at[i, 'similarity_boost'] = boost_factor * 0.7 * (match_score / 100)\n",
    "            df_nmf_copy.at[i, 'match_type'] = 'fuzzy_direct_match'\n",
    "            df_nmf_copy.at[i, 'matched_to'] = f\"{best_match} ({match_score}%)\"\n",
    "            continue\n",
    "    \n",
    "    return df_nmf_copy\n",
    "\n",
    "def get_prediction_interval(X, model, y_std, y_mean, percentile=95):\n",
    "    \"\"\"Calculate prediction intervals from Random Forest\"\"\"\n",
    "    predictions = []\n",
    "    for estimator in model.estimators_:\n",
    "        predictions.append(estimator.predict(X) * y_std + y_mean)\n",
    "    predictions = np.array(predictions)\n",
    "    lower = np.percentile(predictions, (100-percentile)/2, axis=0)\n",
    "    upper = np.percentile(predictions, 100-(100-percentile)/2, axis=0)\n",
    "    return lower, upper\n",
    "\n",
    "def apply_confidence_scaling(predictions, model, X, y_std, y_mean, min_confidence=40):\n",
    "    \"\"\"Apply confidence-based scaling to predictions\"\"\"\n",
    "    # Get prediction intervals\n",
    "    lower, upper = get_prediction_interval(X, model, y_std, y_mean)\n",
    "    uncertainty = upper - lower\n",
    "    confidence = (1 - uncertainty/uncertainty.max()) * 100\n",
    "    \n",
    "    # Scale predictions based on confidence\n",
    "    scaled_predictions = predictions.copy()\n",
    "    \n",
    "    # High confidence: minimal adjustment (90-100% of original)\n",
    "    high_conf = confidence >= min_confidence\n",
    "    scaled_predictions[high_conf] = predictions[high_conf] * (0.9 + 0.1*(confidence[high_conf]/100))\n",
    "    \n",
    "    # Low confidence: aggressive scaling (60-90% of original)\n",
    "    low_conf = confidence < min_confidence\n",
    "    scaled_predictions[low_conf] = predictions[low_conf] * (0.6 + 0.3*(confidence[low_conf]/min_confidence))\n",
    "    \n",
    "    return np.clip(scaled_predictions, None, 100), confidence\n",
    "\n",
    "# Load the similar artists data\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')\n",
    "\n",
    "# Filter liked and favorite albums for similarity boost\n",
    "liked_artists_df = df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]\n",
    "\n",
    "# Create known artists set\n",
    "known_artists = set(df_liked_similar['Artist'])\n",
    "\n",
    "# Features used for prediction\n",
    "features = [\n",
    "    'Genres_encoded', \n",
    "    'Artist Centrality',  \n",
    "    'Record Label Frequency Encoded', \n",
    "    'mood_score', \n",
    "    'Popularity',\n",
    "    'energy_profile'\n",
    "]\n",
    "\n",
    "# Normalize the target variable\n",
    "y_mean = df['liked'].mean()\n",
    "y_std = df['liked'].std()\n",
    "y_normalized = (df['liked'] - y_mean) / y_std\n",
    "\n",
    "# Prepare training data\n",
    "X = df[features]\n",
    "y = y_normalized  # Use normalized target\n",
    "\n",
    "# Initialize models with the best parameters from tuning\n",
    "rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
    "xgb_model = XGBRegressor(**xgb_params, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf_model.fit(X, y)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Get feature importance from both models\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_rf': rf_model.feature_importances_\n",
    "}).sort_values('importance_rf', ascending=False)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_xgb': xgb_model.feature_importances_\n",
    "}).sort_values('importance_xgb', ascending=False)\n",
    "\n",
    "# Combine importance scores\n",
    "feature_importance = pd.merge(rf_importance, xgb_importance, on='feature')\n",
    "feature_importance['avg_importance'] = (feature_importance['importance_rf'] + feature_importance['importance_xgb']) / 2\n",
    "feature_importance = feature_importance.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "# Prepare NMF data for prediction\n",
    "df_nmf_cleaned = df_nmf[features]\n",
    "\n",
    "# Calculate similarity boost for NMF artists\n",
    "df_nmf = calculate_artist_similarity_boost(df_nmf, df_liked_similar, liked_artists_df)\n",
    "\n",
    "# Make predictions and denormalize\n",
    "rf_predictions = rf_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "xgb_predictions = xgb_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "\n",
    "# Calculate adaptive weights for ensemble\n",
    "adaptive_weights = calculate_adaptive_weights(X, y_normalized, df_nmf_cleaned, rf_model, xgb_model, features)\n",
    "\n",
    "# Get raw ensemble predictions\n",
    "raw_predictions = (adaptive_weights * rf_predictions + \n",
    "                  (1 - adaptive_weights) * xgb_predictions)\n",
    "\n",
    "# Apply similarity boost\n",
    "boosted_predictions = raw_predictions + df_nmf['similarity_boost']\n",
    "\n",
    "# Apply confidence scaling\n",
    "final_predictions, confidence_scores = apply_confidence_scaling(\n",
    "    boosted_predictions, \n",
    "    rf_model, \n",
    "    df_nmf_cleaned, \n",
    "    y_std, \n",
    "    y_mean,\n",
    "    min_confidence=40\n",
    ")\n",
    "\n",
    "# Store results\n",
    "df_nmf['predicted_score'] = final_predictions\n",
    "df_nmf['prediction_confidence'] = confidence_scores\n",
    "df_nmf['is_unknown_artist'] = ~df_nmf['Artist Name(s)'].isin(known_artists)\n",
    "\n",
    "# Calculate prediction intervals\n",
    "lower_bound, upper_bound = get_prediction_interval(df_nmf_cleaned, rf_model, y_std, y_mean)\n",
    "df_nmf['prediction_lower'] = lower_bound\n",
    "df_nmf['prediction_upper'] = upper_bound\n",
    "df_nmf['prediction_uncertainty'] = upper_bound - lower_bound\n",
    "\n",
    "# Get the most common release date from NMF dataset\n",
    "nmf_release_date = df_nmf['Release Date'].mode().iloc[0]\n",
    "\n",
    "# Function to find common artists across all tracks in an album\n",
    "def get_common_artists(artist_series):\n",
    "    \"\"\"Find artists common to all tracks in an album\"\"\"\n",
    "    # Handle NaN/None values\n",
    "    artist_series = artist_series.dropna()\n",
    "    if len(artist_series) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Split each string into a set of artists\n",
    "    artist_lists = []\n",
    "    for artists in artist_series:\n",
    "        try:\n",
    "            artist_lists.append(set(a.strip() for a in artists.split(',')))\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    if not artist_lists:\n",
    "        return \"\"\n",
    "    \n",
    "    # Find intersection of all artist sets\n",
    "    common_artists = set.intersection(*artist_lists)\n",
    "    \n",
    "    # If no common artists, use most frequent artist\n",
    "    if not common_artists:\n",
    "        all_artists = [a for artist_set in artist_lists for a in artist_set]\n",
    "        artist_counts = Counter(all_artists)\n",
    "        \n",
    "        # Get artists that appear in all tracks\n",
    "        most_common = [a for a, cnt in artist_counts.items() \n",
    "                      if cnt == len(artist_series)]\n",
    "        \n",
    "        if most_common:\n",
    "            common_artists = set(most_common)\n",
    "        else:\n",
    "            # Fall back to single most common artist\n",
    "            common_artists = {artist_counts.most_common(1)[0][0]}\n",
    "    \n",
    "    return ', '.join(sorted(common_artists))\n",
    "    return \"\"\n",
    "\n",
    "# Group by album and aggregate data\n",
    "album_predictions = df_nmf.groupby('Album Name').agg({\n",
    "    'Artist Name(s)': get_common_artists,\n",
    "    'predicted_score': ['mean', 'std', 'count'],\n",
    "    'prediction_uncertainty': 'mean',\n",
    "    'Genres': lambda x: ' | '.join(list(set(x))[:3]),\n",
    "    'Record Label': 'first',\n",
    "    'Artist Centrality': 'first', \n",
    "    'mood_score': 'first',         \n",
    "    'energy_profile': 'first',\n",
    "    'Genres_encoded': 'first',\n",
    "    'Record Label Frequency Encoded': 'first',\n",
    "    'prediction_confidence': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "album_predictions.columns = [\n",
    "    'Album Name', 'Artist', 'avg_score', 'score_std', 'track_count',\n",
    "    'avg_uncertainty', 'Genres', 'Label', 'Artist_Centrality', \n",
    "    'Mood_Score', 'Energy_Profile', 'Genres_encoded', \n",
    "    'Record_Label_Frequency_Encoded', 'confidence_score'\n",
    "]\n",
    "\n",
    "# Calculate final confidence score\n",
    "max_std = album_predictions['score_std'].max()\n",
    "max_uncertainty = album_predictions['avg_uncertainty'].max()\n",
    "\n",
    "album_predictions['confidence_score'] = (\n",
    "    (1 - album_predictions['score_std'] / max_std) * \n",
    "    (1 - album_predictions['avg_uncertainty'] / max_uncertainty) * \n",
    "    (1 - 1/(1 + album_predictions['track_count']))\n",
    ") * 100\n",
    "\n",
    "album_predictions['confidence_score'] = np.clip(album_predictions['confidence_score'], 1, 100)\n",
    "\n",
    "# Filter and sort albums\n",
    "album_recommendations = album_predictions[album_predictions['track_count'] >= 5].sort_values('avg_score', ascending=False)\n",
    "\n",
    "# Output results\n",
    "output_columns = [\n",
    "    'Artist', 'Album Name', 'avg_score', 'confidence_score',\n",
    "    'track_count', 'Genres', 'Label', 'Artist_Centrality', \n",
    "    'Mood_Score', 'Energy_Profile'\n",
    "]\n",
    "\n",
    "final_recommendations = album_recommendations[output_columns].copy()\n",
    "final_recommendations['Artist_Centrality'] = final_recommendations['Artist_Centrality'].clip(1, 100)\n",
    "final_recommendations['Mood_Score'] = final_recommendations['Mood_Score'].clip(1, 100)\n",
    "final_recommendations['Energy_Profile'] = final_recommendations['Energy_Profile'].clip(1, 100)\n",
    "\n",
    "# Save recommendations\n",
    "date_str = datetime.strptime(nmf_release_date, '%Y-%m-%d').strftime('%m-%d-%y')\n",
    "filename = f\"predictions/{date_str}_Album_Recommendations.csv\"\n",
    "final_recommendations.round(2).to_csv(filename, index=False)\n",
    "\n",
    "# Evaluation metrics\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    y_true_denormalized = y_true * y_std + y_mean\n",
    "    y_pred_denormalized = y_pred * y_std + y_mean\n",
    "    return -mean_squared_error(y_true_denormalized, y_pred_denormalized)\n",
    "\n",
    "custom_scorer_func = make_scorer(custom_scorer, greater_is_better=False)\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\n=== New Music Friday Recommendations ({nmf_release_date}) ===\")\n",
    "print(f\"Albums with 5+ tracks: {len(album_recommendations)}\")\n",
    "print(\"\\nTop 20 Albums:\")\n",
    "print(album_recommendations[['Artist', 'Album Name', 'avg_score', 'track_count']].head(20).round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"Random Forest CV Score: {rf_cv_scores.mean():.3f} (+/- {rf_cv_scores.std() * 2:.3f})\")\n",
    "print(f\"XGBoost CV Score: {xgb_cv_scores.mean():.3f} (+/- {xgb_cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(feature_importance[['feature', 'avg_importance']].round(3).to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['avg_importance'])\n",
    "plt.xlabel('Average Importance')\n",
    "plt.title('Top Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ad19c-d758-4214-b737-8ff44a13791c",
   "metadata": {},
   "source": [
    "# Display the Top Recommended Albums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b983fa-cc7c-40a3-a922-7e6434d2b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where the predictions are saved\n",
    "predictions_folder = \"predictions/\"\n",
    "\n",
    "# Get the latest predictions file\n",
    "files = [f for f in os.listdir(predictions_folder) if f.endswith(\"_Album_Recommendations.csv\")]\n",
    "\n",
    "if files:\n",
    "    thisweek = max(files, key=lambda f: os.path.getmtime(os.path.join(predictions_folder, f)))\n",
    "    print(f\"Loaded latest file: {thisweek}\")  # Optional, just for confirmation\n",
    "    model_output_df = pd.read_csv(os.path.join(predictions_folder, thisweek))\n",
    "    model_output_df = model_output_df.sort_values(by=\"avg_score\", ascending=False)\n",
    "\n",
    "    # Display all rows\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    model_output_df\n",
    "else:\n",
    "    thisweek = None\n",
    "    None  # Ensures no unwanted output\n",
    "\n",
    "thisweek  # Stores the filename for reference\n",
    "model_output_df  #Show the Recommendations Dataframe for This Past Week!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574853d5-e2d1-4056-9078-06dd1c8cc947",
   "metadata": {},
   "source": [
    "## Grab Album Art for the NMF Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a20ad-63e1-4b72-aa0c-da53b59ee761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Last.fm API key\n",
    "LASTFM_API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "\n",
    "# Function to get similar artists using Last.fm API\n",
    "def get_similar_artists(artist: str, api_key: str, limit: int = 5) -> dict:\n",
    "    base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "    params = {\n",
    "        'method': 'artist.getsimilar',\n",
    "        'artist': artist,\n",
    "        'api_key': api_key,\n",
    "        'limit': limit,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "            similar_artists = [artist['name'] for artist in data['similarartists']['artist']]\n",
    "            return {'Artist': artist, 'Similar Artists': \", \".join(similar_artists[:limit]), 'status': 'success'}\n",
    "    except Exception as e:\n",
    "        return {'Artist': artist, 'Similar Artists': None, 'status': f'error: {str(e)}'}\n",
    "    \n",
    "    return {'Artist': artist, 'Similar Artists': None, 'status': 'no_results'}\n",
    "\n",
    "# Function to get album art using Apple Music API\n",
    "def get_album_art(artist: str, album: str) -> dict:\n",
    "    try:\n",
    "        url = f\"https://itunes.apple.com/search?term={artist} {album}&entity=album\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'results' in data and len(data['results']) > 0:\n",
    "            album_art = data['results'][0].get('artworkUrl100', '').replace(\"100x100\", \"600x600\")\n",
    "            return {'Artist': artist, 'Album Name': album, 'Album Art': album_art, 'status': 'success'}\n",
    "    except Exception as e:\n",
    "        return {'Artist': artist, 'Album Name': album, 'Album Art': None, 'status': f'error: {str(e)}'}\n",
    "    \n",
    "    return {'Artist': artist, 'Album Name': album, 'Album Art': None, 'status': 'no_results'}\n",
    "\n",
    "# Main function to update album data\n",
    "def update_album_data(input_file: str, album_art_file: str, similar_artists_file: str, api_key: str) -> None:\n",
    "    print(f\"\\nStarting data fetch at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    df_input = pd.read_csv(input_file)\n",
    "    album_pairs = df_input[['Primary Artist', 'Album Name']].drop_duplicates()\n",
    "    recommended_artists = df_input[df_input['playlist_origin'] == 'df_nmf']['Primary Artist'].unique()\n",
    "    \n",
    "    try:\n",
    "        existing_album_art = pd.read_csv(album_art_file)\n",
    "    except FileNotFoundError:\n",
    "        existing_album_art = pd.DataFrame(columns=['Artist', 'Album Name', 'Album Art'])\n",
    "    \n",
    "    album_pairs = album_pairs.merge(\n",
    "        existing_album_art,\n",
    "        left_on=['Primary Artist', 'Album Name'],\n",
    "        right_on=['Artist', 'Album Name'],\n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    album_pairs = album_pairs[album_pairs['_merge'] == 'left_only'].drop(columns=['_merge', 'Album Art'])\n",
    "    \n",
    "    df_album_art = pd.DataFrame(columns=['Artist', 'Album Name', 'Album Art'])\n",
    "    df_similar = pd.DataFrame(columns=['Artist', 'Similar Artists'])\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_album = {\n",
    "            executor.submit(get_album_art, row['Primary Artist'], row['Album Name']): (row['Primary Artist'], row['Album Name'])\n",
    "            for _, row in album_pairs.iterrows()\n",
    "        }\n",
    "        for future in as_completed(future_to_album):\n",
    "            result = future.result()\n",
    "            if result['status'] == 'success' and result['Album Art']:\n",
    "                df_album_art = pd.concat([df_album_art, pd.DataFrame([result])], ignore_index=True)\n",
    "            sleep(0.25)\n",
    "    \n",
    "    updated_album_art = pd.concat([existing_album_art, df_album_art], ignore_index=True)\n",
    "    updated_album_art.to_csv(album_art_file, index=False)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(get_similar_artists, artist, api_key): artist\n",
    "            for artist in recommended_artists\n",
    "        }\n",
    "        for future in as_completed(future_to_artist):\n",
    "            result = future.result()\n",
    "            if result['status'] == 'success' and result['Similar Artists']:\n",
    "                df_similar = pd.concat([df_similar, pd.DataFrame([result])], ignore_index=True)\n",
    "            sleep(0.25)\n",
    "    \n",
    "    df_similar.to_csv(similar_artists_file, index=False)\n",
    "    print(f\"\\nFinished at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data/df_nmf_later.csv\"  \n",
    "    album_art_file = \"data/nmf_album_covers.csv\"  \n",
    "    similar_artists_file = \"data/nmf_similar_artists.csv\"  \n",
    "    update_album_data(input_file, album_art_file, similar_artists_file, LASTFM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025f562-96cb-4e59-a32d-6338f3a7da96",
   "metadata": {},
   "source": [
    "## Grab the Spotify Link for each New Music Friday Album üîó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126d6b2-d2bb-4c08-bc71-a12a69115c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spotify_links(batch_size=None, overwrite=False):\n",
    "    \n",
    "    output_file = 'data/nmf_album_links.csv'\n",
    "    \n",
    "    # Check if the output file already exists\n",
    "    if os.path.exists(output_file) and not overwrite:\n",
    "        print(f\"Output file {output_file} already exists.\")\n",
    "        print(\"Loading existing links file instead of regenerating...\")\n",
    "        try:\n",
    "            existing_links = pd.read_csv(output_file)\n",
    "            print(f\"Loaded {len(existing_links)} existing album links.\")\n",
    "            return existing_links\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing file: {e}\")\n",
    "            print(\"Continuing with link generation...\")\n",
    "    \n",
    "    print(\"Starting Spotify link generation...\")\n",
    "    \n",
    "    # Initialize Spotify client with your credentials\n",
    "    client_id = \"71faef9605da4db495b691d96a0daa4b\"\n",
    "    client_secret = \"832e40da22e049bba93f29d9dbeb2e62\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Authenticating with Spotify...\")\n",
    "        sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret\n",
    "        ))\n",
    "        print(\"Spotify authentication successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to authenticate with Spotify: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Read the NMF data\n",
    "    try:\n",
    "        print(\"Reading NMF data...\")\n",
    "        df = pd.read_csv('data/nmf.csv')\n",
    "        print(f\"Loaded {len(df)} tracks\")\n",
    "        \n",
    "        # Print the column names to verify\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading NMF data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Get unique albums\n",
    "        print(\"Extracting unique albums...\")\n",
    "        albums = df.drop_duplicates(subset=['Album Name'], keep='first')\n",
    "        print(f\"Found {len(albums)} unique albums\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting albums: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Function to get album ID from track URI with rate limiting\n",
    "    def get_album_id(track_uri):\n",
    "        if pd.isna(track_uri):\n",
    "            print(\"Warning: Found NaN URI\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Processing track: {track_uri}\")\n",
    "        try:\n",
    "            # Extract just the ID part from the URI (spotify:track:ID_HERE)\n",
    "            if isinstance(track_uri, str) and 'spotify:track:' in track_uri:\n",
    "                track_id = track_uri.split(':')[-1]\n",
    "            else:\n",
    "                track_id = track_uri  # If it's already an ID\n",
    "            \n",
    "            print(f\"Extracted track ID: {track_id}\")\n",
    "                \n",
    "            # Add delay to respect rate limits\n",
    "            time.sleep(0.1)  # 100ms delay between requests\n",
    "            track_info = sp.track(track_id)\n",
    "            album_id = track_info['album']['id']\n",
    "            print(f\"Found album ID: {album_id}\")\n",
    "            return album_id\n",
    "        except spotipy.exceptions.SpotifyException as e:\n",
    "            print(f\"Spotify API error: {e}\")\n",
    "            if hasattr(e, 'http_status') and e.http_status == 429:  # Too Many Requests\n",
    "                print(\"Rate limit hit, waiting longer...\")\n",
    "                time.sleep(5)  # Wait 5 seconds before retrying\n",
    "                try:\n",
    "                    track_info = sp.track(track_id)\n",
    "                    return track_info['album']['id']\n",
    "                except:\n",
    "                    print(f\"Still failed after retry for track {track_id}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Error getting album ID for track {track_id}: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for track URI {track_uri}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Check if we actually have the Track URI column\n",
    "    track_id_column = None\n",
    "    for possible_name in ['Track URI', 'track_uri', 'Track ID', 'track_id']:\n",
    "        if possible_name in albums.columns:\n",
    "            track_id_column = possible_name\n",
    "            print(f\"Found track identifier column: {track_id_column}\")\n",
    "            break\n",
    "    \n",
    "    if track_id_column is None:\n",
    "        print(\"ERROR: Could not find a track ID or URI column. Available columns are:\")\n",
    "        print(albums.columns.tolist())\n",
    "        return None\n",
    "    \n",
    "    # Determine which albums to process\n",
    "    if batch_size is not None:\n",
    "        albums_to_process = albums.head(batch_size)\n",
    "        print(f\"Processing a batch of {len(albums_to_process)} out of {len(albums)} total albums...\")\n",
    "    else:\n",
    "        albums_to_process = albums\n",
    "        print(f\"Processing all {len(albums)} albums...\")\n",
    "    \n",
    "    # Instead of using apply, let's process one by one for better error tracking\n",
    "    albums['Album ID'] = None\n",
    "    \n",
    "    for i, (idx, row) in enumerate(albums_to_process.iterrows()):\n",
    "        print(f\"\\nProcessing album {i+1}/{len(albums_to_process)}: {row['Album Name']}\")\n",
    "        album_id = get_album_id(row[track_id_column])\n",
    "        albums.at[idx, 'Album ID'] = album_id\n",
    "    \n",
    "    # Filter out any failed lookups\n",
    "    processed_albums = albums.dropna(subset=['Album ID'])\n",
    "    \n",
    "    processed_albums['Spotify URL'] = 'open.spotify.com/album/' + processed_albums['Album ID'].astype(str)\n",
    "    \n",
    "    # Select and reorder columns for output\n",
    "    output_columns = ['Album Name', 'Artist Name(s)', 'Album ID', 'Spotify URL']\n",
    "    # Make sure all required columns exist\n",
    "    output_columns = [col for col in output_columns if col in processed_albums.columns]\n",
    "    \n",
    "    output_df = processed_albums[output_columns]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated album links for {len(output_df)} albums\")\n",
    "    return output_df\n",
    "\n",
    "# Run the function\n",
    "# Pass overwrite=True to regenerate links even if the file exists\n",
    "result = generate_spotify_links(overwrite=True)  # Force regenerate all links\n",
    "print(\"Function completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73467-5b49-4809-8203-805fbf599238",
   "metadata": {},
   "source": [
    "## Save a HTML copy of this notebook at its newest! üîΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd78cd-cf1f-41fc-9d5e-94bc1e6a70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'graphics/' directory exists\n",
    "os.makedirs('graphics', exist_ok=True)\n",
    "\n",
    "# Load the current notebook with 'utf-8' encoding\n",
    "notebook_filename = 'Music Taste Machine Learning Data Prep.ipynb'\n",
    "with open(notebook_filename, 'r', encoding='utf-8') as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Export the notebook as HTML\n",
    "html_exporter = HTMLExporter()\n",
    "html_data, resources = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Save the HTML to the 'graphics/' folder\n",
    "output_filename = 'graphics/Music_Taste_Machine_Learning_Data_Prep.html'\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_data)\n",
    "\n",
    "print(f\"HTML version saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
