{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d392a2d-8247-40dc-9431-ae29941dc3ea",
   "metadata": {},
   "source": [
    "# Music Taste Prediction Model: New Music Friday Recommender\n",
    "In this model, I use my liked songs playlist, my recently loved and not loved albums, to train my regression model on what kind of music I do and don't like. At the end my test model will be the new music friday albums from the most recent Friday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e436444-4aff-431a-aedc-e7871c247d1e",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160a9a1f-e9f9-4fb7-b0e3-dcc706dba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# API and Network Requests\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from time import sleep\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Type Hints\n",
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9616a76-166e-4707-b84a-0ad594210b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8067f0c-b06b-4426-bad9-69bd28e3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked = pd.read_csv(\"data/liked.csv\")  # Liked playlist on Spotify\n",
    "df_fav_albums = pd.read_csv(\"data/liked_albums.csv\")  # Albums I've Liked in Recent Years\n",
    "df_not_liked = pd.read_csv(\"data/did_not_like.csv\")  # Albums I've not liked in Recent Years\n",
    "df_nmf = pd.read_csv(\"data/nmf.csv\")  # The most recent New Music Friday Playlist\n",
    "df_nmf_similar = pd.read_csv(\"data/nmf_artist_adjacent.csv\")  # Lastfm pull of similar artists to this weeks NMF artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf0bead-7afc-461d-8f1d-3ece0c86debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull Similar Artists to Your Favorite Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae3c1adc-0020-425f-89fa-56dee6f455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing and new data...\n",
      "Loaded 2126 existing artists from database\n",
      "Found 0 new artists to process\n",
      "No new artists to process. Database is up to date!\n",
      "\n",
      "First few rows of the similar artists DataFrame:\n",
      "        Artist                                    Similar Artists\n",
      "0         RY X                                                NaN\n",
      "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...\n",
      "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...\n",
      "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...\n",
      "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25, limit: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        self.limit = limit\n",
    "\n",
    "    def get_similar_artists(self, artist_name: str) -> List[str]:\n",
    "        \"\"\"Fetch similar artists for a given artist from LastFM API.\"\"\"\n",
    "        params = {\n",
    "            'method': 'artist.getSimilar',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'limit': self.limit,  # Add limit parameter\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Handle rate limiting\n",
    "            if 'X-RateLimit-Remaining' in response.headers:\n",
    "                remaining = int(response.headers['X-RateLimit-Remaining'])\n",
    "                if remaining == 0:\n",
    "                    sleep(self.rate_limit_delay)\n",
    "            \n",
    "            data = response.json()\n",
    "            if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "                return [artist['name'] for artist in data['similarartists']['artist'][:self.limit]]\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching similar artists for {artist_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "def extract_primary_artist(artist_string: str) -> str:\n",
    "    \"\"\"Extract the first artist name before any comma.\"\"\"\n",
    "    if pd.isna(artist_string):\n",
    "        return \"\"\n",
    "    return artist_string.split(\",\")[0].strip()\n",
    "\n",
    "def update_similar_artists(liked_path: str, \n",
    "                         albums_path: str, \n",
    "                         output_path: str, \n",
    "                         api_key: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Update the similar artists database with new artists from liked playlists.\n",
    "    Returns the complete DataFrame of artists and their similar artists.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading existing and new data...\")\n",
    "    \n",
    "    # Load existing similar artists data\n",
    "    existing_data: Dict[str, List[str]] = {}\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        existing_data = dict(zip(existing_df['Artist'], existing_df['Similar Artists']))\n",
    "        print(f\"Loaded {len(existing_data)} existing artists from database\")\n",
    "    \n",
    "    # Load and process current playlists\n",
    "    df_liked = pd.read_csv(liked_path)\n",
    "    df_albums = pd.read_csv(albums_path)\n",
    "    \n",
    "    # Extract and combine primary artists\n",
    "    current_artists = set(\n",
    "        pd.concat([\n",
    "            df_liked['Artist Name(s)'].apply(extract_primary_artist),\n",
    "            df_albums['Artist Name(s)'].apply(extract_primary_artist)\n",
    "        ]).unique()\n",
    "    )\n",
    "    current_artists.discard(\"\")  # Remove empty strings\n",
    "    \n",
    "    # Find new artists not in existing data\n",
    "    new_artists = current_artists - set(existing_data.keys())\n",
    "    print(f\"Found {len(new_artists)} new artists to process\")\n",
    "    \n",
    "    if not new_artists:\n",
    "        print(\"No new artists to process. Database is up to date!\")\n",
    "        # Create and return DataFrame even if no updates\n",
    "        return pd.DataFrame({\n",
    "            'Artist': list(existing_data.keys()),\n",
    "            'Similar Artists': list(existing_data.values())\n",
    "        })\n",
    "    \n",
    "    # Initialize LastFM API client\n",
    "    api = LastFMAPI(api_key)\n",
    "    \n",
    "    # Process artists with concurrent requests\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(api.get_similar_artists, artist): artist \n",
    "            for artist in new_artists\n",
    "        }\n",
    "        \n",
    "        # Show progress bar while processing\n",
    "        for future in tqdm(as_completed(future_to_artist), \n",
    "                         total=len(future_to_artist),\n",
    "                         desc=\"Fetching similar artists\"):\n",
    "            artist = future_to_artist[future]\n",
    "            similar_artists = future.result()\n",
    "            results[artist] = ', '.join(similar_artists)\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    combined_data = {**existing_data, **results}\n",
    "    \n",
    "    # Create DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        'Artist': list(combined_data.keys()),\n",
    "        'Similar Artists': list(combined_data.values())\n",
    "    })\n",
    "    \n",
    "    # Save updated data\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    print(f\"Successfully updated database with {len(new_artists)} new artists\")\n",
    "    print(f\"Total artists in database: {len(combined_data)}\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "    LIKED_PATH = \"data/liked.csv\"\n",
    "    ALBUMS_PATH = \"data/liked_albums.csv\"\n",
    "    OUTPUT_PATH = \"data/liked_artists_only_similar.csv\"\n",
    "    \n",
    "    # Run the update and get the DataFrame\n",
    "    df_liked_similar = update_similar_artists(\n",
    "        LIKED_PATH, \n",
    "        ALBUMS_PATH, \n",
    "        OUTPUT_PATH, \n",
    "        API_KEY\n",
    "    )\n",
    "    \n",
    "    # Now df_liked_similar is ready to use\n",
    "    print(\"\\nFirst few rows of the similar artists DataFrame:\")\n",
    "    print(df_liked_similar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b978abe-0086-4608-bbe9-a45c5591a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sampa the Great</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spillage Village</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>serpentwithfeet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Omar Apollo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Urban Jams United</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>Cate Le Bon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>GAYLE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Artist Similar Artists\n",
       "0                  RY X             NaN\n",
       "22      Sampa the Great             NaN\n",
       "30     Spillage Village             NaN\n",
       "45      serpentwithfeet             NaN\n",
       "76          Omar Apollo             NaN\n",
       "...                 ...             ...\n",
       "2041  Urban Jams United             NaN\n",
       "2043              JAY-Z             NaN\n",
       "2045     PinkPantheress             NaN\n",
       "2067        Cate Le Bon             NaN\n",
       "2106              GAYLE             NaN\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03340fb2-3681-4654-8d18-c0f4b2c4397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MBID 3b4cd16e-3a25-4c7b-ada6-33f5ea91e1b1: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 9d79c790-9897-464e-aef0-db5bd3290f00: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 4b1d3ebc-b45a-45ec-a97e-426a20c1c6ab: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID cc9ddb3d-1217-4a40-9864-d85920cfa1ed: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 0b966a38-5ad9-43c1-b86b-c07079523165: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID a148ffde-581c-4c39-a8f1-bc49dec7fe68: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 950c20e2-dbab-4c7d-8784-cee86be11787: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 66c662b6-6e2f-4930-8610-912e24c63ed1: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 85c18775-22bd-4a66-8415-3fe11c026040: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID b3b223a5-61a1-488f-b003-10edbaf632a3: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 2cc2e542-9e15-40fb-b4e7-bf467c778e3f: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 175 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID d616b606-cf6a-4b6e-ab0f-e253b8db6610: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID f2a72370-1dfb-4a39-90ac-c7c52ae93bad: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID cf1021a4-ba16-4563-b4c2-e40aaf1802f6: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ef798cd9-c8ea-4825-8840-271fbd7d23b7: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID a56f9cc3-1569-4205-8514-9c5c545d724d: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID b8cc2c1b-f62e-4a60-a9a6-5ebae2ec040b: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 12f8b9d5-fd3f-4182-8a3f-bbd517c709cf: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 88927646-0c28-4b1b-a69e-cb33c400d650: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 90744b3e-363a-458e-8da1-e3e392a489c4: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 8562cd5d-68d7-462e-9c33-40a0e3e4d082: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 2bdaac0f-acae-434a-b86a-d41239cf76be: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ad322b8b-31b2-437d-8fd8-1af13c1d7b91: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID b25798de-0ca8-4f44-886e-3d00f6e9be6e: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 6b07994f-bccd-4691-a1af-af518de0948c: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 455 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 8dd37f6f-bf89-40f2-8b46-46bb850cb29e: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 569c0d90-28dd-413b-83e4-aaa7c27e667b: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID bce172fc-51bb-43f7-9a25-b406a0a581d5: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID e9243b8e-84ed-4a8f-82d1-ea084a2f0c4a: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ce6fbc1a-7a8b-4596-a8bb-7ef87290d892: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 660 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 80a37f31-402b-4dfe-9181-2e7dd8f40143: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 2e222fce-02ae-4221-b1c6-3c3242b423b6: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 4da158cc-4d03-48d6-aefc-6726e4f9a149: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 0a89981d-65c5-4848-a563-bba10e9bf2c2: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID e78de7e9-c2af-4249-b266-2d4eacd6115d: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 730 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 80609a00-b394-4a49-975b-2db6b543fa97: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 3449ecd8-0bb7-4571-804c-64b91f4d8c8f: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID fac3ff34-6ba4-425a-8f01-b181ef4a908a: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 0568c60f-9852-4708-82ab-1afb8bb1342f: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ad2b62da-3451-48b4-97f5-9670ae10e29a: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 885 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 71e86c92-76cd-461f-b593-50e1909527fc: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 146dbf7a-fffe-4a69-bcad-03b84c88c6fa: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 7d8fb539-811e-4491-a3f7-f56d3ef35e7a: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 970 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID f2832dd6-6977-462b-beed-4082557d04fc: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 763cb144-afdb-471e-bd86-d4f5b9b58641: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 990 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 64598fd8-5d7c-441d-a936-e1fc13d5a4f6: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 5b2a8faa-ffee-4706-a1a8-58f109bc8ca2: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID c8e48299-2214-4be5-84ba-113adc5efb35: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1025 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID be465d4f-c28d-4ba1-94ab-ebaada7db8af: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1030 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID a6c6897a-7415-4f8d-b5a5-3a5e05f3be67: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 317606b4-e0c2-48fe-bcfc-a7e7547d968e: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 4d09a017-4e09-47a7-b274-a7e0767ac4e0: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1125 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 5fb4da03-2dd6-4c28-a217-232ae8a0aed7: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 2bc82618-2d0f-436e-adb2-8aa0774dd799: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 5ed8f4ac-3ae8-4a83-9ff9-565510c7f6e5: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1175 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 4ae429fe-735c-4968-8253-a591421b1bd0: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 0e84b561-5a1b-460d-bd14-35dad2abcc08: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 8893ecf1-1cef-4acb-877b-111a7524e696: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 1395c84b-2e84-4f25-9962-f1c0d5aa31ed: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 92de1f8d-833e-47d0-ba85-02a03c81848a: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1250 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 423a85de-66ba-4113-abdc-ba2678ee89ba: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 20d43d07-00b8-404f-a440-07adf7c257f2: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 7b24231e-faa5-4838-b6a8-6a2eb2727b37: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 7a17b309-7500-49e3-8b66-433e150a7837: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID baa94921-e65a-4461-b5ca-46497b0f11e9: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 7442fbfa-00ad-4e3b-8f45-9d2c62786eed: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1330 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 0520d813-1f26-444e-83e7-1f4d1baab3c8: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1395 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 7ed36954-f027-43df-b353-c7239f4faa27: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 5e1dbdb2-87ac-41ff-9960-4a42a872327a: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID c9dda914-1eb2-4762-8006-208010b89ee3: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1430 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID f6727f2d-9012-412e-9827-50e61a16711d: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1440 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID de22adae-f8ac-414f-b653-b0162611bd60: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 0286c5aa-5124-4efd-b784-ce9efb98895c: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID a71eaf3d-3f69-4255-90be-b310dfa00566: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 383005e1-657d-468b-a448-08ecf35b3943: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 1a81a97c-caf7-4f63-aceb-b10fdf055dfb: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1510 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID b142ddb1-9e43-464f-8097-82dc5f64fef5: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1570 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID cb862d76-90a8-4733-b8f6-69240d60d805: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1575 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 96c5c9a3-6c9b-41a7-90cc-e7375afbfde1: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID bb1d641d-a76e-4c8e-907e-e9de012fe435: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1610 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 893b6621-4877-4671-8a7c-b9971f723837: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID b04df404-eefa-4ae4-9f3e-ba220d9dce16: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 59968a5e-151d-4f92-a4ce-67a889ac17e2: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 83b9cbe7-9857-49e2-ab8e-b57b01038103: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 7f233cda-eacb-4235-b681-5f7be343a1a2: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ab1a3f85-e0ea-470a-af5c-175447ae774c: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1685 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID f6af669a-56ea-448a-a044-de76181ada33: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 8b98035f-fbd2-4fb3-9c2f-263c7506680d: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1710 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 0181a90e-6b1d-4d09-bd6f-b0b1145e7ad8: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1725 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 3ceeddbd-fba5-4bdb-99f7-2d028ed5afda: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ced4f725-1773-4566-92a5-75df7de91411: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 415a5366-c1eb-4cd8-b584-429cbf121317: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 4c41d78d-9dd5-430d-81ea-286052158293: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1775 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 079e9abe-72e4-489d-b726-c2916bc00e40: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID da8b6c67-710c-4480-bf2a-ca2849b42094: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 61af87f4-16ee-4431-8504-cc06187079fb: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1810 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID a410fed0-efb4-41ce-9520-5b8b3e3f1e60: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 06ebbe09-da8e-42dc-92fc-68b4ff2dd256: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1850 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 05ff5cc0-7f2d-45d5-9c6d-6913c7ed6049: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1875 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 26dc8914-2efd-4298-b805-0e2ce55e7d9d: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID c1184bef-262b-4d23-8946-57f2ce92311c: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 8be564c3-dfba-440b-af8c-4ffbceeef45e: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID bca63b5d-a28c-4937-a8f4-e3f2d95426e1: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 9198adad-435d-44db-8634-6eeb30b32692: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1935 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID f1660eaa-929f-48d4-9926-9aaa61afa52f: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 5016b2b7-f44d-4876-bb8d-15d1bac41dd3: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID ee74db56-c264-4c23-9504-29e2d8078f36: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 58b599cd-b1de-45e3-863a-3b54194a0f20: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID cde174be-fe47-44c8-9dc4-968b7ae50a0c: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 1985 artists, pausing for 3 seconds...\n",
      "Error fetching data for MBID 5db6354e-6669-4510-ae61-66fe35340449: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID e9cda0a2-285c-4a15-9697-c295c216a94f: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 2a6426e5-966e-4fec-a8c0-36908abbb866: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID eb444c85-7a90-49ba-bd79-ac82008bab11: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID f82bcf78-5b69-4622-a5ef-73800768d9ac: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID 7441014f-f8f5-494f-81db-ff166fbc078d: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID f2393e49-b791-46da-a6d7-1e9e60743405: Expecting value: line 1 column 1 (char 0)\n",
      "Error fetching data for MBID cefd9d3d-9506-461c-972f-89b4cbade9da: Expecting value: line 1 column 1 (char 0)\n",
      "Updated DataFrame:\n",
      "        Artist                                    Similar Artists\n",
      "0         RY X                                               None\n",
      "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...\n",
      "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...\n",
      "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...\n",
      "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Load the existing CSV file into a DataFrame\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')\n",
    "\n",
    "# Filter out the artists with missing similar artists (where 'Similar Artists' is NaN)\n",
    "df_missing_similar = df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]\n",
    "\n",
    "# Function to fetch similar artists using ListenBrainz\n",
    "def get_similar_artists(artist_mbid):\n",
    "    api_url = f'https://labs.api.listenbrainz.org/similar-artists?artist_mbid={artist_mbid}&algorithm=session_based_days_9000_session_300_contribution_5_threshold_15_limit_50_skip_30'\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            similar_artists = [artist['artist_name'] for artist in data.get('payload', {}).get('artists', [])]\n",
    "            return ', '.join(similar_artists)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for MBID {artist_mbid}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for MBID {artist_mbid}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to get MBID from artist name using MusicBrainz API\n",
    "def get_artist_mbid(artist_name):\n",
    "    api_url = f'https://musicbrainz.org/ws/2/artist?query={artist_name}&limit=1&fmt=json'\n",
    "    try:\n",
    "        response = requests.get(api_url, headers={'User-Agent': 'YourApp/1.0'})\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get('artists'):\n",
    "                return data['artists'][0]['id']  # Return the first matching MBID\n",
    "        else:\n",
    "            print(f\"Failed to fetch MBID for {artist_name}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching MBID for {artist_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# To avoid overwhelming the API, we will process a batch at a time\n",
    "batch_size = 5\n",
    "delay_seconds = 3  # Delay in seconds between requests\n",
    "\n",
    "# Iterate over missing artists in batches\n",
    "updated_rows = []\n",
    "for i, row in df_missing_similar.iterrows():\n",
    "    artist_name = row['Artist']\n",
    "    artist_mbid = get_artist_mbid(artist_name)\n",
    "    \n",
    "    if artist_mbid:\n",
    "        similar_artists = get_similar_artists(artist_mbid)\n",
    "        updated_rows.append((i, similar_artists))\n",
    "    else:\n",
    "        updated_rows.append((i, None))\n",
    "    \n",
    "    # Wait for the specified delay before the next request\n",
    "    if (i + 1) % batch_size == 0:\n",
    "        print(f\"Processed {i + 1} artists, pausing for {delay_seconds} seconds...\")\n",
    "        time.sleep(delay_seconds)\n",
    "\n",
    "# Update the 'Similar Artists' column for the rows that were processed\n",
    "for index, similar_artists in updated_rows:\n",
    "    df_liked_similar.at[index, 'Similar Artists'] = similar_artists\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df_liked_similar.to_csv('data/liked_artists_only_similar.csv', index=False)\n",
    "\n",
    "# After the loop, you can check if all the missing artists have been filled\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df_liked_similar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "709eec5c-1af3-4a45-a785-656ec1d5194e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sampa the Great</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spillage Village</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>serpentwithfeet</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Omar Apollo</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Urban Jams United</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>Cate Le Bon</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>GAYLE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Artist Similar Artists\n",
       "0                  RY X            None\n",
       "22      Sampa the Great            None\n",
       "30     Spillage Village            None\n",
       "45      serpentwithfeet            None\n",
       "76          Omar Apollo            None\n",
       "...                 ...             ...\n",
       "2041  Urban Jams United            None\n",
       "2043              JAY-Z            None\n",
       "2045     PinkPantheress            None\n",
       "2067        Cate Le Bon            None\n",
       "2106              GAYLE            None\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1846ab38-016d-4539-8c37-ad21daf594be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/liked_artists_only.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the CSV with liked artists (make sure the path is correct)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df_liked_similar \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/liked_artists_only.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Target rows where 'Similar Artists' is NaN\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df_target \u001b[38;5;241m=\u001b[39m df_liked_similar[df_liked_similar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilar Artists\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/liked_artists_only.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Load the CSV with liked artists (make sure the path is correct)\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only.csv')\n",
    "\n",
    "# Target rows where 'Similar Artists' is NaN\n",
    "df_target = df_liked_similar[df_liked_similar[\"Similar Artists\"].isna()]\n",
    "\n",
    "# Function to get similar artists using MusicBrainz API\n",
    "def get_similar_artists(artist_name):\n",
    "    # API URL to search for artists\n",
    "    url = f'https://musicbrainz.org/ws/2/artist?query={artist_name}&fmt=json'\n",
    "    \n",
    "    try:\n",
    "        # Request data from MusicBrainz\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if results exist\n",
    "        if data['artists']:\n",
    "            # Get the first artist in the results\n",
    "            artist_data = data['artists'][0]\n",
    "            artist_id = artist_data['id']\n",
    "            \n",
    "            # Get related artists (if any) using artist-rels\n",
    "            related_url = f'https://musicbrainz.org/ws/2/artist/{artist_id}?inc=artist-rels&fmt=json'\n",
    "            related_response = requests.get(related_url)\n",
    "            related_response.raise_for_status()\n",
    "            \n",
    "            related_data = related_response.json()\n",
    "            \n",
    "            # Check if 'artist-rels' exists and has data\n",
    "            if 'artist-rels' in related_data:\n",
    "                related_artists = [rel['artist']['name'] for rel in related_data['artist-rels']]\n",
    "                return related_artists\n",
    "            else:\n",
    "                return []\n",
    "        else:\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error retrieving data for {artist_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Iterate through the target rows and get similar artists\n",
    "for index, row in df_target.iterrows():\n",
    "    artist_name = row['Artist Name']  # Assuming the artist name column is 'Artist Name'\n",
    "    \n",
    "    # Get similar artists\n",
    "    similar_artists = get_similar_artists(artist_name)\n",
    "    \n",
    "    # If similar artists are found, update the 'Similar Artists' column\n",
    "    if similar_artists:\n",
    "        df_liked_similar.at[index, 'Similar Artists'] = ', '.join(similar_artists)\n",
    "    \n",
    "    # Pause between requests to avoid overwhelming the API\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df_liked_similar.to_csv('data/liked_artists_only_similar.csv', index=False)\n",
    "\n",
    "print(\"Updated 'Similar Artists' for target rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392df38d-c607-4196-bf48-ab735338849e",
   "metadata": {},
   "source": [
    "## Quick Glance at our Refreshed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ec508-7fe2-43be-ac08-f08bb640aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b875a-ebab-472e-82b5-85568f036a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liked Albums in Recent Years\n",
    "df_fav_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d6345-80d1-4b33-a4c5-10b1e138bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albums Not Liked in Recent Years\n",
    "df_not_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190ec91-73e0-40c5-95b4-fc212abd1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Music Friday Playlist\n",
    "df_nmf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bfbf76-1649-4542-b001-2fedd527ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar Artists to Recently Played Artists (Last.fm)\n",
    "\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbf40b-4217-4500-aa1e-13a92c8265be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar Artists to NMF Artists (Last.fm)\n",
    "df_nmf_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30386-5197-4245-9871-cffbe4952a33",
   "metadata": {},
   "source": [
    "> A quick reminder of the standard columns of a spotify export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f0c33-76f1-4d7b-95c3-988b1ca941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe763b3-50c4-474d-8363-a5c41461ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked_similar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a101e0-c4a5-4831-b90d-0dcb6385c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmf_similar.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25a6b9-e488-4c3a-9e27-4cf15e57c504",
   "metadata": {},
   "source": [
    "### Add Target Labels for Training Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a802d4-ff06-4dab-886d-059ed0ee2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign liked scores before combining\n",
    "df_liked['liked'] = 100\n",
    "df_fav_albums['liked'] = 50\n",
    "df_not_liked['liked'] = 0\n",
    "df_nmf['liked'] = np.nan \n",
    "\n",
    "# Add playlist_origin column before combining\n",
    "df_liked['playlist_origin'] = 'df_liked'\n",
    "df_fav_albums['playlist_origin'] = 'df_fav_albums'\n",
    "df_not_liked['playlist_origin'] = 'df_not_liked'\n",
    "df_nmf['playlist_origin'] = 'df_nmf'\n",
    "df_liked_similar['source'] = 'liked_similar'\n",
    "df_nmf_similar['source'] = 'nmf_similar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10e0ba-5881-4cd4-91e0-630063a72dd8",
   "metadata": {},
   "source": [
    "### Check application of the target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add9e6b-4a3c-46f0-bc43-4bb4215cd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cb7c2-b08e-4d00-9cd7-fcea6eec1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_albums[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b72fb6-dac5-4d75-b6fd-b3ca1d8973f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75164a9-8182-463f-a450-2534f52aeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmf[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fa4a1-a55a-42c6-b3b1-8994b44c3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked_similar[['Artist', 'Similar Artists', 'source']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c2822-fe11-4842-b97c-53a11412af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmf_similar[['Artist', 'Similar Artists', 'source']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44856ee-a472-41f3-8622-01d76e370849",
   "metadata": {},
   "source": [
    "## Merge The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd66a5-2ed8-4eda-b8df-09a5feaa782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_liked, df_fav_albums, df_not_liked, df_nmf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b1007-6bfe-429b-bf10-5de0241f9e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#How Large is the Dataset, Now?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035bf83-b7da-4fbb-bc26-f1ed816a5798",
   "metadata": {},
   "source": [
    "#### Remove the Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861de4ff-4fb7-421b-8923-419d750172bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates: Keep the highest 'liked' score (100 > 50)\n",
    "df = df.sort_values(by='liked', ascending=False)  # Ensures 100-rated songs come first\n",
    "df = df.drop_duplicates(subset=['Track Name', 'Artist Name(s)'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b202b5-4145-4b67-96fa-d7a9642088be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #Checking to remind myself what is all available to drop, keep seperate as metadata, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2580a-e10a-4d8f-a9fc-258a2777d37f",
   "metadata": {},
   "source": [
    "#### Drop columns that won't help the model (Track ID, Added By, Added At, Time Signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1551b-d6a6-4ff4-b5f3-f333f2e4e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Track ID', 'Added By', 'Added At', 'Time Signature'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658750-d956-442d-99ed-2dca4323ec47",
   "metadata": {},
   "source": [
    "#### Getting missing Genres (of which Spotify is \"Spotty\" at best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b250a-eb92-4eb4-a0a1-c20f0550eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        \n",
    "    def _make_request(self, params: dict) -> dict:\n",
    "        try:\n",
    "            # Handle rate limit by checking headers for remaining requests\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Check for rate limit info in the response headers\n",
    "            remaining = int(response.headers.get('X-RateLimit-Remaining', 1))\n",
    "            if remaining == 0:\n",
    "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
    "                wait_time = reset_time - int(datetime.now().timestamp())\n",
    "                print(f\"Rate limit hit, waiting for {wait_time} seconds...\")\n",
    "                sleep(wait_time + 1)  # wait for the reset time plus 1 second for safety\n",
    "                response = requests.get(self.base_url, params=params)  # retry after waiting\n",
    "                response.raise_for_status()\n",
    "\n",
    "            return response.json()\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed: {e}\")\n",
    "            if response.status_code == 429:\n",
    "                print(\"Rate limit exceeded, increasing delay.\")\n",
    "                self.rate_limit_delay *= 2\n",
    "            return None\n",
    "\n",
    "    def get_artist_tags(self, artist_name: str, limit: int = 5) -> List[str]:\n",
    "        params = {\n",
    "            'method': 'artist.getTopTags',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'format': 'json',\n",
    "            'limit': limit\n",
    "        }\n",
    "        data = self._make_request(params)\n",
    "        if data and 'toptags' in data:\n",
    "            return [tag['name'] for tag in data['toptags'].get('tag', [])]\n",
    "        return []\n",
    "\n",
    "def export_artist_tags(api_key: str, unique_artists: List[str], output_file: str = 'data/missing_genres.csv'):\n",
    "    api = LastFMAPI(api_key)\n",
    "\n",
    "    # Load existing data if the file exists\n",
    "    existing_data = {}\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                existing_data[row['Artist']] = row['Tags']\n",
    "\n",
    "    # Identify new artists not in the existing data\n",
    "    new_artists = [artist for artist in unique_artists if artist not in existing_data]\n",
    "    print(f\"Total new artists with missing genres: {len(new_artists)}\")\n",
    "\n",
    "    if not new_artists:\n",
    "        print(\"No new missing artists to process.\")\n",
    "        return\n",
    "\n",
    "    # Using ThreadPoolExecutor to parallelize API requests\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers based on your needs\n",
    "        future_to_artist = {executor.submit(api.get_artist_tags, artist): artist for artist in new_artists}\n",
    "        \n",
    "        try:\n",
    "            with open(output_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=['Artist', 'Tags'])\n",
    "                if not os.path.exists(output_file):  # Write header only if file doesn't exist\n",
    "                    writer.writeheader()\n",
    "                \n",
    "                for i, future in enumerate(as_completed(future_to_artist), 1):\n",
    "                    artist = future_to_artist[future]\n",
    "                    tags = future.result()\n",
    "                    \n",
    "                    # Ensure only the top 5 tags are saved\n",
    "                    top_5_tags = tags[:5]\n",
    "                    writer.writerow({\n",
    "                        'Artist': artist,\n",
    "                        'Tags': ', '.join(top_5_tags)  # Join only the top 5 tags\n",
    "                    })\n",
    "\n",
    "                    # Print progress in increments of 100\n",
    "                    if i % 100 == 0:\n",
    "                        print(f\"Processed tags for {i} new artists\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Fatal error during export: {e}\")\n",
    "    \n",
    "    print(f\"\\nExport complete! Processed {len(new_artists)} new artists.\")\n",
    "\n",
    "# Extract first artist if multiple are listed\n",
    "df['Primary Artist'] = df['Artist Name(s)'].apply(lambda x: x.split(',')[0] if pd.notna(x) else x)\n",
    "\n",
    "# Get unique artists with missing genres\n",
    "artists_missing_genres = df[df['Genres'].isna()]['Primary Artist'].unique()\n",
    "print(f\"Total artists with missing genres: {len(artists_missing_genres)}\")\n",
    "\n",
    "# Fetch tags for missing artists\n",
    "API_KEY = '74a510ecc9fc62bf3e0edc6adc2e99f9'\n",
    "export_artist_tags(API_KEY, artists_missing_genres, output_file='data/missing_genres.csv')\n",
    "\n",
    "# Load the fetched tags\n",
    "missing_genres_df = pd.read_csv('data/missing_genres.csv')\n",
    "\n",
    "# Merge with the original dataframe\n",
    "df = df.merge(\n",
    "    missing_genres_df,\n",
    "    how='left',\n",
    "    left_on='Primary Artist',\n",
    "    right_on='Artist',\n",
    "    suffixes=('', '_tags')  # Add a suffix to overlapping columns from missing_genres_df\n",
    ")\n",
    "\n",
    "# Fill missing genres in the original 'Genres' column\n",
    "df['Genres'] = df['Genres'].fillna(df['Tags'])\n",
    "\n",
    "# Drop the temporary 'Tags' and 'Artist' columns if no longer needed\n",
    "df.drop(columns=['Tags', 'Artist'], inplace=True)\n",
    "\n",
    "# Now `df` is updated in memory with the new genre data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fb3b7-348c-4d1a-abd2-29710e0c866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Genres' and 'Record Label' with 'Unknown'\n",
    "df['Genres'] = df['Genres'].fillna('Unknown')\n",
    "df['Record Label'] = df['Record Label'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff07c-0b26-47bf-af09-6c87b741ba13",
   "metadata": {},
   "source": [
    "#### Handle missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7d185-71c3-4aa3-8b81-8920a76aa070",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e0e6e-7b06-452d-8999-c96b5fcd8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls in any column except 'liked'\n",
    "df = df[df.drop(columns=['liked']).notna().all(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d89341-0210-4136-bd93-66070a896e54",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c803a7f-4ea3-431f-8c62-54b6801f8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4860391-1274-4020-bd0a-8cca3608576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many of each 'playlist_origin' are in the df dataset\n",
    "playlist_origin_counts = df['playlist_origin'].value_counts()\n",
    "\n",
    "print(\"Playlist Origin Counts:\")\n",
    "print(playlist_origin_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef584c69-80fb-4a3c-9631-e0e9edcb042a",
   "metadata": {},
   "source": [
    "## Target Encoding Record Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2bf7c-9d60-4221-b664-fead058df463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def target_encode(df, column, target, smoothing=1):\n",
    "    # Separate out df_nmf to ensure it's never used in encoding\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "    mean_target = df_train[target].mean()\n",
    "    label_means = df_train.groupby(column)[target].mean()\n",
    "    label_counts = df_train[column].value_counts()\n",
    "\n",
    "    smoothed_values = (label_means * label_counts + mean_target * smoothing) / (label_counts + smoothing)\n",
    "\n",
    "    # Map with a fallback to the overall mean\n",
    "    df[column + '_encoded'] = df[column].map(smoothed_values).fillna(mean_target)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Target encode only on the training data (excludes df_nmf)\n",
    "df = target_encode(df, 'Record Label', 'liked', smoothing=10)\n",
    "df[['Record Label', 'Record Label_encoded', 'liked']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e14d4-ae08-4cf0-bc7c-e78f0aa26bca",
   "metadata": {},
   "source": [
    "## Artists with Missing Genres (Last.fm to the rescue!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67598ab-44f6-4d23-a30c-6ceedf2c1de7",
   "metadata": {},
   "source": [
    "> I noticed in the data previews that one of the common genres imported from last.fm was 'seen live', which I take to meen a lot of last.fm users have seen that artist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccb97b-cd24-4928-ab57-7f77f311f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'seen live' from the 'Genres' column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: ', '.join([genre for genre in x.split(', ') if genre != 'seen live']) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275ff43-c4a4-4a7a-acb7-d5c74a80285e",
   "metadata": {},
   "source": [
    "## Target Encode Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1f54f-259b-46aa-826e-df7fa3d3596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a binary indicator column for 'Unknown' genres\n",
    "df['is_unknown_genre'] = (df['Genres'] == 'Unknown').astype(int)\n",
    "\n",
    "# Define the target encoding function\n",
    "def target_encode_multi_genre(df, genre_column, target, smoothing=1, aggregation_method='mean', nmf_fallback=0):\n",
    "    \"\"\"\n",
    "    Target encode a multi-genre column by splitting genres, encoding individually, and aggregating.\n",
    "    Explicitly handles 'Unknown' genres and NMF rows.\n",
    "    \"\"\"\n",
    "    # Separate out df_nmf to ensure it's never used in encoding\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "    # Calculate the global mean of the target variable\n",
    "    global_mean = df_train[target].mean()\n",
    "\n",
    "    # Split genres into individual categories and exclude 'seen live' and 'Unknown'\n",
    "    df_train['split_genres'] = df_train[genre_column].str.split(', ').apply(\n",
    "        lambda x: [genre for genre in x if genre != 'seen live' and genre != 'Unknown'] if isinstance(x, list) else x\n",
    "    )\n",
    "\n",
    "    # Explode the list of genres into separate rows\n",
    "    exploded_genres = df_train.explode('split_genres')\n",
    "\n",
    "    # Calculate target encoding for individual genres\n",
    "    label_means = exploded_genres.groupby('split_genres')[target].mean()\n",
    "    label_counts = exploded_genres['split_genres'].value_counts()\n",
    "\n",
    "    # Calculate smoothed target encoding for individual genres\n",
    "    smoothed_values = (label_means * label_counts + global_mean * smoothing) / (label_counts + smoothing)\n",
    "\n",
    "    # Map the smoothed values back to the exploded genres\n",
    "    exploded_genres['genre_encoded'] = exploded_genres['split_genres'].map(smoothed_values).fillna(global_mean)\n",
    "\n",
    "    # Aggregate encodings for multi-genre rows\n",
    "    if aggregation_method == 'mean':\n",
    "        aggregated_encodings = exploded_genres.groupby(exploded_genres.index)['genre_encoded'].mean()\n",
    "    elif aggregation_method == 'max':\n",
    "        aggregated_encodings = exploded_genres.groupby(exploded_genres.index)['genre_encoded'].max()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported aggregation method: {aggregation_method}\")\n",
    "\n",
    "    # Add the aggregated encodings to the original dataframe\n",
    "    df[genre_column + '_encoded'] = aggregated_encodings\n",
    "\n",
    "    # Handle 'Unknown' genres\n",
    "    is_unknown = df[genre_column] == 'Unknown'\n",
    "    df.loc[is_unknown, genre_column + '_encoded'] = global_mean  # Use global mean for non-NMF rows\n",
    "\n",
    "    # Handle NMF rows with 'Unknown' genres separately\n",
    "    is_nmf = df['playlist_origin'] == 'df_nmf'\n",
    "    df.loc[is_nmf & is_unknown, genre_column + '_encoded'] = nmf_fallback  # Use nmf_fallback for NMF rows\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the target encoding function\n",
    "df = target_encode_multi_genre(df, 'Genres', 'liked', smoothing=100, nmf_fallback=0)\n",
    "\n",
    "# Inspect the results\n",
    "print(df[['Genres', 'Genres_encoded', 'is_unknown_genre', 'liked', 'playlist_origin']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a202887-7b10-4ba6-858c-b52a0d2727b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Genres'] == 'Unknown']['Genres_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb6056-15fe-4dfa-b8b7-9d12b4e6f350",
   "metadata": {},
   "source": [
    "#### Further Examination of Missing Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb359b86-12e7-4553-a8af-0f3e49c97d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which rows still have Unknown Genres\n",
    "unknown_genres = df[df['Genres'] == 'Unknown']\n",
    "\n",
    "# Count the number of 'Unknown' genre tracks from each playlist_origin\n",
    "unknown_genres_origin_counts = unknown_genres['playlist_origin'].value_counts()\n",
    "\n",
    "print(\"Unknown Genres by Playlist Origin:\")\n",
    "print(unknown_genres_origin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84e7d3-24d4-4095-ab40-8fd3941a7e54",
   "metadata": {},
   "source": [
    "##### Getting Rid of Rows Where Genre is Unknown and Playlist Origin is Not df_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e843cb-99a9-42ae-b356-5ce4a6ddb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where:\n",
    "# 1. Genres is not 'Unknown', OR\n",
    "# 2. Genres is 'Unknown' and playlist_origin is 'df_nmf'\n",
    "df_filtered = df[~((df['Genres'] == 'Unknown') & (df['playlist_origin'] != 'df_nmf'))]\n",
    "\n",
    "# Verify the result\n",
    "print(\"Remaining Rows by Playlist Origin:\")\n",
    "print(df_filtered['playlist_origin'].value_counts())\n",
    "\n",
    "# Check remaining 'Unknown' genre rows\n",
    "remaining_unknown_genres = df_filtered[df_filtered['Genres'] == 'Unknown']\n",
    "\n",
    "print(\"\\nRemaining 'Unknown' Genres by Playlist Origin:\")\n",
    "print(remaining_unknown_genres['playlist_origin'].value_counts())\n",
    "\n",
    "# Inspect the remaining NMF tracks with 'Unknown' genres\n",
    "unknown_genres_nmf = df_filtered[(df_filtered['Genres'] == 'Unknown') & (df_filtered['playlist_origin'] == 'df_nmf')]\n",
    "\n",
    "print(\"\\nRemaining NMF Tracks with 'Unknown' Genres:\")\n",
    "print(unknown_genres_nmf[['Track Name', 'Artist Name(s)', 'Genres_encoded']])\n",
    "\n",
    "# Save the filtered dataframe to a CSV file (optional)\n",
    "df_filtered.to_csv('data/filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81899797-ed17-4353-8309-8ee3af5f826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all encoded columns to confirm the encoding\n",
    "df[['Record Label', 'Record Label_encoded', 'Genres', 'Genres_encoded']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df9122-2225-49b9-b63c-3f9f15f433dc",
   "metadata": {},
   "source": [
    "# Finding How Central an Artist is to My Music Taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612732d8-7cc2-4527-bcc5-307649e7d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for liked artists\n",
    "liked_artists = set(\n",
    "    df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Artist Name(s)']\n",
    "    .str.split(',').explode().str.strip()\n",
    ")\n",
    "G.add_nodes_from(liked_artists, type='liked')\n",
    "\n",
    "# Add nodes for similar artists (from liked)\n",
    "similar_artists_liked = set(\n",
    "    df_liked_similar['Similar Artists']\n",
    "    .dropna()  # Remove NaN values\n",
    "    .str.split(',').explode().str.strip()\n",
    ")\n",
    "G.add_nodes_from(similar_artists_liked, type='similar_liked')\n",
    "\n",
    "# Add edges based on similarity (from liked)\n",
    "for _, row in df_liked_similar.iterrows():\n",
    "    artist = row['Artist']\n",
    "    # Check if Similar Artists is a string before splitting\n",
    "    if isinstance(row['Similar Artists'], str):\n",
    "        similar = row['Similar Artists'].split(', ')\n",
    "        for s in similar:\n",
    "            G.add_edge(artist, s, weight=1.0)\n",
    "\n",
    "# Step 2: Calculate centrality scores\n",
    "centrality_scores = nx.pagerank(G)\n",
    "\n",
    "# Step 3: Map centrality scores back to DataFrame\n",
    "df['Artist Centrality'] = (\n",
    "    df['Artist Name(s)']\n",
    "    .str.split(',').str[0].str.strip()\n",
    "    .map(centrality_scores).fillna(0)\n",
    ")\n",
    "\n",
    "# Normalize centrality scores to 0-100\n",
    "df['Artist Centrality'] = (df['Artist Centrality'] / df['Artist Centrality'].max()) * 100\n",
    "\n",
    "# Step 4: Calculate NMF Similarity Scores\n",
    "# For NMF artists, calculate similarity to liked artists\n",
    "nmf_artists = df[df['playlist_origin'] == 'df_nmf']['Artist Name(s)'].str.split(',').str[0].str.strip()\n",
    "nmf_similarity_scores = {}\n",
    "\n",
    "for artist in nmf_artists:\n",
    "    similar_artists = (\n",
    "        df_nmf_similar[df_nmf_similar['Artist'] == artist]['Similar Artists']\n",
    "        .dropna()  # Add dropna here too\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    similarity_score = similar_artists.map(centrality_scores).mean()  # Average centrality of similar artists\n",
    "    nmf_similarity_scores[artist] = similarity_score if not pd.isna(similarity_score) else 0\n",
    "\n",
    "# Map NMF similarity scores back to DataFrame\n",
    "df['NMF Similarity'] = (\n",
    "    df['Artist Name(s)']\n",
    "    .str.split(',').str[0].str.strip()\n",
    "    .map(nmf_similarity_scores).fillna(0)\n",
    ")\n",
    "\n",
    "# Normalize NMF similarity scores to 0-100\n",
    "df['NMF Similarity'] = (df['NMF Similarity'] / df['NMF Similarity'].max()) * 100\n",
    "\n",
    "# Check the result\n",
    "print(df[['Artist Name(s)', 'Artist Centrality', 'NMF Similarity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7945566-7ea2-4c1d-8693-81283db3bebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Rows with NaN Similar Artists:\")\n",
    "print(df_liked_similar[df_liked_similar['Similar Artists'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c71190-c95d-476a-8a07-e92748e5e757",
   "metadata": {},
   "source": [
    "## Genre Strength Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0a5cb-84d6-4248-978b-b74cabd4495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the set of liked genres\n",
    "liked_genres = set(df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Genres'].str.split(',').explode().str.strip())\n",
    "\n",
    "# Calculate genre strength for each artist\n",
    "def calculate_genre_strength(genres):\n",
    "    if pd.isna(genres):\n",
    "        return 0\n",
    "    artist_genres = set(genres.split(','))\n",
    "    overlap = artist_genres.intersection(liked_genres)\n",
    "    return len(overlap) / len(artist_genres) if artist_genres else 0\n",
    "\n",
    "df['Genre Strength'] = df['Genres'].apply(calculate_genre_strength)\n",
    "\n",
    "# Normalize genre strength to 0–100\n",
    "df['Genre Strength'] = (df['Genre Strength'] / df['Genre Strength'].max()) * 100\n",
    "\n",
    "# Check the result\n",
    "print(df[['Genres', 'Genre Strength']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1229f7bd-8150-4f44-a713-98823e363aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in Genres_encoded\n",
    "genres_encoded_mean = df['Genres_encoded'].mean()\n",
    "df['Genres_encoded'] = df['Genres_encoded'].fillna(genres_encoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0a236-7e93-4a4f-ad96-aa77414f9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff4e76-fde1-460d-8997-9fbf06ce956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e10d2a-a4b1-4fc5-ba15-e0f339c9d738",
   "metadata": {},
   "source": [
    "## Standardize the numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e2297-9c93-4b11-aa84-a465fcacbe93",
   "metadata": {},
   "source": [
    "### Seperate New Music Friday and Save it for Later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46560726-196c-49ae-aa77-eb98091b8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 'df_nmf' from the main dataframe and save it for later\n",
    "df_nmf = df[df['playlist_origin'] == 'df_nmf'].copy()\n",
    "\n",
    "# Remove df_nmf entries from the original dataframe\n",
    "df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Save df_nmf to CSV for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb709d88-3b66-4b3d-bd0f-31c17b361b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns to standardize\n",
    "numeric_columns = [\n",
    "    'Duration (ms)', 'Popularity', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
    "    'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
    "    'Valence', 'Tempo', 'Record Label_encoded', 'Genres_encoded',\n",
    "    'Artist Centrality', 'NMF Similarity'\n",
    "]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data (df)\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Transform the test data (df_nmf) using the fitted scaler\n",
    "df_nmf[numeric_columns] = scaler.transform(df_nmf[numeric_columns])\n",
    "\n",
    "# Save the standardized df_nmf for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66c9a3-793f-4955-82a5-3b50e79be99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmf[numeric_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f901-f9af-4fd4-b402-32873abf0327",
   "metadata": {},
   "source": [
    "#### The data is now ready for modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a81c7d-b745-4c61-bb08-14142affdd55",
   "metadata": {},
   "source": [
    "## One last look at our columns before we run our model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd46fea-b43c-4b31-b48a-43679928a062",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "| Column Name           | Description                                                                                      | Data Type   | Drop From Model? |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|-------------|------------------|\n",
    "| Track Name            | Name of the track (song)                                                                          | object      | Yes              |\n",
    "| Album Name            | Name of the album the track belongs to                                                            | object      | Yes              |\n",
    "| Artist Name(s)        | Name(s) of the artist(s) associated with the track                                                | object      | Yes              |\n",
    "| Release Date          | Release date of the track (in object format for now, can be converted to datetime)               | object      | Yes              |\n",
    "| Duration (ms)         | Duration of the track in milliseconds                                                             | int64       | No               |\n",
    "| Popularity            | Popularity score of the track (higher is more popular)                                            | int64       | No               |\n",
    "| Genres                | Genres associated with the track                                                                  | object      | Yes              |\n",
    "| Record Label          | Record label associated with the track                                                            | object      | Yes              |\n",
    "| Danceability          | Measure of the track's danceability (0-1 scale)                                                  | float64     | No               |\n",
    "| Energy                | Energy level of the track (0-1 scale)                                                            | float64     | No               |\n",
    "| Key                   | The key of the track (musical key)                                                                | float64     | No               |\n",
    "| Loudness              | The loudness of the track (in decibels)                                                          | float64     | No               |\n",
    "| Mode                  | Mode of the track (major or minor key)                                                           | float64     | No               |\n",
    "| Speechiness           | Amount of speech-like content in the track                                                        | float64     | No               |\n",
    "| Acousticness          | Measure of acoustic quality (0-1 scale)                                                           | float64     | No               |\n",
    "| Instrumentalness      | Measure of instrumental content (0-1 scale)                                                      | float64     | No               |\n",
    "| Liveness              | Measure of the track's liveness (0-1 scale)                                                      | float64     | No               |\n",
    "| Valence               | Measure of the track's mood (0-1 scale, from negative to positive)                               | float64     | No               |\n",
    "| Tempo                 | Tempo of the track (beats per minute)                                                            | float64     | No               |\n",
    "| liked                 | Target variable: Whether the track was liked (1 = liked, 0 = not liked)                          | float64     | No               |\n",
    "| playlist_origin       | The playlist where the track originates from (e.g., 'df_nmf' for New Music Friday)               | object      | Yes              |\n",
    "| Primary Artist        | Main artist of the track (extracted from Artist Name(s))                                         | object      | Yes              |\n",
    "| Record Label_encoded  | Encoded version of the record label (numeric representation)                                     | float64     | No               |\n",
    "| is_unknown_genre      | Binary indicator if the track has an unknown genre (1 = unknown, 0 = known)                     | int32       | No               |\n",
    "| Genres_encoded        | Encoded version of the genre (numeric representation)                                            | float64     | No               |\n",
    "| Artist Centrality     | Measure of artist's importance in the similarity network (0-100 scale)                          | float64     | No               |\n",
    "| NMF Similarity        | Similarity score based on NMF algorithm (0-100 scale)                                           | float64     | No               |\n",
    "| Genre Strength        | Measure of how strongly a track belongs to its assigned genres                                   | float64     | No               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7455-4090-48fb-92bd-1fe791ed3f65",
   "metadata": {},
   "source": [
    "# Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3948a-af2a-497b-9b0e-5f68579ced00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Previous code until model training remains the same]\n",
    "features = [\n",
    "    'Duration (ms)', 'Popularity', 'Danceability', 'Energy', 'Key', \n",
    "    'Loudness', 'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness',\n",
    "    'Liveness', 'Valence', 'Tempo', 'Record Label_encoded', \n",
    "    'is_unknown_genre', 'Genres_encoded', 'Artist Centrality',\n",
    "    'NMF Similarity', 'Genre Strength'\n",
    "]\n",
    "\n",
    "# Normalize the target variable\n",
    "y_mean = df['liked'].mean()\n",
    "y_std = df['liked'].std()\n",
    "y_normalized = (df['liked'] - y_mean) / y_std\n",
    "\n",
    "# Prepare training data\n",
    "X = df[features]\n",
    "y = y_normalized  # Use normalized target\n",
    "\n",
    "# Train models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X, y)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Get feature importance from both models\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_rf': rf_model.feature_importances_\n",
    "}).sort_values('importance_rf', ascending=False)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_xgb': xgb_model.feature_importances_\n",
    "}).sort_values('importance_xgb', ascending=False)\n",
    "\n",
    "# Combine importance scores\n",
    "feature_importance = pd.merge(rf_importance, xgb_importance, on='feature')\n",
    "feature_importance['avg_importance'] = (feature_importance['importance_rf'] + feature_importance['importance_xgb']) / 2\n",
    "feature_importance = feature_importance.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "# Prepare NMF data for prediction\n",
    "df_nmf_cleaned = df_nmf[features]\n",
    "\n",
    "# Make predictions and denormalize\n",
    "rf_predictions = rf_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "xgb_predictions = xgb_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "\n",
    "# Combine predictions (ensemble)\n",
    "final_predictions = (rf_predictions + xgb_predictions) / 2\n",
    "\n",
    "# Get prediction intervals\n",
    "def get_prediction_interval(X, model, percentile=95):\n",
    "    predictions = []\n",
    "    for estimator in model.estimators_:\n",
    "        predictions.append(estimator.predict(X) * y_std + y_mean)\n",
    "    predictions = np.array(predictions)\n",
    "    lower = np.percentile(predictions, (100-percentile)/2, axis=0)\n",
    "    upper = np.percentile(predictions, 100-(100-percentile)/2, axis=0)\n",
    "    return lower, upper\n",
    "\n",
    "# Calculate prediction intervals\n",
    "lower_bound, upper_bound = get_prediction_interval(df_nmf_cleaned, rf_model)\n",
    "df_nmf['predicted_score'] = final_predictions\n",
    "df_nmf['prediction_lower'] = lower_bound\n",
    "df_nmf['prediction_upper'] = upper_bound\n",
    "df_nmf['prediction_uncertainty'] = upper_bound - lower_bound\n",
    "\n",
    "# Get the most common release date from NMF dataset\n",
    "nmf_release_date = df_nmf['Release Date'].mode().iloc[0]\n",
    "\n",
    "# Aggregate by album\n",
    "album_predictions = df_nmf.groupby('Album Name').agg({\n",
    "    'Artist Name(s)': 'first',\n",
    "    'predicted_score': ['mean', 'min', 'max', 'std', 'count'],\n",
    "    'prediction_uncertainty': 'mean',\n",
    "    'Genres': 'first',\n",
    "    'Record Label': 'first',\n",
    "    'Release Date': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "album_predictions.columns = [\n",
    "    'Album Name', 'Artist', \n",
    "    'avg_score', 'min_score', 'max_score', 'score_std', 'track_count',\n",
    "    'avg_uncertainty', 'Genres', 'Record Label', 'Release Date'\n",
    "]\n",
    "\n",
    "# Calculate confidence score (revised)\n",
    "max_std = album_predictions['score_std'].max()\n",
    "max_uncertainty = album_predictions['avg_uncertainty'].max()\n",
    "\n",
    "album_predictions['confidence_score'] = (\n",
    "    (1 - album_predictions['score_std'] / max_std) * \n",
    "    (1 - album_predictions['avg_uncertainty'] / max_uncertainty) * \n",
    "    (1 - 1/(1 + album_predictions['track_count']))\n",
    ") * 100\n",
    "\n",
    "# Clip confidence scores to avoid extremely low values\n",
    "album_predictions['confidence_score'] = np.clip(\n",
    "    album_predictions['confidence_score'], a_min=1, a_max=100\n",
    ")\n",
    "\n",
    "# Add weighted score for ranking\n",
    "album_predictions['weighted_score'] = (\n",
    "    album_predictions['avg_score'] * album_predictions['confidence_score'] / 100\n",
    ")\n",
    "\n",
    "# Add NMF release date\n",
    "album_predictions['NMF_Date'] = nmf_release_date\n",
    "\n",
    "# Sort by weighted score\n",
    "album_recommendations = album_predictions.sort_values('weighted_score', ascending=False)\n",
    "\n",
    "# Format the date for the filename\n",
    "date_str = datetime.strptime(nmf_release_date, '%Y-%m-%d').strftime('%m-%d-%y')\n",
    "filename = f\"{date_str}_Album_Recommendations.csv\"\n",
    "\n",
    "# Create predictions directory if it doesn't exist\n",
    "os.makedirs('predictions', exist_ok=True)\n",
    "\n",
    "# Save recommendations to the root predictions folder\n",
    "album_recommendations.to_csv(f'predictions/{filename}', index=False)\n",
    "\n",
    "# Sort df_nmf by predicted_score before saving detailed predictions\n",
    "df_nmf_sorted = df_nmf.sort_values('predicted_score', ascending=False)\n",
    "df_nmf_sorted[['Artist Name(s)', 'Track Name', 'Album Name', 'predicted_score',\n",
    "               'prediction_lower', 'prediction_upper', 'prediction_uncertainty']].to_csv(\n",
    "                   f'predictions/nmf_predictions_with_uncertainty.csv', index=False)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nNew Music Friday Release Date: {nmf_release_date}\")\n",
    "print(\"\\nTop 10 Recommended Albums:\")\n",
    "print(album_recommendations[['Album Name', 'Artist', 'avg_score', 'track_count', \n",
    "                           'confidence_score', 'NMF_Date']].head(10))\n",
    "\n",
    "# Define the custom scorer for cross-validation\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    y_true_denormalized = y_true * y_std + y_mean\n",
    "    y_pred_denormalized = y_pred * y_std + y_mean\n",
    "    return -mean_squared_error(y_true_denormalized, y_pred_denormalized)  # Negative MSE for scoring\n",
    "\n",
    "# Wrap the custom scorer for use with cross_val_score\n",
    "custom_scorer_func = make_scorer(custom_scorer, greater_is_better=False)\n",
    "\n",
    "# Evaluate models using cross-validation\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(f\"Random Forest CV Score: {rf_cv_scores.mean():.3f} (+/- {rf_cv_scores.std() * 2:.3f})\")\n",
    "print(f\"XGBoost CV Score: {xgb_cv_scores.mean():.3f} (+/- {xgb_cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Print top 20 most important features\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance[['feature', 'avg_importance']].head(20).to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['avg_importance'])\n",
    "plt.xlabel('Average Importance')\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9322a5-2f57-4eec-a695-15c73b3a8b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
