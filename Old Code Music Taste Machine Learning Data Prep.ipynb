{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d392a2d-8247-40dc-9431-ae29941dc3ea",
   "metadata": {},
   "source": [
    "# Music Taste Prediction Model: New Music Friday Recommender üíøüéßüëçüëé\n",
    "In this model, I use my liked songs playlist, my recently loved and not loved albums, to train my regression model on what kind of music I do and don't like. At the end my test model will be the new music friday albums from the most recent Friday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e436444-4aff-431a-aedc-e7871c247d1e",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160a9a1f-e9f9-4fb7-b0e3-dcc706dba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Third-Party Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Fuzzy Matching\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from nbconvert import HTMLExporter\n",
    "import nbformat\n",
    "\n",
    "# Streamlit (if needed)\n",
    "import streamlit as st\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42454624-15b3-4b80-bab9-a8ecbf9d299b",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8067f0c-b06b-4426-bad9-69bd28e3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liked = pd.read_csv(\"data/liked.csv\")  # Liked playlist on Spotify\n",
    "df_fav_albums = pd.read_csv(\"data/liked_albums.csv\")  # Albums I've Liked in Recent Years\n",
    "df_not_liked = pd.read_csv(\"data/did_not_like.csv\")  # Albums I've not liked in Recent Years\n",
    "df_nmf = pd.read_csv(\"data/nmf.csv\")  # The most recent New Music Friday Playlist\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv') #Similar Artisits to My Liked Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b112f9a-264e-4da1-87fd-ffe68974dd78",
   "metadata": {},
   "source": [
    "## A Check for New Artists / Pull Their Similar Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae3c1adc-0020-425f-89fa-56dee6f455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing and new data...\n",
      "Loaded 2140 existing artists from database\n",
      "Found 0 new artists to process\n",
      "No new artists to process. Database is up to date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Faim</td>\n",
       "      <td>Oh The Larceny, City Wolf, Random Hero, needsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melody Lake</td>\n",
       "      <td>Ian Wong, Limelight Glow, Slow Rising Hope, Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liza Anne</td>\n",
       "      <td>Miya Folick, Torres, Billie Marten, Pom Pom Sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Kinks</td>\n",
       "      <td>Dave Davies, The Who, Small Faces, The Zombies...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Artist                                    Similar Artists\n",
       "0         RY X                                                NaN\n",
       "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...\n",
       "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...\n",
       "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...\n",
       "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar Artist Check/Pull\n",
    "class LastFMAPI:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25, limit: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        self.limit = limit\n",
    "\n",
    "    def get_similar_artists(self, artist_name: str) -> List[str]:\n",
    "        \"\"\"Fetch similar artists for a given artist from LastFM API.\"\"\"\n",
    "        params = {\n",
    "            'method': 'artist.getSimilar',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'limit': self.limit,  # Add limit parameter\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Handle rate limiting\n",
    "            if 'X-RateLimit-Remaining' in response.headers:\n",
    "                remaining = int(response.headers['X-RateLimit-Remaining'])\n",
    "                if remaining == 0:\n",
    "                    sleep(self.rate_limit_delay)\n",
    "            \n",
    "            data = response.json()\n",
    "            if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "                return [artist['name'] for artist in data['similarartists']['artist'][:self.limit]]\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching similar artists for {artist_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "def extract_primary_artist(artist_string: str) -> str:\n",
    "    \"\"\"Extract the first artist name before any comma.\"\"\"\n",
    "    if pd.isna(artist_string):\n",
    "        return \"\"\n",
    "    return artist_string.split(\",\")[0].strip()\n",
    "\n",
    "def update_similar_artists(liked_path: str, \n",
    "                         albums_path: str, \n",
    "                         output_path: str, \n",
    "                         api_key: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Update the similar artists database with new artists from liked playlists.\n",
    "    Returns the complete DataFrame of artists and their similar artists.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading existing and new data...\")\n",
    "    \n",
    "    # Load existing similar artists data\n",
    "    existing_data: Dict[str, List[str]] = {}\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        existing_data = dict(zip(existing_df['Artist'], existing_df['Similar Artists']))\n",
    "        print(f\"Loaded {len(existing_data)} existing artists from database\")\n",
    "    \n",
    "    # Load and process current playlists\n",
    "    df_liked = pd.read_csv(liked_path)\n",
    "    df_albums = pd.read_csv(albums_path)\n",
    "    \n",
    "    # Extract and combine primary artists\n",
    "    current_artists = set(\n",
    "        pd.concat([\n",
    "            df_liked['Artist Name(s)'].apply(extract_primary_artist),\n",
    "            df_albums['Artist Name(s)'].apply(extract_primary_artist)\n",
    "        ]).unique()\n",
    "    )\n",
    "    current_artists.discard(\"\")  # Remove empty strings\n",
    "    \n",
    "    # Find new artists not in existing data\n",
    "    new_artists = current_artists - set(existing_data.keys())\n",
    "    print(f\"Found {len(new_artists)} new artists to process\")\n",
    "    \n",
    "    if not new_artists:\n",
    "        print(\"No new artists to process. Database is up to date!\")\n",
    "        # Create and return DataFrame even if no updates\n",
    "        return pd.DataFrame({\n",
    "            'Artist': list(existing_data.keys()),\n",
    "            'Similar Artists': list(existing_data.values())\n",
    "        })\n",
    "    \n",
    "    # Initialize LastFM API client\n",
    "    api = LastFMAPI(api_key)\n",
    "    \n",
    "    # Process artists with concurrent requests\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(api.get_similar_artists, artist): artist \n",
    "            for artist in new_artists\n",
    "        }\n",
    "        \n",
    "        # Show progress bar while processing\n",
    "        for future in tqdm(as_completed(future_to_artist), \n",
    "                         total=len(future_to_artist),\n",
    "                         desc=\"Fetching similar artists\"):\n",
    "            artist = future_to_artist[future]\n",
    "            similar_artists = future.result()\n",
    "            results[artist] = ', '.join(similar_artists)\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    combined_data = {**existing_data, **results}\n",
    "    \n",
    "    # Create DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        'Artist': list(combined_data.keys()),\n",
    "        'Similar Artists': list(combined_data.values())\n",
    "    })\n",
    "    \n",
    "    # Save updated data\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    print(f\"Successfully updated database with {len(new_artists)} new artists\")\n",
    "    print(f\"Total artists in database: {len(combined_data)}\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "    LIKED_PATH = \"data/liked.csv\"\n",
    "    ALBUMS_PATH = \"data/liked_albums.csv\"\n",
    "    OUTPUT_PATH = \"data/liked_artists_only_similar.csv\"\n",
    "    \n",
    "    # Run the update and get the DataFrame\n",
    "    df_liked_similar = update_similar_artists(\n",
    "        LIKED_PATH, \n",
    "        ALBUMS_PATH, \n",
    "        OUTPUT_PATH, \n",
    "        API_KEY\n",
    "    )\n",
    "    \n",
    "# Now df_liked_similar is ready to use\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392df38d-c607-4196-bf48-ab735338849e",
   "metadata": {},
   "source": [
    "## Quick Glance at our Refreshed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929ec508-7fe2-43be-ac08-f08bb640aca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0zlVF45v1USPhSzmq558LF</td>\n",
       "      <td>Debbie Downer</td>\n",
       "      <td>Armageddon In A Summer Dress</td>\n",
       "      <td>Sunny War</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>203000</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-25T15:57:50Z</td>\n",
       "      <td>folk punk,americana</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>90.770</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3XFO3ezyuum0Ulxozpi2o3</td>\n",
       "      <td>Beautiful Trip</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Smif-N-Wessun</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>184106</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-22T21:11:10Z</td>\n",
       "      <td>east coast hip hop,boom bap,hip hop</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.415</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.3710</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>84.980</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4FG86wYpIjIl5NrOr79Fxf</td>\n",
       "      <td>Tough Love</td>\n",
       "      <td>Flyte</td>\n",
       "      <td>Flyte,Laura Marling</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>181763</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-21T03:05:09Z</td>\n",
       "      <td>singer-songwriter,chamber pop,folk,indie folk</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.872</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.6830</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>119.942</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5KWrRynsADgBtgqoPCh7kn</td>\n",
       "      <td>Words</td>\n",
       "      <td>Waking Up</td>\n",
       "      <td>Storefront Church,Phoebe Bridgers</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>325443</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-20T04:35:16Z</td>\n",
       "      <td>chamber pop,baroque pop</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.978</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>77.883</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7nGN1Wu9kCaKUUdqBcY9NZ</td>\n",
       "      <td>Let Me Go (feat. Madison Cunningham)</td>\n",
       "      <td>Let Me Go (feat. Madison Cunningham)</td>\n",
       "      <td>Deep Sea Diver,Madison Cunningham</td>\n",
       "      <td>2025-02-04</td>\n",
       "      <td>282200</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-19T00:45:28Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.924</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>127.658</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID                            Track Name  \\\n",
       "0  0zlVF45v1USPhSzmq558LF                         Debbie Downer   \n",
       "1  3XFO3ezyuum0Ulxozpi2o3                        Beautiful Trip   \n",
       "2  4FG86wYpIjIl5NrOr79Fxf                            Tough Love   \n",
       "3  5KWrRynsADgBtgqoPCh7kn                                 Words   \n",
       "4  7nGN1Wu9kCaKUUdqBcY9NZ  Let Me Go (feat. Madison Cunningham)   \n",
       "\n",
       "                             Album Name                     Artist Name(s)  \\\n",
       "0          Armageddon In A Summer Dress                          Sunny War   \n",
       "1                              Infinity                      Smif-N-Wessun   \n",
       "2                                 Flyte                Flyte,Laura Marling   \n",
       "3                             Waking Up  Storefront Church,Phoebe Bridgers   \n",
       "4  Let Me Go (feat. Madison Cunningham)  Deep Sea Diver,Madison Cunningham   \n",
       "\n",
       "  Release Date  Duration (ms)  Popularity  Added By              Added At  \\\n",
       "0   2025-02-21         203000          20       NaN  2025-02-25T15:57:50Z   \n",
       "1   2025-02-21         184106          25       NaN  2025-02-22T21:11:10Z   \n",
       "2   2023-10-27         181763          48       NaN  2025-02-21T03:05:09Z   \n",
       "3   2023-02-03         325443          31       NaN  2025-02-20T04:35:16Z   \n",
       "4   2025-02-04         282200          39       NaN  2025-02-19T00:45:28Z   \n",
       "\n",
       "                                          Genres  ... Key  Loudness  Mode  \\\n",
       "0                            folk punk,americana  ...   4    -5.054     0   \n",
       "1            east coast hip hop,boom bap,hip hop  ...   9    -7.415     0   \n",
       "2  singer-songwriter,chamber pop,folk,indie folk  ...   2    -6.872     1   \n",
       "3                        chamber pop,baroque pop  ...   5   -10.978     1   \n",
       "4                                            NaN  ...   4    -4.924     0   \n",
       "\n",
       "   Speechiness  Acousticness  Instrumentalness  Liveness  Valence    Tempo  \\\n",
       "0       0.0326        0.0728          0.000147    0.1570   0.5990   90.770   \n",
       "1       0.2560        0.3710          0.006050    0.0737   0.4780   84.980   \n",
       "2       0.0288        0.6830          0.272000    0.1090   0.6160  119.942   \n",
       "3       0.0345        0.5330          0.026300    0.1070   0.0671   77.883   \n",
       "4       0.0308        0.3040          0.000000    0.1140   0.3740  127.658   \n",
       "\n",
       "   Time Signature  \n",
       "0               4  \n",
       "1               4  \n",
       "2               4  \n",
       "3               4  \n",
       "4               4  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80b875a-ebab-472e-82b5-85568f036a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0UOeq7bSskoJa4cJaJOmFS</td>\n",
       "      <td>Ticking</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>186949</td>\n",
       "      <td>27</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.291</td>\n",
       "      <td>175.574</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02bA26OEe0nNFyE3YcNx4K</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>207409</td>\n",
       "      <td>43</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.00435</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.0877</td>\n",
       "      <td>0.189</td>\n",
       "      <td>88.581</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7IPDhCIQlpvxVxtC1Q7Jq4</td>\n",
       "      <td>Cathedral</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>179694</td>\n",
       "      <td>27</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.00978</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.397</td>\n",
       "      <td>119.056</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65fPteG9ctHt2rrJxlbMr8</td>\n",
       "      <td>Shaking Their Hands</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>222489</td>\n",
       "      <td>25</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.551</td>\n",
       "      <td>89.485</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4UgkFdXpJD0fhw06BMk0bz</td>\n",
       "      <td>Adore Adore Adore</td>\n",
       "      <td>Letter to Self</td>\n",
       "      <td>SPRINTS</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>157766</td>\n",
       "      <td>32</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T00:53:10Z</td>\n",
       "      <td>post-punk</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.402</td>\n",
       "      <td>176.054</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID           Track Name      Album Name Artist Name(s)  \\\n",
       "0  0UOeq7bSskoJa4cJaJOmFS              Ticking  Letter to Self        SPRINTS   \n",
       "1  02bA26OEe0nNFyE3YcNx4K                Heavy  Letter to Self        SPRINTS   \n",
       "2  7IPDhCIQlpvxVxtC1Q7Jq4            Cathedral  Letter to Self        SPRINTS   \n",
       "3  65fPteG9ctHt2rrJxlbMr8  Shaking Their Hands  Letter to Self        SPRINTS   \n",
       "4  4UgkFdXpJD0fhw06BMk0bz    Adore Adore Adore  Letter to Self        SPRINTS   \n",
       "\n",
       "  Release Date  Duration (ms)  Popularity                   Added By  \\\n",
       "0   2024-01-05         186949          27  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "1   2024-01-05         207409          43  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "2   2024-01-05         179694          27  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "3   2024-01-05         222489          25  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "4   2024-01-05         157766          32  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "\n",
       "               Added At     Genres  ...   Key  Loudness  Mode  Speechiness  \\\n",
       "0  2025-01-29T00:53:10Z  post-punk  ...  11.0    -6.490   1.0       0.3440   \n",
       "1  2025-01-29T00:53:10Z  post-punk  ...  11.0    -5.925   1.0       0.0591   \n",
       "2  2025-01-29T00:53:10Z  post-punk  ...   7.0    -6.231   1.0       0.0473   \n",
       "3  2025-01-29T00:53:10Z  post-punk  ...   4.0    -5.658   0.0       0.0533   \n",
       "4  2025-01-29T00:53:10Z  post-punk  ...   4.0    -4.401   0.0       0.2570   \n",
       "\n",
       "   Acousticness  Instrumentalness  Liveness  Valence    Tempo  Time Signature  \n",
       "0       0.02500          0.076500    0.0934    0.291  175.574             4.0  \n",
       "1       0.00435          0.000738    0.0877    0.189   88.581             4.0  \n",
       "2       0.00978          0.002700    0.0887    0.397  119.056             4.0  \n",
       "3       0.19900          0.108000    0.1330    0.551   89.485             4.0  \n",
       "4       0.01070          0.000107    0.1010    0.402  176.054             4.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liked Albums in Recent Years\n",
    "df_fav_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0d6345-80d1-4b33-a4c5-10b1e138bbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54KEm0VI9i3ic7VHHKHKRx</td>\n",
       "      <td>¬øC√≥mo As√≠?</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>169654</td>\n",
       "      <td>54</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.04170</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.379</td>\n",
       "      <td>135.985</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5mVkTPlTPxlQOn7kEvuM3j</td>\n",
       "      <td>Me Pongo Loca</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>177815</td>\n",
       "      <td>51</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.03710</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.407</td>\n",
       "      <td>114.999</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6XaJfhwof7qIgbbXO5tIQI</td>\n",
       "      <td>Igual Que Un √Ångel (with Peso Pluma)</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis,Peso Pluma</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>260370</td>\n",
       "      <td>74</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>corrido,corridos tumbados,corridos b√©licos,m√∫s...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.482</td>\n",
       "      <td>108.001</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52x8HIGuk1gGTlvO8CuLNS</td>\n",
       "      <td>Pensamientos Intrusivos</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>192027</td>\n",
       "      <td>58</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.511</td>\n",
       "      <td>119.994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3RleMgz4iO0BNezGdSxDnY</td>\n",
       "      <td>Diosa</td>\n",
       "      <td>ORQU√çDEAS</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>156037</td>\n",
       "      <td>56</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-01-29T01:04:15Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.06750</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.698</td>\n",
       "      <td>107.994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID                            Track Name Album Name  \\\n",
       "0  54KEm0VI9i3ic7VHHKHKRx                            ¬øC√≥mo As√≠?  ORQU√çDEAS   \n",
       "1  5mVkTPlTPxlQOn7kEvuM3j                         Me Pongo Loca  ORQU√çDEAS   \n",
       "2  6XaJfhwof7qIgbbXO5tIQI  Igual Que Un √Ångel (with Peso Pluma)  ORQU√çDEAS   \n",
       "3  52x8HIGuk1gGTlvO8CuLNS               Pensamientos Intrusivos  ORQU√çDEAS   \n",
       "4  3RleMgz4iO0BNezGdSxDnY                                 Diosa  ORQU√çDEAS   \n",
       "\n",
       "          Artist Name(s) Release Date  Duration (ms)  Popularity  \\\n",
       "0             Kali Uchis   2024-01-12         169654          54   \n",
       "1             Kali Uchis   2024-01-12         177815          51   \n",
       "2  Kali Uchis,Peso Pluma   2024-01-12         260370          74   \n",
       "3             Kali Uchis   2024-01-12         192027          58   \n",
       "4             Kali Uchis   2024-01-12         156037          56   \n",
       "\n",
       "                    Added By              Added At  \\\n",
       "0  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "1  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "2  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "3  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "4  mmr4r23xnc6oh1c77lysfbqg4  2025-01-29T01:04:15Z   \n",
       "\n",
       "                                              Genres  ...  Key  Loudness  \\\n",
       "0                                                NaN  ...  6.0    -7.662   \n",
       "1                                                NaN  ...  7.0    -8.680   \n",
       "2  corrido,corridos tumbados,corridos b√©licos,m√∫s...  ...  5.0    -5.340   \n",
       "3                                                NaN  ...  9.0    -8.333   \n",
       "4                                                NaN  ...  5.0    -5.518   \n",
       "\n",
       "   Mode  Speechiness  Acousticness  Instrumentalness  Liveness  Valence  \\\n",
       "0   0.0       0.0892       0.04170          0.346000     0.154    0.379   \n",
       "1   0.0       0.0426       0.03710          0.152000     0.106    0.407   \n",
       "2   0.0       0.0320       0.00449          0.000663     0.185    0.482   \n",
       "3   0.0       0.0394       0.57500          0.012900     0.110    0.511   \n",
       "4   0.0       0.0668       0.06750          0.000101     0.078    0.698   \n",
       "\n",
       "     Tempo  Time Signature  \n",
       "0  135.985             4.0  \n",
       "1  114.999             4.0  \n",
       "2  108.001             4.0  \n",
       "3  119.994             4.0  \n",
       "4  107.994             4.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Albums Not Liked in Recent Years\n",
    "df_not_liked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a190ec91-73e0-40c5-95b4-fc212abd1730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist Name(s)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Added At</th>\n",
       "      <th>Genres</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08aaQA6A7UHvbPGsfPrAFe</td>\n",
       "      <td>Praise</td>\n",
       "      <td>Sinister Grift</td>\n",
       "      <td>Panda Bear</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>211126</td>\n",
       "      <td>0</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-02-28T14:13:47Z</td>\n",
       "      <td>psychedelic pop</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.01470</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.833</td>\n",
       "      <td>128.870</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4t65DNY5AeBaoDiSQoALlE</td>\n",
       "      <td>Anywhere but Here</td>\n",
       "      <td>Sinister Grift</td>\n",
       "      <td>Panda Bear</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>279972</td>\n",
       "      <td>0</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-02-28T14:13:47Z</td>\n",
       "      <td>psychedelic pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.39000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.461</td>\n",
       "      <td>123.957</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2TKDC967TRogQLg86tGw5b</td>\n",
       "      <td>50mg</td>\n",
       "      <td>Sinister Grift</td>\n",
       "      <td>Panda Bear</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>274538</td>\n",
       "      <td>0</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-02-28T14:13:47Z</td>\n",
       "      <td>psychedelic pop</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.746</td>\n",
       "      <td>133.014</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0Krqcz9OB6G9wUUBL9BpGz</td>\n",
       "      <td>Ends Meet</td>\n",
       "      <td>Sinister Grift</td>\n",
       "      <td>Panda Bear</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>201762</td>\n",
       "      <td>0</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-02-28T14:13:47Z</td>\n",
       "      <td>psychedelic pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.04940</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.852</td>\n",
       "      <td>114.030</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0AN9lNRBYphPA1xNt48UZJ</td>\n",
       "      <td>Just as Well</td>\n",
       "      <td>Sinister Grift</td>\n",
       "      <td>Panda Bear</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>213937</td>\n",
       "      <td>0</td>\n",
       "      <td>mmr4r23xnc6oh1c77lysfbqg4</td>\n",
       "      <td>2025-02-28T14:13:47Z</td>\n",
       "      <td>psychedelic pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.17200</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.940</td>\n",
       "      <td>149.934</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track ID         Track Name      Album Name Artist Name(s)  \\\n",
       "0  08aaQA6A7UHvbPGsfPrAFe             Praise  Sinister Grift     Panda Bear   \n",
       "1  4t65DNY5AeBaoDiSQoALlE  Anywhere but Here  Sinister Grift     Panda Bear   \n",
       "2  2TKDC967TRogQLg86tGw5b               50mg  Sinister Grift     Panda Bear   \n",
       "3  0Krqcz9OB6G9wUUBL9BpGz          Ends Meet  Sinister Grift     Panda Bear   \n",
       "4  0AN9lNRBYphPA1xNt48UZJ       Just as Well  Sinister Grift     Panda Bear   \n",
       "\n",
       "  Release Date  Duration (ms)  Popularity                   Added By  \\\n",
       "0   2025-02-28         211126           0  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "1   2025-02-28         279972           0  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "2   2025-02-28         274538           0  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "3   2025-02-28         201762           0  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "4   2025-02-28         213937           0  mmr4r23xnc6oh1c77lysfbqg4   \n",
       "\n",
       "               Added At           Genres  ...   Key  Loudness  Mode  \\\n",
       "0  2025-02-28T14:13:47Z  psychedelic pop  ...  10.0    -5.195   1.0   \n",
       "1  2025-02-28T14:13:47Z  psychedelic pop  ...   1.0    -7.861   1.0   \n",
       "2  2025-02-28T14:13:47Z  psychedelic pop  ...  10.0    -6.908   0.0   \n",
       "3  2025-02-28T14:13:47Z  psychedelic pop  ...   1.0    -5.302   1.0   \n",
       "4  2025-02-28T14:13:47Z  psychedelic pop  ...   1.0    -6.400   1.0   \n",
       "\n",
       "   Speechiness  Acousticness  Instrumentalness  Liveness  Valence    Tempo  \\\n",
       "0       0.0353       0.01470          0.000002    0.3810    0.833  128.870   \n",
       "1       0.0298       0.39000          0.000003    0.1170    0.461  123.957   \n",
       "2       0.0328       0.00253          0.000552    0.0956    0.746  133.014   \n",
       "3       0.0372       0.04940          0.000608    0.2350    0.852  114.030   \n",
       "4       0.0438       0.17200          0.002050    0.0894    0.940  149.934   \n",
       "\n",
       "   Time Signature  \n",
       "0             4.0  \n",
       "1             3.0  \n",
       "2             4.0  \n",
       "3             4.0  \n",
       "4             3.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New Music Friday Playlist\n",
    "df_nmf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64bfbf76-1649-4542-b001-2fedd527ecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Faim</td>\n",
       "      <td>Oh The Larceny, City Wolf, Random Hero, needsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melody Lake</td>\n",
       "      <td>Ian Wong, Limelight Glow, Slow Rising Hope, Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liza Anne</td>\n",
       "      <td>Miya Folick, Torres, Billie Marten, Pom Pom Sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Kinks</td>\n",
       "      <td>Dave Davies, The Who, Small Faces, The Zombies...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Artist                                    Similar Artists\n",
       "0         RY X                                                NaN\n",
       "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...\n",
       "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...\n",
       "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...\n",
       "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar Artists to Recently Played Artists (Last.fm)\n",
    "\n",
    "df_liked_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30386-5197-4245-9871-cffbe4952a33",
   "metadata": {},
   "source": [
    "> A quick reminder of the standard columns of a spotify export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a3f0c33-76f1-4d7b-95c3-988b1ca941a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track ID', 'Track Name', 'Album Name', 'Artist Name(s)',\n",
       "       'Release Date', 'Duration (ms)', 'Popularity', 'Added By', 'Added At',\n",
       "       'Genres', 'Record Label', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
       "       'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
       "       'Valence', 'Tempo', 'Time Signature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694749b-c05c-45c8-8c17-6f30a6ffc54d",
   "metadata": {},
   "source": [
    "> What's available in the Similar dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fe763b3-50c4-474d-8363-a5c41461ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Artist', 'Similar Artists'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25a6b9-e488-4c3a-9e27-4cf15e57c504",
   "metadata": {},
   "source": [
    "### Add Target Labels for Training Feature\n",
    "We need to assign a score to songs I've faved on spotify (100), albums I've enjoyed in recent years (50), and albums that I have not enjoyed in recent years (0) to train the model on the types of songs I don't like, like, and love. 'liked' will be our target variable, later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a802d4-ff06-4dab-886d-059ed0ee2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign liked scores before combining\n",
    "df_liked['liked'] = 100\n",
    "df_fav_albums['liked'] = 50\n",
    "df_not_liked['liked'] = 0\n",
    "df_nmf['liked'] = np.nan \n",
    "\n",
    "# Add playlist_origin column before combining\n",
    "df_liked['playlist_origin'] = 'df_liked'\n",
    "df_fav_albums['playlist_origin'] = 'df_fav_albums'\n",
    "df_not_liked['playlist_origin'] = 'df_not_liked'\n",
    "df_nmf['playlist_origin'] = 'df_nmf'\n",
    "df_liked_similar['source'] = 'liked_similar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10e0ba-5881-4cd4-91e0-630063a72dd8",
   "metadata": {},
   "source": [
    "### Check application of the target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4add9e6b-4a3c-46f0-bc43-4bb4215cd97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>df_liked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0    100        df_liked\n",
       "1    100        df_liked\n",
       "2    100        df_liked\n",
       "3    100        df_liked\n",
       "4    100        df_liked"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6cb7c2-b08e-4d00-9cd7-fcea6eec1ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>df_fav_albums</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0     50   df_fav_albums\n",
       "1     50   df_fav_albums\n",
       "2     50   df_fav_albums\n",
       "3     50   df_fav_albums\n",
       "4     50   df_fav_albums"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fav_albums[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7b72fb6-dac5-4d75-b6fd-b3ca1d8973f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>df_not_liked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0      0    df_not_liked\n",
       "1      0    df_not_liked\n",
       "2      0    df_not_liked\n",
       "3      0    df_not_liked\n",
       "4      0    df_not_liked"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_liked[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c75164a9-8182-463f-a450-2534f52aeb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>playlist_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>df_nmf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked playlist_origin\n",
       "0    NaN          df_nmf\n",
       "1    NaN          df_nmf\n",
       "2    NaN          df_nmf\n",
       "3    NaN          df_nmf\n",
       "4    NaN          df_nmf"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf[['liked', 'playlist_origin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e40fa4a1-a55a-42c6-b3b1-8994b44c3602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Similar Artists</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RY X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Faim</td>\n",
       "      <td>Oh The Larceny, City Wolf, Random Hero, needsh...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melody Lake</td>\n",
       "      <td>Ian Wong, Limelight Glow, Slow Rising Hope, Po...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liza Anne</td>\n",
       "      <td>Miya Folick, Torres, Billie Marten, Pom Pom Sq...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Kinks</td>\n",
       "      <td>Dave Davies, The Who, Small Faces, The Zombies...</td>\n",
       "      <td>liked_similar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Artist                                    Similar Artists  \\\n",
       "0         RY X                                                NaN   \n",
       "1     The Faim  Oh The Larceny, City Wolf, Random Hero, needsh...   \n",
       "2  Melody Lake  Ian Wong, Limelight Glow, Slow Rising Hope, Po...   \n",
       "3    Liza Anne  Miya Folick, Torres, Billie Marten, Pom Pom Sq...   \n",
       "4    The Kinks  Dave Davies, The Who, Small Faces, The Zombies...   \n",
       "\n",
       "          source  \n",
       "0  liked_similar  \n",
       "1  liked_similar  \n",
       "2  liked_similar  \n",
       "3  liked_similar  \n",
       "4  liked_similar  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_similar[['Artist', 'Similar Artists', 'source']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4bb9c-a4ea-4286-bf9b-9a7575d9ffcf",
   "metadata": {},
   "source": [
    "## Data Cleaning üßπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44856ee-a472-41f3-8622-01d76e370849",
   "metadata": {},
   "source": [
    "## Merge The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34bd66a5-2ed8-4eda-b8df-09a5feaa782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_liked, df_fav_albums, df_not_liked, df_nmf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f9b1007-6bfe-429b-bf10-5de0241f9e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14006, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How Large is the Dataset, Now?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035bf83-b7da-4fbb-bc26-f1ed816a5798",
   "metadata": {},
   "source": [
    "#### Remove the Duplicates üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "861de4ff-4fb7-421b-8923-419d750172bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11756, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates: Keep the highest 'liked' score (100 > 50)\n",
    "df = df.sort_values(by='liked', ascending=False)  # Ensures 100-rated songs come first\n",
    "df = df.drop_duplicates(subset=['Track Name', 'Artist Name(s)'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2580a-e10a-4d8f-a9fc-258a2777d37f",
   "metadata": {},
   "source": [
    "#### Drop columns that won't help the model üí£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9a1551b-d6a6-4ff4-b5f3-f333f2e4e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Added By', 'Added At', 'Time Signature'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bff07c-0b26-47bf-af09-6c87b741ba13",
   "metadata": {},
   "source": [
    "#### Handle missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34d7d185-71c3-4aa3-8b81-8920a76aa070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track ID               0\n",
       "Track Name             0\n",
       "Album Name             0\n",
       "Artist Name(s)         0\n",
       "Release Date           0\n",
       "Duration (ms)          0\n",
       "Popularity             0\n",
       "Genres              5713\n",
       "Record Label           3\n",
       "Danceability           9\n",
       "Energy                 9\n",
       "Key                    9\n",
       "Loudness               9\n",
       "Mode                   9\n",
       "Speechiness            9\n",
       "Acousticness           9\n",
       "Instrumentalness       9\n",
       "Liveness               9\n",
       "Valence                9\n",
       "Tempo                  9\n",
       "liked                632\n",
       "playlist_origin        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658750-d956-442d-99ed-2dca4323ec47",
   "metadata": {},
   "source": [
    "## Getting New Genre Data From Last.fm üü¢üéµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "427b250a-eb92-4eb4-a0a1-c20f0550eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73 new artists to process\n",
      "Processed 50/73 artists\n",
      "\n",
      "Successfully updated data/ten_genres.csv with 0 new artists!\n"
     ]
    }
   ],
   "source": [
    "class LastFMGenreFetcher:\n",
    "    def __init__(self, api_key: str, rate_limit_delay: float = 0.25):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "        self.rate_limit_delay = rate_limit_delay\n",
    "        \n",
    "        # Define tags to ignore\n",
    "        self.ignored_tags = {\n",
    "            'seen live',\n",
    "            'albums i own',\n",
    "            'favorite',\n",
    "            'favourites',\n",
    "            'favourite',\n",
    "            'my playlist',\n",
    "            'spotify',\n",
    "            'pandora',\n",
    "            'wish i had seen live',\n",
    "            'awesome',\n",
    "            'love at first listen',\n",
    "            'love',\n",
    "            'amazing',\n",
    "            'listened',\n",
    "            'personal',\n",
    "            'my music'\n",
    "        }\n",
    "        \n",
    "        # Define variations of female vocalist to standardize\n",
    "        self.female_vocalist_variants = {\n",
    "            'female vocalists',\n",
    "            'female vocalist',\n",
    "            'female vocals',\n",
    "            'female fronted',\n",
    "            'female voices',\n",
    "            'female voice',\n",
    "            'female singers',\n",
    "            'female singer'\n",
    "        }\n",
    "        \n",
    "    def _make_request(self, params: Dict) -> Dict:\n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            sleep(self.rate_limit_delay)  # Basic rate limiting\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed for params {params}: {e}\")\n",
    "            if getattr(response, 'status_code', None) == 429:\n",
    "                print(\"Rate limit exceeded, increasing delay.\")\n",
    "                self.rate_limit_delay *= 2\n",
    "                sleep(5)  # Wait before retry\n",
    "            return None\n",
    "\n",
    "    def get_artist_tags(self, artist_name: str) -> List[str]:\n",
    "        params = {\n",
    "            'method': 'artist.getTopTags',\n",
    "            'artist': artist_name,\n",
    "            'api_key': self.api_key,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        data = self._make_request(params)\n",
    "        \n",
    "        if not data or 'toptags' not in data:\n",
    "            return []\n",
    "            \n",
    "        tags = []\n",
    "        seen_tags = set()  # Track unique tags\n",
    "        has_female_vocalist = False\n",
    "        \n",
    "        for tag in data['toptags'].get('tag', []):\n",
    "            tag_name = tag['name'].lower()\n",
    "            \n",
    "            # Skip if tag is in ignored list\n",
    "            if tag_name in self.ignored_tags:\n",
    "                continue\n",
    "                \n",
    "            # Handle female vocalist variations\n",
    "            if tag_name in self.female_vocalist_variants:\n",
    "                if not has_female_vocalist:\n",
    "                    tags.insert(0, 'female vocalist')\n",
    "                    has_female_vocalist = True\n",
    "                continue\n",
    "            \n",
    "            # Only add tag if we haven't seen it before\n",
    "            if tag_name not in seen_tags:\n",
    "                tags.append(tag_name)\n",
    "                seen_tags.add(tag_name)\n",
    "                \n",
    "        return tags[:10]  # Return up to 10 tags\n",
    "\n",
    "def update_genre_data(api_key: str, dataframes: List[pd.DataFrame], output_file: str = 'data/ten_genres.csv') -> None:\n",
    "    # Initialize the API client\n",
    "    api = LastFMGenreFetcher(api_key)\n",
    "    \n",
    "    # Get all unique artists from the dataframes\n",
    "    all_artists = set()\n",
    "    for df in dataframes:\n",
    "        if 'Artist Name(s)' in df.columns:\n",
    "            artists = df['Artist Name(s)'].apply(lambda x: x.split(',')[0].strip() if pd.notna(x) else None)\n",
    "            all_artists.update(artist for artist in artists if artist)\n",
    "    \n",
    "    # Load existing data\n",
    "    existing_data = {}\n",
    "    try:\n",
    "        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "            existing_data = pd.read_csv(output_file).set_index('Artist')['Genres'].to_dict()\n",
    "    except (pd.errors.EmptyDataError, KeyError):\n",
    "        print(\"No existing genre data found or file is empty. Starting fresh.\")\n",
    "    \n",
    "    # Load obscure artist genres and merge\n",
    "    obscure_artists = pd.read_csv(\"data/obscure_artists_mike_likes.csv\", quotechar='\"')\n",
    "    obscure_artists_dict = pd.Series(obscure_artists[\"Genres\"].values, index=obscure_artists[\"Artist\"]).to_dict()\n",
    "    \n",
    "    # Merge genres from obscure artists with existing data\n",
    "    existing_data.update(obscure_artists_dict)\n",
    "    \n",
    "    # Identify new artists that aren't in existing data or obscure_artists\n",
    "    new_artists = [artist for artist in all_artists if artist not in existing_data]\n",
    "    \n",
    "    if not new_artists:\n",
    "        print(\"No new artists to process!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(new_artists)} new artists to process\")\n",
    "    \n",
    "    # Process new artists with ThreadPoolExecutor\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_artist = {executor.submit(api.get_artist_tags, artist): artist \n",
    "                          for artist in new_artists}\n",
    "        \n",
    "        completed = 0\n",
    "        for future in as_completed(future_to_artist):\n",
    "            artist = future_to_artist[future]\n",
    "            try:\n",
    "                tags = future.result()\n",
    "                if tags:\n",
    "                    results[artist] = ', '.join(tags)\n",
    "                completed += 1\n",
    "                if completed % 50 == 0 or (len(new_artists) < 50 and completed % 10 == 0):\n",
    "                    print(f\"Processed {completed}/{len(new_artists)} artists\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {artist}: {e}\")\n",
    "    \n",
    "    # Combine existing and new data\n",
    "    all_data = {**existing_data, **results}\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_output = pd.DataFrame(\n",
    "        [{'Artist': artist, 'Genres': genres} \n",
    "         for artist, genres in all_data.items()]\n",
    "    )\n",
    "    df_output.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSuccessfully updated {output_file} with {len(results)} new artists!\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = '74a510ecc9fc62bf3e0edc6adc2e99f9'\n",
    "\n",
    "    # Update genre data\n",
    "    update_genre_data(API_KEY, [df], 'data/ten_genres.csv')\n",
    "\n",
    "    # Load the ten_genres.csv file\n",
    "    ten_genres = pd.read_csv(\"data/ten_genres.csv\")\n",
    "\n",
    "    # Extract the primary artist (before the comma)\n",
    "    df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0]\n",
    "    ten_genres[\"Primary Artist\"] = ten_genres[\"Artist\"].str.split(\",\").str[0]\n",
    "\n",
    "    # Merge, prioritizing ten_genres\n",
    "    df = df.merge(ten_genres[[\"Primary Artist\", \"Genres\"]], on=\"Primary Artist\", how=\"left\", suffixes=(\"\", \"_ten\"))\n",
    "\n",
    "    # If ten_genres has a match, use it; otherwise, keep the original\n",
    "    df[\"Genres\"] = df[\"Genres_ten\"].combine_first(df[\"Genres\"])\n",
    "\n",
    "    # Drop the extra columns\n",
    "    df.drop(columns=[\"Genres_ten\", \"Primary Artist\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8f067-0f96-4c4c-8d63-7296b631a751",
   "metadata": {},
   "source": [
    "### Save a copy of the missing genre artists in case i want to fuss with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ada40922-e667-48b7-aa4f-a87e06a9112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 175 missing artists to 'data/missing_artists.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load the ten_genres.csv file\n",
    "ten_genres = pd.read_csv(\"data/ten_genres.csv\")\n",
    "\n",
    "# Extract the primary artist from both datasets\n",
    "df[\"Primary Artist\"] = df[\"Artist Name(s)\"].str.split(\",\").str[0].str.strip()\n",
    "ten_genres[\"Primary Artist\"] = ten_genres[\"Artist\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "# Identify missing artists\n",
    "missing_artists = df[~df[\"Primary Artist\"].isin(ten_genres[\"Primary Artist\"])]\n",
    "\n",
    "# Save to CSV\n",
    "missing_artists[[\"Primary Artist\"]].drop_duplicates().to_csv(\"data/missing_artists.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(missing_artists)} missing artists to 'data/missing_artists.csv'.\")\n",
    "\n",
    "# remaining missing artists will be in data/missing_artists.csv, you can manually pick genres\n",
    "# if you so choose and place in obscure_artists_mike_likes.csv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64562b7f-ea92-400d-b33d-845770388d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track ID              0\n",
       "Track Name            0\n",
       "Album Name            0\n",
       "Artist Name(s)        0\n",
       "Release Date          0\n",
       "Duration (ms)         0\n",
       "Popularity            0\n",
       "Genres              120\n",
       "Record Label          3\n",
       "Danceability          9\n",
       "Energy                9\n",
       "Key                   9\n",
       "Loudness              9\n",
       "Mode                  9\n",
       "Speechiness           9\n",
       "Acousticness          9\n",
       "Instrumentalness      9\n",
       "Liveness              9\n",
       "Valence               9\n",
       "Tempo                 9\n",
       "liked               632\n",
       "playlist_origin       0\n",
       "Primary Artist        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b2e0e6e-7b06-452d-8999-c96b5fcd8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls in any column except 'liked'\n",
    "df = df[df.drop(columns=['liked']).notna().all(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11d89341-0210-4136-bd93-66070a896e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track ID              0\n",
       "Track Name            0\n",
       "Album Name            0\n",
       "Artist Name(s)        0\n",
       "Release Date          0\n",
       "Duration (ms)         0\n",
       "Popularity            0\n",
       "Genres                0\n",
       "Record Label          0\n",
       "Danceability          0\n",
       "Energy                0\n",
       "Key                   0\n",
       "Loudness              0\n",
       "Mode                  0\n",
       "Speechiness           0\n",
       "Acousticness          0\n",
       "Instrumentalness      0\n",
       "Liveness              0\n",
       "Valence               0\n",
       "Tempo                 0\n",
       "liked               616\n",
       "playlist_origin       0\n",
       "Primary Artist        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c803a7f-4ea3-431f-8c62-54b6801f8416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11625, 23)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4860391-1274-4020-bd0a-8cca3608576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist Origin Counts:\n",
      "playlist_origin\n",
      "df_fav_albums    5575\n",
      "df_liked         4069\n",
      "df_not_liked     1365\n",
      "df_nmf            616\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many of each 'playlist_origin' are in the df dataset\n",
    "playlist_origin_counts = df['playlist_origin'].value_counts()\n",
    "\n",
    "print(\"Playlist Origin Counts:\")\n",
    "print(playlist_origin_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99e430-4c09-4dc2-bb20-445d1ebe6a16",
   "metadata": {},
   "source": [
    "# Feature Engineering / Further Selecting üëå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef584c69-80fb-4a3c-9631-e0e9edcb042a",
   "metadata": {},
   "source": [
    "## Target Encoding Record Labels\n",
    "Record labels are currently having an outsized influence on the model, making up 48% of feature importance (at the time of this addition to the model). This is mainly due to the target encoding being too granular, with hundreds of individual labels. To address this, we're grouping labels by size and frequency first. This helps reduce the risk of overfitting to smaller labels, creates more meaningful categories based on their reach and influence, and makes it easier to handle rare or lesser-known labels without distorting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6075b5b-3b34-4b10-b304-ef671e86f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Category Distribution:\n",
      "Label_Category\n",
      "Large Label     9245\n",
      "Medium Label    1284\n",
      "Small Label      770\n",
      "Unknown/DIY      326\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of Large Labels: ['Anti/Epitaph', 'Mom+Pop', 'Loma Vista Recordings', 'Columbia', 'Dead Oceans']\n",
      "\n",
      "Sample of encoded values:\n",
      "  Label_Category  Label_Category_encoded  liked\n",
      "0    Large Label               56.096541  100.0\n",
      "1    Large Label               56.096541  100.0\n",
      "2   Medium Label               83.153776  100.0\n",
      "3    Large Label               56.096541  100.0\n",
      "4    Large Label               56.096541  100.0\n"
     ]
    }
   ],
   "source": [
    "# The Labels are categorized by quartile by how frequently they appear in the dataset,\n",
    "# Those quartiles are then target encoded on the target variable 'liked'\n",
    "\n",
    "def categorize_labels_by_size(df):\n",
    "    # Count number of tracks per label\n",
    "    label_counts = df[df['playlist_origin'] != 'df_nmf']['Record Label'].value_counts()\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    p75 = label_counts.quantile(0.75)\n",
    "    p25 = label_counts.quantile(0.25)\n",
    "    \n",
    "    # Create category mapping\n",
    "    label_categories = {}\n",
    "    for label, count in label_counts.items():\n",
    "        if count >= p75:\n",
    "            label_categories[label] = 'Large Label'\n",
    "        elif count <= p25:\n",
    "            label_categories[label] = 'Small Label'\n",
    "        else:\n",
    "            label_categories[label] = 'Medium Label'\n",
    "    \n",
    "    # Map unknown labels to 'Unknown/DIY'\n",
    "    df['Label_Category'] = df['Record Label'].map(label_categories).fillna('Unknown/DIY')\n",
    "    \n",
    "    # Print some statistics about the categorization\n",
    "    print(\"\\nLabel Category Distribution:\")\n",
    "    print(df['Label_Category'].value_counts())\n",
    "    print(\"\\nSample of Large Labels:\", \n",
    "          list(label for label, count in label_counts.items() if count >= p75)[:5])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def target_encode_categories(df, column, target, smoothing=35, boost_small_labels=1.5):\n",
    "    # Separate out df_nmf to ensure it's never used in encoding\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    mean_target = df_train[target].mean()\n",
    "    \n",
    "    # Calculate encoding values for each category\n",
    "    label_means = df_train.groupby(column)[target].mean()\n",
    "    label_counts = df_train[column].value_counts()\n",
    "    \n",
    "    # Calculate the smoothed encoding values\n",
    "    smoothed_values = (label_means * label_counts + mean_target * smoothing) / (label_counts + smoothing)\n",
    "    \n",
    "    # Apply boost to small labels\n",
    "    small_labels = df['Label_Category'] == 'Small Label'\n",
    "    \n",
    "    # Align indices between small_labels and smoothed_values\n",
    "    for label in smoothed_values.index:\n",
    "        if label == 'Small Label':\n",
    "            smoothed_values[label] *= boost_small_labels\n",
    "    \n",
    "    # Map with a fallback to the overall mean\n",
    "    df[column + '_encoded'] = df[column].map(smoothed_values).fillna(mean_target)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the categorization and encoding\n",
    "df = categorize_labels_by_size(df)\n",
    "df = target_encode_categories(df, 'Label_Category', 'liked', smoothing=35)\n",
    "\n",
    "# Print sample of results\n",
    "print(\"\\nSample of encoded values:\")\n",
    "print(df[['Label_Category', 'Label_Category_encoded', 'liked']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275ff43-c4a4-4a7a-acb7-d5c74a80285e",
   "metadata": {},
   "source": [
    "## Target Encode Genres üéö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6b1f54f-259b-46aa-826e-df7fa3d3596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Genres  Genres_encoded  \\\n",
      "0  female vocalist, folk, singer-songwriter, blue...       61.137994   \n",
      "1  female vocalist, indie pop, folk, canadian, dr...       65.983958   \n",
      "2  indie rock, folk, dub, shoegaze, dream pop, fo...       65.580611   \n",
      "3  indie, folk, indie pop, indie rock, american, ...       67.017594   \n",
      "4  female vocalist, electronic, pop, indie pop, i...       62.292638   \n",
      "\n",
      "   is_unknown_genre  liked playlist_origin  \n",
      "0                 0  100.0        df_liked  \n",
      "1                 0  100.0        df_liked  \n",
      "2                 0  100.0        df_liked  \n",
      "3                 0  100.0        df_liked  \n",
      "4                 0  100.0        df_liked  \n"
     ]
    }
   ],
   "source": [
    "#temporarily removing to see if model performs better than 67%\n",
    "#This code explodes the list of genres for each song onto their own line,\n",
    "#target encodes, or gives a typical like score for each genre, then\n",
    "#averages the score for each genre of that song, and leaves that as its\n",
    "#target encoded score!\n",
    "\n",
    "# Create a binary indicator column for 'Unknown' genres\n",
    "df['is_unknown_genre'] = (df['Genres'] == 'Unknown').astype(int)\n",
    "\n",
    "# Define the target encoding function\n",
    "def target_encode_multi_genre(df, genre_column, target, smoothing=1, aggregation_method='mean', nmf_fallback=0):\n",
    "    \"\"\"\n",
    "    Target encode a multi-genre column by splitting genres, encoding individually, and aggregating.\n",
    "    Explicitly handles 'Unknown' genres and NMF rows.\n",
    "    \"\"\"\n",
    "    # Separate out df_nmf to ensure it's never used in encoding\n",
    "    df_train = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "    # Calculate the global mean of the target variable\n",
    "    global_mean = df_train[target].mean()\n",
    "\n",
    "    # Split genres into individual categories and exclude 'seen live' and 'Unknown'\n",
    "    df_train['split_genres'] = df_train[genre_column].str.split(', ').apply(\n",
    "        lambda x: [genre for genre in x if genre != 'seen live' and genre != 'Unknown'] if isinstance(x, list) else x\n",
    "    )\n",
    "\n",
    "    # Explode the list of genres into separate rows\n",
    "    exploded_genres = df_train.explode('split_genres')\n",
    "\n",
    "    # Calculate target encoding for individual genres\n",
    "    label_means = exploded_genres.groupby('split_genres')[target].mean()\n",
    "    label_counts = exploded_genres['split_genres'].value_counts()\n",
    "\n",
    "    # Calculate smoothed target encoding for individual genres\n",
    "    smoothed_values = (label_means * label_counts + global_mean * smoothing) / (label_counts + smoothing)\n",
    "\n",
    "    # Map the smoothed values back to the exploded genres\n",
    "    exploded_genres['genre_encoded'] = exploded_genres['split_genres'].map(smoothed_values).fillna(global_mean)\n",
    "\n",
    "    # Aggregate encodings for multi-genre rows\n",
    "    if aggregation_method == 'mean':\n",
    "        aggregated_encodings = exploded_genres.groupby(exploded_genres.index)['genre_encoded'].mean()\n",
    "    elif aggregation_method == 'max':\n",
    "        aggregated_encodings = exploded_genres.groupby(exploded_genres.index)['genre_encoded'].max()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported aggregation method: {aggregation_method}\")\n",
    "\n",
    "    # Add the aggregated encodings to the original dataframe\n",
    "    df[genre_column + '_encoded'] = aggregated_encodings\n",
    "\n",
    "    # Handle 'Unknown' genres\n",
    "    is_unknown = df[genre_column] == 'Unknown'\n",
    "    df.loc[is_unknown, genre_column + '_encoded'] = global_mean  # Use global mean for non-NMF rows\n",
    "\n",
    "    # Handle NMF rows with 'Unknown' genres separately\n",
    "    is_nmf = df['playlist_origin'] == 'df_nmf'\n",
    "    df.loc[is_nmf & is_unknown, genre_column + '_encoded'] = nmf_fallback  # Use nmf_fallback for NMF rows\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the target encoding function\n",
    "df = target_encode_multi_genre(df, 'Genres', 'liked', smoothing=35, nmf_fallback=0)\n",
    "\n",
    "# Inspect the results\n",
    "print(df[['Genres', 'Genres_encoded', 'is_unknown_genre', 'liked', 'playlist_origin']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a051ef7-ad16-4f40-93bd-15672a3ffc30",
   "metadata": {},
   "source": [
    "### Checking the distribution of Genres_encoded by playlist_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff30ffe8-48dc-4b23-a0be-73215cc19248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.39 - -5.11):\n",
      "  df_liked:  (1)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[-5.11 - -4.82):\n",
      "  df_liked:  (0)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[-4.82 - -4.54):\n",
      "  df_liked:  (0)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked: ## (11)\n",
      "\n",
      "[-4.54 - -4.26):\n",
      "  df_liked:  (0)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[-4.26 - -3.97):\n",
      "  df_liked:  (0)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked: ## (11)\n",
      "\n",
      "[-3.97 - -3.69):\n",
      "  df_liked:  (1)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked: ###### (34)\n",
      "\n",
      "[-3.69 - -3.40):\n",
      "  df_liked:  (1)\n",
      "  df_fav_albums: # (8)\n",
      "  df_not_liked: ############# (65)\n",
      "\n",
      "[-3.40 - -3.12):\n",
      "  df_liked:  (0)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked: ##### (25)\n",
      "\n",
      "[-3.12 - -2.83):\n",
      "  df_liked:  (1)\n",
      "  df_fav_albums: ### (19)\n",
      "  df_not_liked: ############## (71)\n",
      "\n",
      "[-2.83 - -2.55):\n",
      "  df_liked:  (4)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked: ############ (63)\n",
      "\n",
      "[-2.55 - -2.27):\n",
      "  df_liked: # (7)\n",
      "  df_fav_albums: ## (12)\n",
      "  df_not_liked: ############## (72)\n",
      "\n",
      "[-2.27 - -1.98):\n",
      "  df_liked: ## (11)\n",
      "  df_fav_albums: ######## (42)\n",
      "  df_not_liked: ########################## (133)\n",
      "\n",
      "[-1.98 - -1.70):\n",
      "  df_liked: ##### (25)\n",
      "  df_fav_albums: ########## (51)\n",
      "  df_not_liked: ################ (80)\n",
      "\n",
      "[-1.70 - -1.41):\n",
      "  df_liked: ####### (35)\n",
      "  df_fav_albums: ################ (80)\n",
      "  df_not_liked: ########################### (139)\n",
      "\n",
      "[-1.41 - -1.13):\n",
      "  df_liked: ########### (56)\n",
      "  df_fav_albums: ###################### (114)\n",
      "  df_not_liked: ########################## (131)\n",
      "\n",
      "[-1.13 - -0.84):\n",
      "  df_liked: ################# (88)\n",
      "  df_fav_albums: ###################################### (193)\n",
      "  df_not_liked: ####################### (118)\n",
      "\n",
      "[-0.84 - -0.56):\n",
      "  df_liked: ############################### (157)\n",
      "  df_fav_albums: ############################################################################## (390)\n",
      "  df_not_liked: ################# (87)\n",
      "\n",
      "[-0.56 - -0.28):\n",
      "  df_liked: ################################################## (251)\n",
      "  df_fav_albums: ############################################################################################################################## (631)\n",
      "  df_not_liked: ####################### (116)\n",
      "\n",
      "[-0.28 - 0.01):\n",
      "  df_liked: ######################################################################### (367)\n",
      "  df_fav_albums: ################################################################################################################################################################# (809)\n",
      "  df_not_liked: ######################### (127)\n",
      "\n",
      "[0.01 - 0.29):\n",
      "  df_liked: ############################################################################################################# (546)\n",
      "  df_fav_albums: ################################################################################################################################################################################## (893)\n",
      "  df_not_liked: ##### (27)\n",
      "\n",
      "[0.29 - 0.58):\n",
      "  df_liked: ##################################################################################################################################### (667)\n",
      "  df_fav_albums: ############################################################################################################################################################# (788)\n",
      "  df_not_liked: #### (22)\n",
      "\n",
      "[0.58 - 0.86):\n",
      "  df_liked: ############################################################################################################################################### (715)\n",
      "  df_fav_albums: ############################################################################################################################################################### (796)\n",
      "  df_not_liked: #### (22)\n",
      "\n",
      "[0.86 - 1.15):\n",
      "  df_liked: ############################################################################################################################################## (713)\n",
      "  df_fav_albums: ########################################################################################################################## (610)\n",
      "  df_not_liked: ## (10)\n",
      "\n",
      "[1.15 - 1.43):\n",
      "  df_liked: ############################################ (223)\n",
      "  df_fav_albums: ###################### (114)\n",
      "  df_not_liked:  (1)\n",
      "\n",
      "[1.43 - 1.71):\n",
      "  df_liked: ######################## (120)\n",
      "  df_fav_albums: # (9)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[1.71 - 2.00):\n",
      "  df_liked: ######## (42)\n",
      "  df_fav_albums: ### (16)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[2.00 - 2.28):\n",
      "  df_liked: #### (23)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[2.28 - 2.57):\n",
      "  df_liked: ## (11)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[2.57 - 2.85):\n",
      "  df_liked:  (3)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n",
      "[2.85 - 3.14):\n",
      "  df_liked:  (0)\n",
      "  df_fav_albums:  (0)\n",
      "  df_not_liked:  (0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_histogram(df, column, hue_column, bins=30):\n",
    "    \"\"\"\n",
    "    Generate a text-based histogram for a column, grouped by a hue column.\n",
    "    \"\"\"\n",
    "    # Get unique values in the hue column\n",
    "    hue_values = df[hue_column].unique()\n",
    "    \n",
    "    # Calculate bin edges\n",
    "    min_val = df[column].min()\n",
    "    max_val = df[column].max()\n",
    "    bin_edges = np.linspace(min_val, max_val, bins + 1)\n",
    "    \n",
    "    # Initialize a dictionary to store counts for each hue\n",
    "    hist_data = {hue: np.zeros(bins, dtype=int) for hue in hue_values}\n",
    "    \n",
    "    # Populate the histogram counts\n",
    "    for i in range(bins):\n",
    "        bin_start = bin_edges[i]\n",
    "        bin_end = bin_edges[i + 1]\n",
    "        for hue in hue_values:\n",
    "            hist_data[hue][i] = df[(df[column] >= bin_start) & (df[column] < bin_end) & (df[hue_column] == hue)].shape[0]\n",
    "    \n",
    "    # Print the histogram\n",
    "    for i in range(bins):\n",
    "        bin_start = bin_edges[i]\n",
    "        bin_end = bin_edges[i + 1]\n",
    "        print(f\"[{bin_start:.2f} - {bin_end:.2f}):\")\n",
    "        for hue in hue_values:\n",
    "            count = hist_data[hue][i]\n",
    "            bar = '#' * (count // 5)  # Scale the bar length for better visualization\n",
    "            print(f\"  {hue}: {bar} ({count})\")\n",
    "        print()\n",
    "\n",
    "# Generate the text-based histogram\n",
    "text_histogram(df, 'Genres_encoded', 'playlist_origin', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df9122-2225-49b9-b63c-3f9f15f433dc",
   "metadata": {},
   "source": [
    "## Finding How Central an Artist is to My Music Taste üéØ\n",
    "This code builds a network of artists based on which ones are liked and which are similar to them. It then calculates how important each artist is in the network using a method called PageRank. The final scores, showing each artist‚Äôs \"centrality,\" are added to the dataset and scaled from 0 to 100, giving us a measure of an artist's influence within the group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fbfbe-20e1-4130-b17e-231f1466f189",
   "metadata": {},
   "source": [
    "### It also Finds Featured Artists, Who Gave the Album Their Co-Sign ‚úç\n",
    "This feature was inspired by Denison Witmer, who on Valentines day 2025 released a lovely album where Sufjan features on multiple songs. I love Sufjan, and didnt know the two were frequent collaborators. This sometimes could help an obscure artist reach new hights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "612732d8-7cc2-4527-bcc5-307649e7d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Regular Artists by Centrality:\n",
      "      Artist Name(s)  Artist Centrality\n",
      "1691     Molly Sarl√©         100.000000\n",
      "942         WebsterX          93.056960\n",
      "3423  String Machine          91.029621\n",
      "1299       Bob Dylan          90.060421\n",
      "322    Generationals          90.048734\n",
      "\n",
      "Top 5 Featured Artists by Centrality:\n",
      "     Featured_Artist(s)  Featured_Centrality_Score\n",
      "1173  [Jess Williamson]                      100.0\n",
      "5604  [Jess Williamson]                      100.0\n",
      "5607  [Jess Williamson]                      100.0\n",
      "5608  [Jess Williamson]                      100.0\n",
      "5611  [Jess Williamson]                      100.0\n"
     ]
    }
   ],
   "source": [
    "# First, create the Featured_Artist(s) column\n",
    "def extract_featured_artists(df):\n",
    "    # Create new column by splitting on comma and taking all but first artist\n",
    "    df['Featured_Artist(s)'] = df['Artist Name(s)'].apply(\n",
    "        lambda x: ', '.join(str(x).split(',')[1:]).strip() if ',' in str(x) else ''\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Prepare the data\n",
    "def prepare_featured_artists(df):\n",
    "    # First create the column if it doesn't exist\n",
    "    df = extract_featured_artists(df)\n",
    "    \n",
    "    # Ensure 'Featured_Artist(s)' is a string and handle missing values\n",
    "    df['Featured_Artist(s)'] = df['Featured_Artist(s)'].fillna('').astype(str)\n",
    "    \n",
    "    # Split and clean the 'Featured_Artist(s)' column into lists\n",
    "    df['Featured_Artist(s)'] = df['Featured_Artist(s)'].str.split(',').apply(\n",
    "        lambda x: [artist.strip() for artist in x] if isinstance(x, list) else []\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_graph(df, df_liked_similar):\n",
    "    \"\"\"Build a graph of artists and their connections.\"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for liked artists\n",
    "    liked_artists = set(\n",
    "        df[df['playlist_origin'].isin(['df_liked', 'df_fav_albums'])]['Artist Name(s)']\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    G.add_nodes_from(liked_artists, type='liked')\n",
    "    \n",
    "    # Add nodes for similar artists (from liked)\n",
    "    similar_artists_liked = set(\n",
    "        df_liked_similar['Similar Artists']\n",
    "        .dropna()\n",
    "        .str.split(',').explode().str.strip()\n",
    "    )\n",
    "    G.add_nodes_from(similar_artists_liked, type='similar_liked')\n",
    "    \n",
    "    # Add edges based on similarity (from liked)\n",
    "    for _, row in df_liked_similar.iterrows():\n",
    "        artist = row['Artist']\n",
    "        if isinstance(row['Similar Artists'], str):\n",
    "            similar = row['Similar Artists'].split(', ')\n",
    "            for s in similar:\n",
    "                G.add_edge(artist, s, weight=1.0)\n",
    "    \n",
    "    # Add nodes for featured artists\n",
    "    featured_artists = set()\n",
    "    for artists in df['Featured_Artist(s)']:\n",
    "        if artists:  # Check if the list is not empty\n",
    "            featured_artists.update(artists)\n",
    "    G.add_nodes_from(featured_artists, type='featured')\n",
    "    \n",
    "    return G\n",
    "\n",
    "def calculate_centrality_scores(G, df):\n",
    "    \"\"\"Calculate PageRank centrality for all artists in the graph.\"\"\"\n",
    "    centrality_scores = nx.pagerank(G)\n",
    "    \n",
    "    # Map centrality scores back to DataFrame for main artists\n",
    "    df['Artist Centrality'] = (\n",
    "        df['Artist Name(s)']\n",
    "        .str.split(',').str[0].str.strip()\n",
    "        .map(centrality_scores).fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Map centrality scores back to DataFrame for featured artists\n",
    "    df['Featured_Centrality_Score'] = df['Featured_Artist(s)'].apply(\n",
    "        lambda x: np.mean([centrality_scores.get(artist, 0) for artist in x if artist in centrality_scores]) if x else 0\n",
    "    )\n",
    "    return df, centrality_scores\n",
    "\n",
    "def normalize_centrality_scores(df):\n",
    "    \"\"\"Normalize centrality scores to 0-100 range.\"\"\"\n",
    "    if df['Artist Centrality'].max() != 0:\n",
    "        df['Artist Centrality'] = (df['Artist Centrality'] / df['Artist Centrality'].max()) * 100\n",
    "    if df['Featured_Centrality_Score'].max() != 0:\n",
    "        df['Featured_Centrality_Score'] = (df['Featured_Centrality_Score'] / df['Featured_Centrality_Score'].max()) * 100\n",
    "    return df\n",
    "\n",
    "# Run the complete pipeline\n",
    "def run_centrality_analysis(df, df_liked_similar):\n",
    "    # Prepare the featured artists data\n",
    "    df = prepare_featured_artists(df)\n",
    "    \n",
    "    # Build the graph and calculate centrality\n",
    "    G = build_graph(df, df_liked_similar)\n",
    "    df, centrality_scores = calculate_centrality_scores(G, df)\n",
    "    df = normalize_centrality_scores(df)\n",
    "    \n",
    "    return df, G, centrality_scores\n",
    "\n",
    "# Execute the analysis\n",
    "df, G, centrality_scores = run_centrality_analysis(df, df_liked_similar)\n",
    "\n",
    "# Filter songs where 'Featured_Artist(s)' is not empty or a missing value\n",
    "df_with_featured = df[df['Featured_Artist(s)'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "\n",
    "# Get the top 5 rows with highest 'Artist Centrality' scores\n",
    "top_artist_df = df.nlargest(5, 'Artist Centrality')[['Artist Name(s)', 'Artist Centrality']]\n",
    "\n",
    "# Get the top 5 rows with highest 'Featured_Centrality_Score' scores (if any featured artists exist)\n",
    "df_with_featured = df[df['Featured_Artist(s)'].apply(lambda x: len(x) > 0)]  # Ensure featured artists exist\n",
    "top_featured_df = df_with_featured.nlargest(5, 'Featured_Centrality_Score')[['Featured_Artist(s)', 'Featured_Centrality_Score']]\n",
    "\n",
    "# Print bite-sized samples of both\n",
    "print(\"\\nTop 5 Regular Artists by Centrality:\")\n",
    "print(top_artist_df)\n",
    "\n",
    "print(\"\\nTop 5 Featured Artists by Centrality:\")\n",
    "print(top_featured_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c20db-4987-4708-b980-ed86d33d8c98",
   "metadata": {},
   "source": [
    "## Two More Features Before Primetime! üé≠\n",
    "\n",
    "**Mood Score**: Combines Valence, Danceability, and Liveness to capture the vibe.\n",
    "\n",
    "**Energy Profile**: Mashes Energy, Loudness, and Tempo to gauge the track‚Äôs intensity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c419738-f1f8-4269-8607-60b5139ddcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features only on non-NMF data\n",
    "non_nmf_df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Create mood_score and energy_profile on non-NMF data\n",
    "non_nmf_df['mood_score'] = non_nmf_df[['Valence', 'Danceability', 'Liveness']].mean(axis=1)\n",
    "non_nmf_df['energy_profile'] = non_nmf_df[['Energy', 'Loudness', 'Tempo']].mean(axis=1)\n",
    "\n",
    "# Merge these features back into the main dataframe\n",
    "df = df.merge(non_nmf_df[['mood_score', 'energy_profile']], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b164e-c47e-4a71-8430-0a0c40c78800",
   "metadata": {},
   "source": [
    "## Previwing the features on the menu üìñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27c0a236-7e93-4a4f-ad96-aa77414f9120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track ID', 'Track Name', 'Album Name', 'Artist Name(s)',\n",
       "       'Release Date', 'Duration (ms)', 'Popularity', 'Genres', 'Record Label',\n",
       "       'Danceability', 'Energy', 'Key', 'Loudness', 'Mode', 'Speechiness',\n",
       "       'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo',\n",
       "       'liked', 'playlist_origin', 'Primary Artist', 'Label_Category',\n",
       "       'Label_Category_encoded', 'is_unknown_genre', 'Genres_encoded',\n",
       "       'Featured_Artist(s)', 'Artist Centrality', 'Featured_Centrality_Score',\n",
       "       'mood_score', 'energy_profile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2dff4e76-fde1-460d-8997-9fbf06ce956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track ID                      object\n",
       "Track Name                    object\n",
       "Album Name                    object\n",
       "Artist Name(s)                object\n",
       "Release Date                  object\n",
       "Duration (ms)                  int64\n",
       "Popularity                     int64\n",
       "Genres                        object\n",
       "Record Label                  object\n",
       "Danceability                 float64\n",
       "Energy                       float64\n",
       "Key                          float64\n",
       "Loudness                     float64\n",
       "Mode                         float64\n",
       "Speechiness                  float64\n",
       "Acousticness                 float64\n",
       "Instrumentalness             float64\n",
       "Liveness                     float64\n",
       "Valence                      float64\n",
       "Tempo                        float64\n",
       "liked                        float64\n",
       "playlist_origin               object\n",
       "Primary Artist                object\n",
       "Label_Category                object\n",
       "Label_Category_encoded       float64\n",
       "is_unknown_genre               int32\n",
       "Genres_encoded               float64\n",
       "Featured_Artist(s)            object\n",
       "Artist Centrality            float64\n",
       "Featured_Centrality_Score    float64\n",
       "mood_score                   float64\n",
       "energy_profile               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e10d2a-a4b1-4fc5-ba15-e0f339c9d738",
   "metadata": {},
   "source": [
    "## Standardize the numeric columns üìè\n",
    "When some numbers have a larger size than others, the model can be biased towards them, so we bring all the numeric columns on a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e2297-9c93-4b11-aa84-a465fcacbe93",
   "metadata": {},
   "source": [
    "### Seperate New Music Friday and Save it for Later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46560726-196c-49ae-aa77-eb98091b8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mood and energy scores first\n",
    "df['mood_score'] = df[['Valence', 'Danceability', 'Liveness']].mean(axis=1)\n",
    "df['energy_profile'] = df[['Energy', 'Loudness', 'Tempo']].mean(axis=1)\n",
    "\n",
    "# Split and save data\n",
    "df_nmf = df[df['playlist_origin'] == 'df_nmf'].copy()\n",
    "df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "\n",
    "# Save both versions pre-standardization\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)\n",
    "df_cleaned_pre_standardized = pd.concat([df, df_nmf], ignore_index=True)\n",
    "df_cleaned_pre_standardized.to_csv('data/df_cleaned_pre_standardized.csv', index=False)\n",
    "\n",
    "# Store original values\n",
    "original_centrality = df_nmf['Artist Centrality'].copy()\n",
    "original_mood = df_nmf['mood_score'].copy()\n",
    "original_energy = df_nmf['energy_profile'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb709d88-3b66-4b3d-bd0f-31c17b361b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns to standardize\n",
    "numeric_columns = [\n",
    "    'Duration (ms)', 'Popularity', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
    "    'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
    "    'Valence', 'Tempo', 'Genres_encoded',\n",
    "    'Artist Centrality', 'Label_Category_encoded', 'mood_score', 'energy_profile'\n",
    "]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data (df)\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Transform the test data (df_nmf) using the fitted scaler\n",
    "df_nmf[numeric_columns] = scaler.transform(df_nmf[numeric_columns])\n",
    "\n",
    "# Save the standardized df_nmf for later use\n",
    "df_nmf.to_csv('data/df_nmf_later.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a66c9a3-793f-4955-82a5-3b50e79be99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Genres_encoded</th>\n",
       "      <th>Artist Centrality</th>\n",
       "      <th>Label_Category_encoded</th>\n",
       "      <th>mood_score</th>\n",
       "      <th>energy_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11009</th>\n",
       "      <td>-0.045539</td>\n",
       "      <td>-1.143594</td>\n",
       "      <td>0.656752</td>\n",
       "      <td>0.874182</td>\n",
       "      <td>1.347972</td>\n",
       "      <td>0.904112</td>\n",
       "      <td>0.597880</td>\n",
       "      <td>-0.422943</td>\n",
       "      <td>-1.014210</td>\n",
       "      <td>-0.457302</td>\n",
       "      <td>1.416694</td>\n",
       "      <td>1.721569</td>\n",
       "      <td>0.290582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.503815</td>\n",
       "      <td>-0.394424</td>\n",
       "      <td>1.922241</td>\n",
       "      <td>0.399956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010</th>\n",
       "      <td>0.927107</td>\n",
       "      <td>-1.143594</td>\n",
       "      <td>0.650512</td>\n",
       "      <td>-0.419166</td>\n",
       "      <td>-1.161581</td>\n",
       "      <td>0.191752</td>\n",
       "      <td>0.597880</td>\n",
       "      <td>-0.481396</td>\n",
       "      <td>0.107122</td>\n",
       "      <td>-0.457301</td>\n",
       "      <td>-0.468997</td>\n",
       "      <td>0.117426</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.503815</td>\n",
       "      <td>-0.394424</td>\n",
       "      <td>0.180003</td>\n",
       "      <td>0.141568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11011</th>\n",
       "      <td>0.850336</td>\n",
       "      <td>-1.143594</td>\n",
       "      <td>0.762839</td>\n",
       "      <td>0.156610</td>\n",
       "      <td>1.347972</td>\n",
       "      <td>0.446395</td>\n",
       "      <td>-1.672578</td>\n",
       "      <td>-0.449513</td>\n",
       "      <td>-1.050572</td>\n",
       "      <td>-0.455029</td>\n",
       "      <td>-0.621852</td>\n",
       "      <td>1.346407</td>\n",
       "      <td>0.430435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.503815</td>\n",
       "      <td>-0.394424</td>\n",
       "      <td>0.950198</td>\n",
       "      <td>0.474193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11012</th>\n",
       "      <td>-0.177832</td>\n",
       "      <td>-1.143594</td>\n",
       "      <td>1.081098</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>-1.161581</td>\n",
       "      <td>0.875521</td>\n",
       "      <td>0.597880</td>\n",
       "      <td>-0.402750</td>\n",
       "      <td>-0.910533</td>\n",
       "      <td>-0.454797</td>\n",
       "      <td>0.373850</td>\n",
       "      <td>1.803502</td>\n",
       "      <td>-0.210242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.503815</td>\n",
       "      <td>-0.394424</td>\n",
       "      <td>1.760872</td>\n",
       "      <td>-0.093178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11013</th>\n",
       "      <td>-0.005826</td>\n",
       "      <td>-1.143594</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.354265</td>\n",
       "      <td>-1.161581</td>\n",
       "      <td>0.582134</td>\n",
       "      <td>0.597880</td>\n",
       "      <td>-0.332606</td>\n",
       "      <td>-0.544225</td>\n",
       "      <td>-0.448835</td>\n",
       "      <td>-0.666137</td>\n",
       "      <td>2.182976</td>\n",
       "      <td>1.001456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.503815</td>\n",
       "      <td>-0.394424</td>\n",
       "      <td>1.165721</td>\n",
       "      <td>1.047172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Duration (ms)  Popularity  Danceability    Energy       Key  Loudness  \\\n",
       "11009      -0.045539   -1.143594      0.656752  0.874182  1.347972  0.904112   \n",
       "11010       0.927107   -1.143594      0.650512 -0.419166 -1.161581  0.191752   \n",
       "11011       0.850336   -1.143594      0.762839  0.156610  1.347972  0.446395   \n",
       "11012      -0.177832   -1.143594      1.081098  0.478873 -1.161581  0.875521   \n",
       "11013      -0.005826   -1.143594      0.082637  0.354265 -1.161581  0.582134   \n",
       "\n",
       "           Mode  Speechiness  Acousticness  Instrumentalness  Liveness  \\\n",
       "11009  0.597880    -0.422943     -1.014210         -0.457302  1.416694   \n",
       "11010  0.597880    -0.481396      0.107122         -0.457301 -0.468997   \n",
       "11011 -1.672578    -0.449513     -1.050572         -0.455029 -0.621852   \n",
       "11012  0.597880    -0.402750     -0.910533         -0.454797  0.373850   \n",
       "11013  0.597880    -0.332606     -0.544225         -0.448835 -0.666137   \n",
       "\n",
       "        Valence     Tempo  Genres_encoded  Artist Centrality  \\\n",
       "11009  1.721569  0.290582             NaN          -1.503815   \n",
       "11010  0.117426  0.124777             NaN          -1.503815   \n",
       "11011  1.346407  0.430435             NaN          -1.503815   \n",
       "11012  1.803502 -0.210242             NaN          -1.503815   \n",
       "11013  2.182976  1.001456             NaN          -1.503815   \n",
       "\n",
       "       Label_Category_encoded  mood_score  energy_profile  \n",
       "11009               -0.394424    1.922241        0.399956  \n",
       "11010               -0.394424    0.180003        0.141568  \n",
       "11011               -0.394424    0.950198        0.474193  \n",
       "11012               -0.394424    1.760872       -0.093178  \n",
       "11013               -0.394424    1.165721        1.047172  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf[numeric_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7fcb4-3d9f-4119-985d-824a1e98eafc",
   "metadata": {},
   "source": [
    "## Tuning and Predicting with Random Forest & XGBoost üåü\n",
    "In this section, we fine-tune our Random Forest and XGBoost models using randomized search for optimal hyperparameters. The goal? To get the best possible performance in predicting song ratings. After tuning the models, we make predictions on the unseen data, combining both models' results to generate a more accurate score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8d91d28-f7ea-46c1-9e10-345dfa959649",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 67\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m     62\u001b[0m features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopularity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenres_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_Category_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmood_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_profile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatured_Centrality_Score\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     65\u001b[0m ]\n\u001b[1;32m---> 67\u001b[0m best_rf, best_xgb, rf_params, xgb_params \u001b[38;5;241m=\u001b[39m tune_models(df, features)\n\u001b[0;32m     68\u001b[0m df_nmf \u001b[38;5;241m=\u001b[39m predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd())\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Output best parameters and feature importances\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[66], line 39\u001b[0m, in \u001b[0;36mtune_models\u001b[1;34m(df, features, test_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m xgb_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     34\u001b[0m     xgb, xgb_params, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     35\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Fit models\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m rf_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     40\u001b[0m xgb_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Train final models with best parameters\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1915\u001b[0m         ParameterSampler(\n\u001b[0;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1917\u001b[0m         )\n\u001b[0;32m   1918\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def tune_models(df, features, test_size=0.2):\n",
    "    # Prepare data\n",
    "    X = df[features]\n",
    "    y = (df['liked'] - df['liked'].mean()) / df['liked'].std()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # RandomForest parameters\n",
    "    rf_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 15),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 5)\n",
    "    }\n",
    "    \n",
    "    # XGBoost parameters\n",
    "    xgb_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4)\n",
    "    }\n",
    "    \n",
    "    # Initialize models\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    xgb = XGBRegressor(random_state=42)\n",
    "    \n",
    "    # Perform randomized search\n",
    "    rf_search = RandomizedSearchCV(\n",
    "        rf, rf_params, n_iter=20, cv=5, scoring='neg_mean_squared_error',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    xgb_search = RandomizedSearchCV(\n",
    "        xgb, xgb_params, n_iter=20, cv=5, scoring='neg_mean_squared_error',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit models\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Train final models with best parameters\n",
    "    best_rf = RandomForestRegressor(**rf_search.best_params_, random_state=42)\n",
    "    best_xgb = XGBRegressor(**xgb_search.best_params_, random_state=42)\n",
    "    \n",
    "    best_rf.fit(X_train, y_train)\n",
    "    best_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    return best_rf, best_xgb, rf_search.best_params_, xgb_search.best_params_\n",
    "\n",
    "def predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, y_mean, y_std):\n",
    "    # Make predictions\n",
    "    rf_pred = best_rf.predict(df_nmf[features]) * y_std + y_mean\n",
    "    xgb_pred = best_xgb.predict(df_nmf[features]) * y_std + y_mean\n",
    "    \n",
    "    # Combine predictions\n",
    "    df_nmf['predicted_score'] = (rf_pred + xgb_pred) / 2\n",
    "    \n",
    "    return df_nmf\n",
    "\n",
    "# Usage\n",
    "features = [\n",
    "    'Popularity','Genres_encoded', 'Artist Centrality',\n",
    "    'Label_Category_encoded', 'mood_score', 'energy_profile', 'Featured_Centrality_Score'\n",
    "]\n",
    "\n",
    "best_rf, best_xgb, rf_params, xgb_params = tune_models(df, features)\n",
    "df_nmf = predict_with_tuned_models(best_rf, best_xgb, df_nmf, features, df['liked'].mean(), df['liked'].std())\n",
    "\n",
    "# Output best parameters and feature importances\n",
    "print(f\"Random Forest best parameters: {rf_params}\")\n",
    "print(f\"XGBoost best parameters: {xgb_params}\")\n",
    "print(f\"Random Forest feature importances: {best_rf.feature_importances_}\")\n",
    "print(f\"XGBoost feature importances: {best_xgb.feature_importances_}\")\n",
    "\n",
    "# Feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature importance (Random Forest):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Save outputs to CSV for future review\n",
    "rf_params_df = pd.DataFrame([rf_params], index=['Random Forest'])\n",
    "xgb_params_df = pd.DataFrame([xgb_params], index=['XGBoost'])\n",
    "feature_importance.to_csv('feature_params/feature_importance.csv')\n",
    "rf_params_df.to_csv('feature_params/rf_params.csv')\n",
    "xgb_params_df.to_csv('feature_params/xgb_params.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b494d-4137-409a-96c8-a4bbcff73a76",
   "metadata": {},
   "source": [
    "# 80/20 Train/Test of The Non NMF Data using RandomForrest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329f0f9-85af-4737-bc6e-5b81559867b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(df, features):\n",
    "    \"\"\"\n",
    "    Train and test model on non-NMF data using 80/20 split\n",
    "    \"\"\"\n",
    "    # Only use non-NMF data for training\n",
    "    train_df = df[df['playlist_origin'] != 'df_nmf'].copy()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_df[features]\n",
    "    y = train_df['liked']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Initialize models with the best parameters from tuning\n",
    "    rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
    "    xgb_model = XGBRegressor(**xgb_params, random_state=42)\n",
    "    \n",
    "    # Train models\n",
    "    print(\"Training Random Forest model...\")\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Training XGBoost model...\")\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Combine predictions (80/20 weight)\n",
    "    final_pred = (0.8 * rf_pred) + (0.2 * xgb_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, final_pred)\n",
    "    r2 = r2_score(y_test, final_pred)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Track Name': train_df.loc[X_test.index, 'Track Name'],\n",
    "        'Artist Name(s)': train_df.loc[X_test.index, 'Artist Name(s)'],\n",
    "        'Actual Score': y_test,\n",
    "        'Predicted Score': final_pred\n",
    "    })\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'RF Importance': rf_model.feature_importances_,\n",
    "        'XGB Importance': xgb_model.feature_importances_\n",
    "    })\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R¬≤ Score: {r2:.2f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 Predictions vs Actual:\")\n",
    "    print(results_df.sort_values('Predicted Score', ascending=False).head(10))\n",
    "    \n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importances.sort_values('RF Importance', ascending=False))\n",
    "    \n",
    "    return rf_model, xgb_model, results_df, importances\n",
    "\n",
    "# To use the model:\n",
    "features = [\n",
    "    'Popularity', 'Genres_encoded', 'Artist Centrality', 'Featured_Centrality_Score',\n",
    "    'Label_Category_encoded', 'mood_score', 'energy_profile'\n",
    "]\n",
    "\n",
    "# Run the model\n",
    "rf_model, xgb_model, results, importances = train_test_model(df, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7455-4090-48fb-92bd-1fe791ed3f65",
   "metadata": {},
   "source": [
    "# Run the New Music Friday Regression Model\n",
    "We‚Äôre using non-NMF data to train Random Forest and XGBoost models to predict how much people will like different tracks. After training, we make predictions for new tracks and give lesser-known artists an extra boost.\n",
    "\n",
    "Next, we calculate confidence intervals to gauge how much we trust the predictions. We also aggregate results by album, factoring in consistency and track count, then sort by weighted score to create a list of top album recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3948a-af2a-497b-9b0e-5f68579ced00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your similar artists data\n",
    "df_liked_similar = pd.read_csv('data/liked_artists_only_similar.csv')\n",
    "\n",
    "# Create known artists set\n",
    "known_artists = set(df_liked_similar['Artist'])\n",
    "\n",
    "features = [\n",
    "    'Popularity', 'Genres_encoded', 'Artist Centrality', 'Featured_Centrality_Score',\n",
    "    'Label_Category_encoded', 'mood_score', 'energy_profile'\n",
    "]\n",
    "\n",
    "# Normalize the target variable\n",
    "y_mean = df['liked'].mean()\n",
    "y_std = df['liked'].std()\n",
    "y_normalized = (df['liked'] - y_mean) / y_std\n",
    "\n",
    "# Prepare training data\n",
    "X = df[features]\n",
    "y = y_normalized  # Use normalized target\n",
    "\n",
    "# Initialize models with the best parameters from tuning\n",
    "rf_model = RandomForestRegressor(**rf_params, random_state=42)\n",
    "xgb_model = XGBRegressor(**xgb_params, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf_model.fit(X, y)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Get feature importance from both models\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_rf': rf_model.feature_importances_\n",
    "}).sort_values('importance_rf', ascending=False)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance_xgb': xgb_model.feature_importances_\n",
    "}).sort_values('importance_xgb', ascending=False)\n",
    "\n",
    "# Combine importance scores\n",
    "feature_importance = pd.merge(rf_importance, xgb_importance, on='feature')\n",
    "feature_importance['avg_importance'] = (feature_importance['importance_rf'] + feature_importance['importance_xgb']) / 2\n",
    "feature_importance = feature_importance.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "# Prepare NMF data for prediction\n",
    "df_nmf_cleaned = df_nmf[features]\n",
    "\n",
    "# Make predictions and denormalize\n",
    "rf_predictions = rf_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "xgb_predictions = xgb_model.predict(df_nmf_cleaned) * y_std + y_mean\n",
    "\n",
    "# Combine predictions (ensemble)\n",
    "final_predictions = (rf_predictions + xgb_predictions) / 2\n",
    "\n",
    "# MODIFIED SECTION - Apply artist boost\n",
    "df_nmf['is_unknown_artist'] = ~df_nmf['Artist Name(s)'].isin(known_artists)\n",
    "df_nmf['predicted_score'] = final_predictions + (df_nmf['is_unknown_artist'] * 2.5)\n",
    "\n",
    "# Get prediction intervals\n",
    "def get_prediction_interval(X, model, percentile=95):\n",
    "    predictions = []\n",
    "    for estimator in model.estimators_:\n",
    "        predictions.append(estimator.predict(X) * y_std + y_mean)\n",
    "    predictions = np.array(predictions)\n",
    "    lower = np.percentile(predictions, (100-percentile)/2, axis=0)\n",
    "    upper = np.percentile(predictions, 100-(100-percentile)/2, axis=0)\n",
    "    return lower, upper\n",
    "\n",
    "# Calculate prediction intervals\n",
    "lower_bound, upper_bound = get_prediction_interval(df_nmf_cleaned, rf_model)\n",
    "df_nmf['prediction_lower'] = lower_bound\n",
    "df_nmf['prediction_upper'] = upper_bound\n",
    "df_nmf['prediction_uncertainty'] = upper_bound - lower_bound\n",
    "\n",
    "# Get the most common release date from NMF dataset\n",
    "nmf_release_date = df_nmf['Release Date'].mode().iloc[0]\n",
    "\n",
    "album_predictions = df_nmf.groupby('Album Name').agg({\n",
    "    'Artist Name(s)': 'first',\n",
    "    'predicted_score': ['mean', 'std', 'count'],\n",
    "    'prediction_uncertainty': 'mean',\n",
    "    'Genres': lambda x: ' | '.join(list(set(x))[:3]),\n",
    "    'Record Label': 'first',\n",
    "    'Artist Centrality': 'first',  \n",
    "    'mood_score': 'first',         \n",
    "    'energy_profile': 'first'     \n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# Flatten column names\n",
    "album_predictions.columns = [\n",
    "    'Album Name', 'Artist', 'avg_score', 'score_std', 'track_count',\n",
    "    'avg_uncertainty', 'Genres', 'Label', 'Artist_Centrality', \n",
    "    'Mood_Score', 'Energy_Profile'\n",
    "]\n",
    "\n",
    "# Calculate confidence score (unchanged)\n",
    "max_std = album_predictions['score_std'].max()\n",
    "max_uncertainty = album_predictions['avg_uncertainty'].max()\n",
    "\n",
    "album_predictions['confidence_score'] = (\n",
    "    (1 - album_predictions['score_std'] / max_std) * \n",
    "    (1 - album_predictions['avg_uncertainty'] / max_uncertainty) * \n",
    "    (1 - 1/(1 + album_predictions['track_count']))\n",
    ") * 100\n",
    "\n",
    "album_predictions['confidence_score'] = np.clip(\n",
    "    album_predictions['confidence_score'], a_min=1, a_max=100\n",
    ")\n",
    "\n",
    "# Rename track_count to Track_Count in the album_predictions dataframe\n",
    "album_predictions = album_predictions.rename(columns={'track_count': 'Track_Count'})\n",
    "\n",
    "# Filter out albums with fewer than 5 tracks\n",
    "album_predictions_filtered = album_predictions[album_predictions['Track_Count'] >= 5].copy()\n",
    "\n",
    "# Sort by average score\n",
    "album_recommendations = album_predictions_filtered.sort_values('avg_score', ascending=False)\n",
    "\n",
    "# Define output columns with original values and add Track_Count\n",
    "output_columns = [\n",
    "    'Artist', 'Album Name', 'avg_score', 'confidence_score',\n",
    "    'Track_Count', 'Genres', 'Label', 'Artist_Centrality', \n",
    "    'Mood_Score', 'Energy_Profile'\n",
    "]\n",
    "\n",
    "# Format the date for the filename\n",
    "date_str = datetime.strptime(nmf_release_date, '%Y-%m-%d').strftime('%m-%d-%y')\n",
    "filename = f\"{date_str}_Album_Recommendations.csv\"\n",
    "\n",
    "# Save recommendations with rounded numbers and scale adjustments\n",
    "final_recommendations = album_recommendations[output_columns].copy()\n",
    "final_recommendations['Artist_Centrality'] = final_recommendations['Artist_Centrality'] * 100\n",
    "final_recommendations['Mood_Score'] = final_recommendations['Mood_Score'].clip(0, 1) * 100\n",
    "final_recommendations['Energy_Profile'] = final_recommendations['Energy_Profile'].clip(0, 1) * 100\n",
    "\n",
    "final_recommendations.round(2).to_csv(f'predictions/{filename}', index=False)\n",
    "\n",
    "# Define the custom scorer for cross-validation\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    y_true_denormalized = y_true * y_std + y_mean\n",
    "    y_pred_denormalized = y_pred * y_std + y_mean\n",
    "    return -mean_squared_error(y_true_denormalized, y_pred_denormalized)\n",
    "\n",
    "# Wrap the custom scorer\n",
    "custom_scorer_func = make_scorer(custom_scorer, greater_is_better=False)\n",
    "\n",
    "# Evaluate models using cross-validation\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring=custom_scorer_func)\n",
    "\n",
    "# Print results with improved formatting\n",
    "print(f\"\\n=== New Music Friday Recommendations ({nmf_release_date}) ===\\n\")\n",
    "\n",
    "# Count of albums filtered out\n",
    "albums_filtered_out = len(album_predictions) - len(album_predictions_filtered)\n",
    "print(f\"Total albums: {len(album_predictions)}\")\n",
    "print(f\"Albums with 5+ tracks: {len(album_predictions_filtered)}\")\n",
    "print(f\"Albums filtered out (< 5 tracks): {albums_filtered_out}\\n\")\n",
    "\n",
    "# Display top 20 recommended albums with clean formatting\n",
    "print(\"Top 20 Albums by Average Score:\")\n",
    "display_cols = ['Artist', 'Album Name', 'avg_score', 'Track_Count']\n",
    "print(album_recommendations[display_cols].head(20).round(2).to_string(index=False))\n",
    "\n",
    "# Print model performance metrics\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"Random Forest CV Score: {rf_cv_scores.mean():.3f} (+/- {rf_cv_scores.std() * 2:.3f})\")\n",
    "print(f\"XGBoost CV Score: {xgb_cv_scores.mean():.3f} (+/- {xgb_cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Display feature importance\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(feature_importance[['feature', 'avg_importance']].round(3).to_string(index=False))\n",
    "\n",
    "# Visualization for feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['avg_importance'])\n",
    "plt.xlabel('Average Importance')\n",
    "plt.title('Top 6 Most Important Features')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ad19c-d758-4214-b737-8ff44a13791c",
   "metadata": {},
   "source": [
    "# Display the Top Recommended Albums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad0062-5648-47e6-a079-4671644d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where the predictions are saved\n",
    "predictions_folder = \"predictions/\"\n",
    "\n",
    "# Get the latest predictions file\n",
    "files = [f for f in os.listdir(predictions_folder) if f.endswith(\"_Album_Recommendations.csv\")]\n",
    "\n",
    "if files:\n",
    "    thisweek = max(files, key=lambda f: os.path.getmtime(os.path.join(predictions_folder, f)))\n",
    "    print(f\"Loaded latest file: {thisweek}\")  # Optional, just for confirmation\n",
    "    model_output_df = pd.read_csv(os.path.join(predictions_folder, thisweek))\n",
    "    model_output_df = model_output_df.sort_values(by=\"avg_score\", ascending=False)\n",
    "\n",
    "    # Display all rows\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    model_output_df\n",
    "else:\n",
    "    thisweek = None\n",
    "    None  # Ensures no unwanted output\n",
    "\n",
    "thisweek  # Stores the filename for reference\n",
    "model_output_df  #Show the Recommendations Dataframe for This Past Week!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574853d5-e2d1-4056-9078-06dd1c8cc947",
   "metadata": {},
   "source": [
    "## Grab Album Art for the NMF Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a20ad-63e1-4b72-aa0c-da53b59ee761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from typing import Dict\n",
    "\n",
    "# Your Last.fm API key\n",
    "LASTFM_API_KEY = \"74a510ecc9fc62bf3e0edc6adc2e99f9\"\n",
    "\n",
    "# Function to get similar artists using Last.fm API\n",
    "def get_similar_artists(artist: str, api_key: str, limit: int = 5) -> Dict:\n",
    "    \"\"\"\n",
    "    Get similar artists using Last.fm API.\n",
    "    Returns dict with artist and similar artists list.\n",
    "    \"\"\"\n",
    "    base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "    params = {\n",
    "        'method': 'artist.getsimilar',\n",
    "        'artist': artist,\n",
    "        'api_key': api_key,\n",
    "        'limit': limit,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'similarartists' in data and 'artist' in data['similarartists']:\n",
    "            similar_artists = [artist['name'] for artist in data['similarartists']['artist']]\n",
    "            return {\n",
    "                'Artist': artist,\n",
    "                'Similar Artists': \", \".join(similar_artists[:limit]),\n",
    "                'status': 'success'\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Artist': artist,\n",
    "            'Similar Artists': None,\n",
    "            'status': f'error: {str(e)}'\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'Artist': artist,\n",
    "        'Similar Artists': None,\n",
    "        'status': 'no_results'\n",
    "    }\n",
    "\n",
    "# Function to fetch album art from Discogs (backup)\n",
    "def get_album_art_discogs(artist: str, album: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch album artwork URL using Discogs API directly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://api.discogs.com/database/search\"\n",
    "        params = {\n",
    "            'artist': artist,\n",
    "            'release_title': album,\n",
    "            'type': 'release',\n",
    "            'per_page': 1\n",
    "        }\n",
    "        headers = {\n",
    "            'User-Agent': 'MyApp/1.0',  # Required by Discogs\n",
    "            'Authorization': 'Discogs token=YOUR_DISCOGS_TOKEN'  # Optional: Add if you have a token\n",
    "        }\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get('results') and data['results'][0].get('cover_image'):\n",
    "            return data['results'][0]['cover_image']\n",
    "    except Exception as e:\n",
    "        print(f\"Discogs error for {artist} - {album}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Function to get album art using Last.fm API (primary) and Discogs (backup)\n",
    "def get_album_art(artist: str, album: str, api_key: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Search for album artwork URL using Last.fm API, with Discogs as a backup.\n",
    "    Returns dict with album info and status.\n",
    "    \"\"\"\n",
    "    base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "    params = {\n",
    "        'method': 'album.getinfo',\n",
    "        'api_key': api_key,\n",
    "        'artist': artist,\n",
    "        'album': album,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'album' in data and 'image' in data['album']:\n",
    "            images = data['album']['image']\n",
    "            largest_image = images[-1]['#text'] if images else None\n",
    "            if largest_image:\n",
    "                return {\n",
    "                    'Artist': artist,\n",
    "                    'Album Name': album,\n",
    "                    'Album Art': largest_image,\n",
    "                    'status': 'success (Last.fm)'\n",
    "                }\n",
    "        \n",
    "        # If Last.fm fails, try Discogs as a backup\n",
    "        discogs_art = get_album_art_discogs(artist, album)\n",
    "        if discogs_art:\n",
    "            return {\n",
    "                'Artist': artist,\n",
    "                'Album Name': album,\n",
    "                'Album Art': discogs_art,\n",
    "                'status': 'success (Discogs)'\n",
    "            }\n",
    "        \n",
    "        # If both APIs fail\n",
    "        return {\n",
    "            'Artist': artist,\n",
    "            'Album Name': album,\n",
    "            'Album Art': None,\n",
    "            'status': 'no_results'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Artist': artist,\n",
    "            'Album Name': album,\n",
    "            'Album Art': None,\n",
    "            'status': f'error: {str(e)}'\n",
    "        }\n",
    "\n",
    "# Main function to update album data\n",
    "def update_album_data(input_file: str, album_art_file: str, similar_artists_file: str, api_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Fetch fresh album cover art and similar artists data for the current playlist.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting data fetch at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Read input data\n",
    "    df_input = pd.read_csv(input_file)\n",
    "    \n",
    "    # Get all unique artist/album pairs from the input data\n",
    "    album_pairs = df_input[['Primary Artist', 'Album Name']].drop_duplicates()\n",
    "    \n",
    "    # Get all recommended artists (from df_nmf tracks)\n",
    "    recommended_artists = df_input[df_input['playlist_origin'] == 'df_nmf']['Primary Artist'].unique()\n",
    "    \n",
    "    # Load existing album covers (if any)\n",
    "    try:\n",
    "        existing_album_art = pd.read_csv(album_art_file)\n",
    "        print(\"Loaded existing album covers.\")\n",
    "    except FileNotFoundError:\n",
    "        existing_album_art = pd.DataFrame(columns=['Artist', 'Album Name', 'Album Art'])\n",
    "        print(\"No existing album covers found. Starting fresh.\")\n",
    "    \n",
    "    # Filter out albums that already have artwork\n",
    "    album_pairs = album_pairs.merge(\n",
    "        existing_album_art,\n",
    "        left_on=['Primary Artist', 'Album Name'],\n",
    "        right_on=['Artist', 'Album Name'],\n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    album_pairs = album_pairs[album_pairs['_merge'] == 'left_only'].drop(columns=['_merge', 'Album Art'])\n",
    "    \n",
    "    if len(album_pairs) == 0:\n",
    "        print(\"All albums already have artwork. No new data to process.\")\n",
    "    else:\n",
    "        print(f\"\\nNeed to fetch album artwork for {len(album_pairs)} new albums.\")\n",
    "    \n",
    "    # Initialize empty DataFrames for new data\n",
    "    df_album_art = pd.DataFrame(columns=['Artist', 'Album Name', 'Album Art'])\n",
    "    df_similar = pd.DataFrame(columns=['Artist', 'Similar Artists'])\n",
    "    \n",
    "    # Process album art for new albums\n",
    "    print(\"\\nFetching album artwork...\")\n",
    "    album_entries = []\n",
    "    successful_albums = 0\n",
    "    failed_albums = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_album = {\n",
    "            executor.submit(get_album_art, row['Primary Artist'], row['Album Name'], api_key): (row['Primary Artist'], row['Album Name'])\n",
    "            for _, row in album_pairs.iterrows()\n",
    "        }\n",
    "        \n",
    "        for i, future in enumerate(as_completed(future_to_album), 1):\n",
    "            result = future.result()\n",
    "            if result['status'].startswith('success') and result['Album Art']:\n",
    "                album_entries.append({\n",
    "                    'Artist': result['Artist'],\n",
    "                    'Album Name': result['Album Name'],\n",
    "                    'Album Art': result['Album Art']\n",
    "                })\n",
    "                successful_albums += 1\n",
    "            else:\n",
    "                failed_albums += 1\n",
    "            \n",
    "            if i % 5 == 0 or i == len(album_pairs):\n",
    "                print(f\"Album Progress: {i}/{len(album_pairs)} | Success: {successful_albums} | Failed: {failed_albums}\")\n",
    "            \n",
    "            sleep(0.25)\n",
    "    \n",
    "    if album_entries:\n",
    "        df_album_art = pd.DataFrame(album_entries)\n",
    "        # Append new data to existing data\n",
    "        updated_album_art = pd.concat([existing_album_art, df_album_art], ignore_index=True)\n",
    "        updated_album_art.to_csv(album_art_file, index=False)\n",
    "        print(f\"Saved {len(df_album_art)} new album covers to {album_art_file}.\")\n",
    "    \n",
    "    # Process similar artists for recommended artists\n",
    "    print(\"\\nFetching similar artists...\")\n",
    "    artist_entries = []\n",
    "    successful_artists = 0\n",
    "    failed_artists = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_artist = {\n",
    "            executor.submit(get_similar_artists, artist, api_key): artist\n",
    "            for artist in recommended_artists\n",
    "        }\n",
    "        \n",
    "        for i, future in enumerate(as_completed(future_to_artist), 1):\n",
    "            result = future.result()\n",
    "            if result['status'] == 'success' and result['Similar Artists']:\n",
    "                artist_entries.append({\n",
    "                    'Artist': result['Artist'],\n",
    "                    'Similar Artists': result['Similar Artists']\n",
    "                })\n",
    "                successful_artists += 1\n",
    "            else:\n",
    "                failed_artists += 1\n",
    "            \n",
    "            if i % 5 == 0 or i == len(recommended_artists):\n",
    "                print(f\"Artist Progress: {i}/{len(recommended_artists)} | Success: {successful_artists} | Failed: {failed_artists}\")\n",
    "            \n",
    "            sleep(0.25)\n",
    "    \n",
    "    if artist_entries:\n",
    "        df_similar = pd.DataFrame(artist_entries)\n",
    "        df_similar.to_csv(similar_artists_file, index=False)\n",
    "        print(f\"Saved {len(df_similar)} new similar artists to {similar_artists_file}.\")\n",
    "    \n",
    "    print(f\"\\nFinished at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Summary:\")\n",
    "    print(f\"- Album artwork added: {successful_albums}\")\n",
    "    print(f\"- Album artwork failed: {failed_albums}\")\n",
    "    print(f\"- Similar artists added: {successful_artists}\")\n",
    "    print(f\"- Similar artists failed: {failed_artists}\")\n",
    "    print(f\"- Total albums in database: {len(existing_album_art) + len(df_album_art)}\")\n",
    "    print(f\"- Total artists in database: {len(df_similar)}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data/df_nmf_later.csv\"  # Replace with your input file path\n",
    "    album_art_file = \"data/nmf_album_covers.csv\"  # Replace with your output file path\n",
    "    similar_artists_file = \"data/nmf_similar_artists.csv\"  # Replace with your output file path\n",
    "    update_album_data(input_file, album_art_file, similar_artists_file, LASTFM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025f562-96cb-4e59-a32d-6338f3a7da96",
   "metadata": {},
   "source": [
    "## Grab the Spotify Link for each New Music Friday Album üîó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126d6b2-d2bb-4c08-bc71-a12a69115c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spotify_links():\n",
    "    # Initialize Spotify client with your credentials\n",
    "    client_id = \"71faef9605da4db495b691d96a0daa4b\"\n",
    "    client_secret = \"832e40da22e049bba93f29d9dbeb2e62\"\n",
    "    \n",
    "    sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret\n",
    "    ))\n",
    "    \n",
    "    # Read the NMF data\n",
    "    df = pd.read_csv('data/nmf.csv')\n",
    "    \n",
    "    # Get unique albums\n",
    "    albums = df.drop_duplicates(subset=['Album Name'], keep='first')\n",
    "    \n",
    "    # Function to get album ID from track with rate limiting\n",
    "    def get_album_id(track_id):\n",
    "        try:\n",
    "            # Add delay to respect rate limits\n",
    "            time.sleep(0.1)  # 100ms delay between requests\n",
    "            track_info = sp.track(track_id)\n",
    "            return track_info['album']['id']\n",
    "        except spotipy.exceptions.SpotifyException as e:\n",
    "            if e.http_status == 429:  # Too Many Requests\n",
    "                print(\"Rate limit hit, waiting longer...\")\n",
    "                time.sleep(5)  # Wait 5 seconds before retrying\n",
    "                try:\n",
    "                    track_info = sp.track(track_id)\n",
    "                    return track_info['album']['id']\n",
    "                except:\n",
    "                    print(f\"Still failed after retry for track {track_id}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Error getting album ID for track {track_id}: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for track {track_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"Processing {len(albums)} albums...\")\n",
    "    \n",
    "    # Get album IDs and generate URLs\n",
    "    albums['Album ID'] = albums['Track ID'].apply(get_album_id)\n",
    "    \n",
    "    # Filter out any failed lookups\n",
    "    albums = albums.dropna(subset=['Album ID'])\n",
    "    \n",
    "    albums['Spotify URL'] = 'open.spotify.com/album/' + albums['Album ID'].astype(str)\n",
    "    \n",
    "    # Select and reorder columns for output\n",
    "    output_df = albums[['Album Name', 'Artist Name(s)', 'Album ID', 'Spotify URL']]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv('data/nmf_album_links.csv', index=False)\n",
    "    \n",
    "    print(f\"Successfully generated album links for {len(output_df)} albums\")\n",
    "    return output_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_spotify_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73467-5b49-4809-8203-805fbf599238",
   "metadata": {},
   "source": [
    "## Save a HTML copy of this notebook at its newest! üîΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd78cd-cf1f-41fc-9d5e-94bc1e6a70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'graphics/' directory exists\n",
    "os.makedirs('graphics', exist_ok=True)\n",
    "\n",
    "# Load the current notebook with 'utf-8' encoding\n",
    "notebook_filename = 'Music Taste Machine Learning Data Prep.ipynb'\n",
    "with open(notebook_filename, 'r', encoding='utf-8') as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Export the notebook as HTML\n",
    "html_exporter = HTMLExporter()\n",
    "html_data, resources = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Save the HTML to the 'graphics/' folder\n",
    "output_filename = 'graphics/Music_Taste_Machine_Learning_Data_Prep.html'\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_data)\n",
    "\n",
    "print(f\"HTML version saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
